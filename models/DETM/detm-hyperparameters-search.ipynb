{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10620041,"sourceType":"datasetVersion","datasetId":6575536},{"sourceId":10624888,"sourceType":"datasetVersion","datasetId":6578486}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install topmost","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T03:27:28.369006Z","iopub.execute_input":"2025-02-20T03:27:28.369334Z","iopub.status.idle":"2025-02-20T03:27:31.856560Z","shell.execute_reply.started":"2025-02-20T03:27:28.369304Z","shell.execute_reply":"2025-02-20T03:27:31.855695Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: topmost in /usr/local/lib/python3.10/dist-packages (1.0.1)\nRequirement already satisfied: numpy<1.27.0 in /usr/local/lib/python3.10/dist-packages (from topmost) (1.26.4)\nRequirement already satisfied: scipy<=1.10.1 in /usr/local/lib/python3.10/dist-packages (from topmost) (1.10.1)\nRequirement already satisfied: sentence-transformers<3.0.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from topmost) (2.7.0)\nRequirement already satisfied: torchvision>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from topmost) (0.20.1+cu121)\nRequirement already satisfied: gensim>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from topmost) (4.3.3)\nRequirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from topmost) (1.2.2)\nRequirement already satisfied: tqdm>=4.66.0 in /usr/local/lib/python3.10/dist-packages (from topmost) (4.67.1)\nRequirement already satisfied: fastopic>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from topmost) (1.0.0)\nRequirement already satisfied: bertopic>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from topmost) (0.16.4)\nRequirement already satisfied: hdbscan>=0.8.29 in /usr/local/lib/python3.10/dist-packages (from bertopic>=0.15.0->topmost) (0.8.40)\nRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from bertopic>=0.15.0->topmost) (2.2.2)\nRequirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from bertopic>=0.15.0->topmost) (5.24.1)\nRequirement already satisfied: umap-learn>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from bertopic>=0.15.0->topmost) (0.5.7)\nRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim>=4.2.0->topmost) (7.0.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<1.27.0->topmost) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<1.27.0->topmost) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<1.27.0->topmost) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<1.27.0->topmost) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<1.27.0->topmost) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<1.27.0->topmost) (2.4.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->topmost) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->topmost) (3.5.0)\nRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.6.0->topmost) (4.47.0)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.6.0->topmost) (2.5.1+cu121)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.6.0->topmost) (0.27.0)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.6.0->topmost) (11.0.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (2024.9.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (1.3.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (2.32.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic>=0.15.0->topmost) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic>=0.15.0->topmost) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic>=0.15.0->topmost) (2024.2)\nRequirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic>=0.15.0->topmost) (9.0.0)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim>=4.2.0->topmost) (1.17.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (0.4.5)\nRequirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.0->bertopic>=0.15.0->topmost) (0.60.0)\nRequirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.0->bertopic>=0.15.0->topmost) (0.5.13)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<1.27.0->topmost) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<1.27.0->topmost) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<1.27.0->topmost) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<1.27.0->topmost) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<1.27.0->topmost) (2024.2.0)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic>=0.15.0->topmost) (0.43.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic>=0.15.0->topmost) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (2024.12.14)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import topmost\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom topmost.models.dynamic.DETM import DETM\nfrom topmost import eva\nimport numpy as np\nimport itertools\nimport json\nimport joblib\nfrom tqdm import tqdm\nimport os\nimport json\nimport random","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T03:27:35.809889Z","iopub.execute_input":"2025-02-20T03:27:35.810180Z","iopub.status.idle":"2025-02-20T03:28:34.159084Z","shell.execute_reply.started":"2025-02-20T03:27:35.810156Z","shell.execute_reply":"2025-02-20T03:28:34.158184Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from gensim.corpora import Dictionary\nfrom gensim.models import CoherenceModel\nfrom topmost.data.file_utils import split_text_word","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T03:28:39.488134Z","iopub.execute_input":"2025-02-20T03:28:39.488878Z","iopub.status.idle":"2025-02-20T03:28:39.493031Z","shell.execute_reply.started":"2025-02-20T03:28:39.488846Z","shell.execute_reply":"2025-02-20T03:28:39.491994Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Funciones externas","metadata":{}},{"cell_type":"code","source":"def get_theta_redefined(self, bows, times, eta=None): ## amortized inference\n        \"\"\"Returns the topic proportions.\n        \"\"\"\n        # normalized_bows = bows / bows.sum(1, keepdims=True)\n        # print(\"🍀 Before\", normalized_bows)\n\n        normalized_bows = bows / (bows.sum(1, keepdims=True) + 1e-12)\n        # print(\"🍀 After\", normalized_bows)\n    \n        if eta is None and self.training is False:\n            eta, kl_eta = self.get_eta(self.rnn_inp)\n\n        eta_td = eta[times]\n        inp = torch.cat([normalized_bows, eta_td], dim=1)\n        q_theta = self.q_theta(inp)\n        if self.enc_drop > 0:\n            q_theta = self.t_drop(q_theta)\n        mu_theta = self.mu_q_theta(q_theta)\n        logsigma_theta = self.logsigma_q_theta(q_theta)\n        z = self.reparameterize(mu_theta, logsigma_theta)\n        theta = F.softmax(z, dim=-1)\n        kl_theta = self.get_kl(mu_theta, logsigma_theta, eta_td, torch.zeros(self.num_topics).to(self.device))\n\n        if self.training:\n            return theta, kl_theta\n        else:\n            return theta\n\nDETM.get_theta = get_theta_redefined","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T03:28:55.635285Z","iopub.execute_input":"2025-02-20T03:28:55.635596Z","iopub.status.idle":"2025-02-20T03:28:55.641327Z","shell.execute_reply.started":"2025-02-20T03:28:55.635569Z","shell.execute_reply":"2025-02-20T03:28:55.640541Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class DETMFixed(DETM):\n    def __init__(self, vocab_size, num_times, train_size, train_time_wordfreq, num_topics=50, train_WE=True, pretrained_WE=None, en_units=800, eta_hidden_size=200, rho_size=300, enc_drop=0.0, eta_nlayers=3, eta_dropout=0.0, delta=0.005, theta_act='relu', device='cpu'):\n        super().__init__(vocab_size, num_times, train_size, train_time_wordfreq, num_topics, True, pretrained_WE, en_units, eta_hidden_size, rho_size, enc_drop, eta_nlayers, eta_dropout, delta, theta_act, device)\n        \n        ## define the word embedding matrix \\rho\n        if not self.train_WE:\n            rho = nn.Embedding(pretrained_WE.shape[1], pretrained_WE.shape[0])\n            rho.weight.data = torch.from_numpy(pretrained_WE)\n            self.rho = rho.weight.data.clone().float().to(self.device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T03:28:59.777339Z","iopub.execute_input":"2025-02-20T03:28:59.777666Z","iopub.status.idle":"2025-02-20T03:28:59.783330Z","shell.execute_reply.started":"2025-02-20T03:28:59.777639Z","shell.execute_reply":"2025-02-20T03:28:59.782484Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def _coherence_modified(reference_corpus, vocab, top_words, cv_type='c_v'):\n    # print('🍀')\n    \n    split_top_words = split_text_word(top_words)\n    num_top_words = len(split_top_words[0])\n    for item in split_top_words:\n        assert num_top_words == len(item)\n\n    split_reference_corpus = split_text_word(reference_corpus)\n    dictionary = Dictionary(split_text_word(vocab))\n\n    cm = CoherenceModel(texts=split_reference_corpus, dictionary=dictionary, topics=split_top_words, topn=num_top_words, coherence=cv_type)\n    cv_per_topic = cm.get_coherence_per_topic()\n    # print(f\"Coherence scores per topic: {cv_per_topic}\")\n\n    valid_scores = [score for score in cv_per_topic if not np.isnan(score)]\n    if not valid_scores:\n        raise ValueError(\"All coherence scores are NaN.\")\n    score = np.mean(valid_scores)\n\n    return score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T03:29:03.936302Z","iopub.execute_input":"2025-02-20T03:29:03.936757Z","iopub.status.idle":"2025-02-20T03:29:03.944022Z","shell.execute_reply.started":"2025-02-20T03:29:03.936696Z","shell.execute_reply":"2025-02-20T03:29:03.943084Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"eva.topic_coherence._coherence = _coherence_modified\n\ndef eval(trainer, top_words):\n    # get theta (doc-topic distributions)\n    train_theta, test_theta = trainer.export_theta()\n\n    train_times = dataset.train_times.cpu().numpy()\n    # compute topic coherence\n    dynamic_TC = eva.dynamic_coherence(dataset.train_texts, train_times, dataset.vocab, top_words, verbose=True)\n    print(\"dynamic_TC: \", dynamic_TC)\n\n    # compute topic diversity\n    dynamic_TD = eva.dynamic_diversity(top_words, dataset.train_bow.cpu().numpy(), train_times, dataset.vocab, verbose=False)\n    print(\"dynamic_TD: \", dynamic_TD)\n\n    # evaluate clustering\n    clustering = eva._clustering(test_theta, dataset.test_labels)\n    print(clustering)\n\n    # evaluate classification\n    classification = eva._cls(train_theta, test_theta, dataset.train_labels, dataset.test_labels)\n    print(classification)\n    \n    json = {\n        \"dynamic_TC\": dynamic_TC,\n        \"dynamic_TD\": dynamic_TD,\n        \"clustering\": clustering,\n        \"classification\": classification\n    }\n    \n    return json, dynamic_TC, dynamic_TD, clustering, classification","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T03:29:08.977121Z","iopub.execute_input":"2025-02-20T03:29:08.977396Z","iopub.status.idle":"2025-02-20T03:29:08.983305Z","shell.execute_reply.started":"2025-02-20T03:29:08.977375Z","shell.execute_reply":"2025-02-20T03:29:08.982293Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import joblib\nimport json\n\ndef save_txt(obj, path):\n    with open(path, 'w') as file:\n        file.write(obj)\n\ndef save_top_words_txt(top_words, path):\n    with open(os.path.join(path, 'top_words.txt'), 'w') as file:\n        for i, time in enumerate(top_words):\n            file.write(f'================= Time {i} ================= \\n')\n            for j, topic in enumerate(time):\n                file.write(f'================= Topic {j} ================= \\n')\n                file.write(f'{topic}')\n                file.write('\\n')\n            file.write('\\n')\n\ndef save_json(obj, path):\n    with open(path, 'w') as file:\n        json.dump(obj, file)\n\ndef save_joblib(obj, path):\n    joblib.dump(obj, path)\n\ndef get_desc(num_topics, rho_size, en_units, eta_hidden_size, enc_drop, eta_nlayers, eta_dropout, delta, theta_act, learning_rate, epochs):\n    return f'Trainig model with hyperparameters: \\n num_topics (K):  {num_topics} rho_size: {rho_size} \\n en_units: {en_units} \\n eta_hidden_size: {eta_hidden_size} \\n enc_drop: {eta_dropout} \\n eta_nlayers: {eta_nlayers} \\n eta_dropou: {eta_dropout} \\n delta: {delta} \\n theta_act: {theta_act} \\n learning_rate: {learning_rate} \\n epochs: {epochs}'\n\ndef get_hyperparameters_json(config):\n    return { \n        \"num_topics\" : config['num_topics'],\n        \"rho_size\": config['rho_size'],\n        \"en_units\" : config['en_units'],\n        \"eta_hidden_size\" : config['eta_hidden_size'],\n        \"enc_drop\": config['enc_drop'],\n        \"eta_nlayers\" : config['eta_nlayers'],\n        \"eta_dropou\" : config['eta_dropout'],\n        \"delta\" : config['delta'],\n        \"theta_act\" : config['theta_act'],\n        \"learning_rate\": config['learning_rate'],\n        \"epochs\": config['epochs']}\n    \n# def get_hyperparameter_space():\n    # with open('./hyperparameter_space.json', 'r') as f:\n        # return json.load(f)\n\ndef get_hyperparameter_space():\n    #with open(\"hyperparameter_space.json\", 'r') as f:\n        #return json.load(f)\n    return {\n        \"num_topics\": [20, 50, 100],\n        \"rho_size\": [200, 300, 400],\n        \"en_units\": [400, 800, 1200],\n        \"eta_nlayers\": [2, 3, 4],\n        \"delta\": [0.001, 0.005, 0.01, 0.05],\n        \"theta_act\": ['anh', 'softplus', 'relu', 'rrelu', 'leakyrelu', 'elu', 'selu', 'glu'],\n        \"eta_hidden_size\": [100, 200, 300],\n    \n        # Parametros del optimizador\n        \n        \"enc_drop\": [0.0, 0.2, 0.3, 0.5],\n        \"eta_dropout\": [0.0, 0.2, 0.3, 0.5],\n        \"learning_rate\": [1e-3, 5e-4, 0.02],\n        \"epochs\": [200, 400, 800]\n    }\n\ndef get_default_config():\n    return { \n        \"num_topics\" : 50,\n        \"rho_size\": 300,\n        \"en_units\" : 800,\n        \"eta_hidden_size\" : 200,\n        \"enc_drop\": 0.0,\n        \"eta_nlayers\" : 3,\n        \"eta_dropout\" : 0.0,\n        \"delta\" : 0.005,\n        \"theta_act\" : 'relu',\n        \"learning_rate\": 0.005,\n        \"epochs\": 100}\n\ndef random_configuration(hyperparameter_space):\n    return {\n        'num_topics': random.choice(hyperparameter_space[\"num_topics\"]),\n        'rho_size': random.choice(hyperparameter_space[\"rho_size\"]),\n        'en_units': random.choice(hyperparameter_space[\"en_units\"]),\n        'eta_hidden_size': random.choice(hyperparameter_space[\"eta_hidden_size\"]),\n        'enc_drop': random.choice(hyperparameter_space[\"enc_drop\"]),\n        'eta_nlayers': random.choice(hyperparameter_space[\"eta_nlayers\"]),\n        'eta_dropout': random.choice(hyperparameter_space[\"eta_dropout\"]),\n        'delta': random.choice(hyperparameter_space[\"delta\"]),\n        'theta_act': random.choice(hyperparameter_space[\"theta_act\"]),\n        'learning_rate': random.choice(hyperparameter_space[\"learning_rate\"]),\n        'epochs': random.choice(hyperparameter_space[\"epochs\"])}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T03:29:14.019261Z","iopub.execute_input":"2025-02-20T03:29:14.019596Z","iopub.status.idle":"2025-02-20T03:29:14.030404Z","shell.execute_reply.started":"2025-02-20T03:29:14.019567Z","shell.execute_reply":"2025-02-20T03:29:14.029333Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"### --------------------------------------------------------","metadata":{}},{"cell_type":"code","source":"def save_result(top_words, trainer, config, metrics_json):\n    global samples \n    path = os.path.join(output_dir, f'{samples}')\n    os.makedirs(path, exist_ok=True)\n\n    try:\n        save_top_words_txt(top_words, path)\n        save_json(config, os.path.join(path, 'hyperparameters.json'))\n        save_json(metrics_json, os.path.join(path, 'metrics_json.json'))\n        save_json({\"config\": config, \"metrics\": metrics_json}, os.path.join(path, 'metrics_config.json'))\n        #save_joblib(trainer, os.path.join(path, 'trainer.joblib'))\n        save_joblib(top_words, os.path.join(path, 'top_words.joblib'))\n    except Exception as e:\n        traceback.print_exc()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T03:29:20.418480Z","iopub.execute_input":"2025-02-20T03:29:20.418805Z","iopub.status.idle":"2025-02-20T03:29:20.423775Z","shell.execute_reply.started":"2025-02-20T03:29:20.418783Z","shell.execute_reply":"2025-02-20T03:29:20.422939Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import traceback\n\ndef evaluate_configuration(config):\n    global samples, tested_configs, output_dir\n    \n    config_key = tuple(config.values())\n                       \n    if config_key in tested_configs.keys():\n        return tested_configs[config_key]\n    \n    model = DETMFixed(\n            num_topics=config['num_topics'], \n            vocab_size=dataset.vocab_size,\n            num_times=dataset.num_times,\n            train_size=dataset.train_size,\n            train_time_wordfreq=dataset.train_time_wordfreq,\n            train_WE=False, \n            pretrained_WE=dataset.pretrained_WE, \n            en_units=config['en_units'], \n            eta_hidden_size=config['eta_hidden_size'], \n            rho_size=config['rho_size'], \n            enc_drop=config['enc_drop'], \n            eta_nlayers=config['eta_nlayers'], \n            eta_dropout=config['eta_dropout'], \n            delta=config['delta'], \n            theta_act=config['theta_act'],\n            device=device)\n\n    model = model.to(device)\n    trainer = topmost.DynamicTrainer(model, dataset, epochs=config['epochs'], learning_rate=config['learning_rate'], verbose=False)\n    top_words, train_theta = trainer.train()\n    \n    try:\n        metrics_json, dynamic_TC, dynamic_TD, clustering, classification = eval(trainer, top_words)\n        tested_configs[config_key] = {\"dynamic_TC\": dynamic_TC, \"dynamic_TD\": dynamic_TD}\n        save_result(top_words, trainer, config, metrics_json)\n        samples += 1\n    except Exception as e:\n        tested_configs[config_key] = {\"dynamic_TC\": float('-inf'), \"dynamic_TD\": float('-inf')}\n        print(e)\n        \n    save_joblib(tested_configs, os.path.join(output_dir, 'tested_configs.joblib'))\n    \n    return tested_configs[config_key]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T04:14:16.259267Z","iopub.execute_input":"2025-02-20T04:14:16.259643Z","iopub.status.idle":"2025-02-20T04:14:16.267530Z","shell.execute_reply.started":"2025-02-20T04:14:16.259610Z","shell.execute_reply":"2025-02-20T04:14:16.266516Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"def key_func(value):\n    try:\n        return 0.5 * value[1][\"dynamic_TC\"] + 0.5 * value[1][\"dynamic_TD\"]\n    except: \n        return value[1]\n\ndef evolutionary_search(search_space, generations=10, mutation_rate=0.1, population_size=20, population=None, generation_count=0):\n    global samples\n    \n    if not population:\n        population = [random_configuration(search_space) for _ in range(population_size - 1)]\n        population.append(get_default_config())\n\n    # print(population)\n    \n    for generation in range(generation_count, generations):\n        scores = [(config, evaluate_configuration(config)) for config in population]\n        scores.sort(key=key_func, reverse=True)  \n\n        print(f\"🧬 Generación {generation + 1}, mejor resultado: {scores[0][1]}\")\n        \n        num_parents = population_size // 2\n        parents = [config for config, _ in scores[:num_parents]]\n        \n        children = []\n        while len(children) < population_size - num_parents:\n            parent_1, parent_2 = random.sample(parents, 2)\n            child = {key: random.choice([parent_1[key], parent_2[key]]) for key in search_space.keys()}\n            \n            if random.random() < mutation_rate:\n                param_to_mutate = random.choice(list(search_space.keys()))\n                print(param_to_mutate)\n                child[param_to_mutate] = random.choice(search_space[param_to_mutate])\n            \n            children.append(child)\n        \n        population = parents + children\n        joblib.dump(population, os.path.join(output_dir, 'population.joblib'))\n    \n    best_config, best_score = max(scores, key=key_func)\n    return best_config, best_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T04:20:28.089818Z","iopub.execute_input":"2025-02-20T04:20:28.090260Z","iopub.status.idle":"2025-02-20T04:20:28.098316Z","shell.execute_reply.started":"2025-02-20T04:20:28.090230Z","shell.execute_reply":"2025-02-20T04:20:28.097544Z"}},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":"## Main","metadata":{}},{"cell_type":"code","source":"device = \"cuda\"  # or \"cpu\"\ndataset_dir = \"/kaggle/input/revista-de-ciencias-mdicas-de-la-habana-cuba\"\noutput_dir = \"./results\"\nos.makedirs(output_dir, exist_ok=True)\ndataset = topmost.data.DynamicDataset(dataset_dir, batch_size=200, read_labels=True, device=device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T03:29:38.114770Z","iopub.execute_input":"2025-02-20T03:29:38.115065Z","iopub.status.idle":"2025-02-20T03:29:40.126240Z","shell.execute_reply.started":"2025-02-20T03:29:38.115043Z","shell.execute_reply":"2025-02-20T03:29:40.125524Z"}},"outputs":[{"name":"stdout","text":"train size:  1208\ntest size:  658\nvocab size:  19384\naverage length: 1335.378\nnum of each time slice:  22 [20 34 46 41 56 20 76 58 43 54 83 71 64 67 63 60 55 83 75 58 57 24]\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"output_dir = \"./results\"\nos.makedirs(output_dir, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T03:29:44.416535Z","iopub.execute_input":"2025-02-20T03:29:44.416910Z","iopub.status.idle":"2025-02-20T03:29:44.421085Z","shell.execute_reply.started":"2025-02-20T03:29:44.416879Z","shell.execute_reply":"2025-02-20T03:29:44.420038Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"import os\nimport json\n\ngeneration = 0\n\nresults_path = [dir_.path for dir_ in os.scandir(output_dir) if not dir_.is_file()]\nsamples = len(results_path)\n\nprint(len(results_path))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T03:29:55.971540Z","iopub.execute_input":"2025-02-20T03:29:55.971887Z","iopub.status.idle":"2025-02-20T03:29:55.977495Z","shell.execute_reply.started":"2025-02-20T03:29:55.971858Z","shell.execute_reply":"2025-02-20T03:29:55.976813Z"}},"outputs":[{"name":"stdout","text":"88\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import joblib\npopulation_size = 50\n# population = None\n# population = joblib.load('/kaggle/input/datos-de-inicio-del-entrenamiento/population.joblib')\npopulation = joblib.load('/kaggle/working/results/population.joblib')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T03:36:46.669231Z","iopub.execute_input":"2025-02-20T03:36:46.669574Z","iopub.status.idle":"2025-02-20T03:36:46.675953Z","shell.execute_reply.started":"2025-02-20T03:36:46.669552Z","shell.execute_reply":"2025-02-20T03:36:46.675058Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"import joblib\n# tested_configs = dict()\n# tested_configs = joblib.load('/kaggle/input/datos-de-inicio-del-entrenamiento/tested_configs.joblib')\ntested_configs = joblib.load('/kaggle/working/results/tested_configs.joblib')\n# print(tested_configs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T04:13:28.746848Z","iopub.execute_input":"2025-02-20T04:13:28.747166Z","iopub.status.idle":"2025-02-20T04:13:28.753315Z","shell.execute_reply.started":"2025-02-20T04:13:28.747144Z","shell.execute_reply":"2025-02-20T04:13:28.752452Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"hyperparameter_space = get_hyperparameter_space()\n\nbest_config, best_score = evolutionary_search(hyperparameter_space, population_size=population_size, generations=100, mutation_rate=0.2, population=population, generation_count=generation)\nprint(best_config)\nprint(best_score)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T04:20:35.371577Z","iopub.execute_input":"2025-02-20T04:20:35.371949Z","iopub.status.idle":"2025-02-20T04:20:35.499151Z","shell.execute_reply.started":"2025-02-20T04:20:35.371921Z","shell.execute_reply":"2025-02-20T04:20:35.498445Z"}},"outputs":[{"name":"stdout","text":"🧬 Generación 1, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nrho_size\neta_nlayers\ntheta_act\nepochs\nrho_size\n🧬 Generación 2, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\ndelta\nenc_drop\nnum_topics\nlearning_rate\nlearning_rate\ntheta_act\n🧬 Generación 3, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nen_units\neta_dropout\nenc_drop\n🧬 Generación 4, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nenc_drop\ntheta_act\n🧬 Generación 5, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nlearning_rate\nenc_drop\nnum_topics\neta_dropout\neta_nlayers\nen_units\nrho_size\nnum_topics\n🧬 Generación 6, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nrho_size\nnum_topics\ntheta_act\nlearning_rate\nlearning_rate\n🧬 Generación 7, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nenc_drop\nrho_size\nnum_topics\nrho_size\ndelta\n🧬 Generación 8, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\neta_nlayers\nlearning_rate\neta_nlayers\n🧬 Generación 9, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nnum_topics\neta_dropout\n🧬 Generación 10, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\neta_nlayers\nen_units\neta_hidden_size\n🧬 Generación 11, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nrho_size\nepochs\nenc_drop\ndelta\nlearning_rate\nenc_drop\nlearning_rate\ntheta_act\nrho_size\n🧬 Generación 12, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\neta_nlayers\nnum_topics\nrho_size\nepochs\nenc_drop\ndelta\n🧬 Generación 13, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\neta_hidden_size\ntheta_act\nepochs\neta_nlayers\neta_dropout\nenc_drop\n🧬 Generación 14, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\neta_dropout\nrho_size\nenc_drop\n🧬 Generación 15, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nrho_size\nen_units\neta_nlayers\nen_units\n🧬 Generación 16, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\neta_hidden_size\nlearning_rate\nepochs\nrho_size\ntheta_act\nenc_drop\nlearning_rate\nenc_drop\n🧬 Generación 17, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nenc_drop\ndelta\nnum_topics\n🧬 Generación 18, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nepochs\nen_units\neta_hidden_size\neta_hidden_size\nen_units\ntheta_act\nrho_size\n🧬 Generación 19, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nnum_topics\neta_dropout\nrho_size\ntheta_act\neta_nlayers\ndelta\ndelta\n🧬 Generación 20, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nrho_size\nen_units\neta_nlayers\neta_dropout\neta_hidden_size\n🧬 Generación 21, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\ndelta\nenc_drop\nepochs\n🧬 Generación 22, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nnum_topics\nnum_topics\neta_dropout\n🧬 Generación 23, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\neta_nlayers\nlearning_rate\nen_units\neta_dropout\nrho_size\n🧬 Generación 24, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nen_units\ndelta\neta_hidden_size\nnum_topics\nen_units\n🧬 Generación 25, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nen_units\ndelta\n🧬 Generación 26, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nenc_drop\neta_hidden_size\neta_dropout\neta_hidden_size\neta_nlayers\n🧬 Generación 27, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\neta_dropout\n🧬 Generación 28, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nrho_size\nrho_size\neta_nlayers\nenc_drop\ntheta_act\ndelta\neta_hidden_size\ndelta\n🧬 Generación 29, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nen_units\nenc_drop\nepochs\nlearning_rate\neta_hidden_size\n🧬 Generación 30, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nenc_drop\neta_hidden_size\nepochs\ntheta_act\nen_units\nen_units\nenc_drop\nlearning_rate\nrho_size\n🧬 Generación 31, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\ndelta\nnum_topics\neta_dropout\nlearning_rate\nrho_size\n🧬 Generación 32, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\neta_nlayers\nrho_size\nnum_topics\nrho_size\nlearning_rate\n🧬 Generación 33, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nen_units\nlearning_rate\n🧬 Generación 34, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nlearning_rate\neta_nlayers\nepochs\ndelta\nepochs\nrho_size\nrho_size\n🧬 Generación 35, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\neta_dropout\nnum_topics\nenc_drop\nen_units\n🧬 Generación 36, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nnum_topics\nlearning_rate\nepochs\n🧬 Generación 37, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nepochs\nepochs\ndelta\ndelta\nnum_topics\neta_nlayers\neta_nlayers\n🧬 Generación 38, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\neta_nlayers\nepochs\neta_nlayers\nenc_drop\n🧬 Generación 39, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\ndelta\nrho_size\ndelta\nenc_drop\n🧬 Generación 40, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\neta_nlayers\nepochs\neta_dropout\neta_dropout\nepochs\nrho_size\n🧬 Generación 41, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nrho_size\nlearning_rate\n🧬 Generación 42, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\neta_hidden_size\nnum_topics\nlearning_rate\n🧬 Generación 43, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\neta_hidden_size\nenc_drop\n🧬 Generación 44, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nenc_drop\nnum_topics\ntheta_act\neta_nlayers\ntheta_act\n🧬 Generación 45, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\neta_dropout\ndelta\nepochs\ndelta\nenc_drop\n🧬 Generación 46, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\neta_hidden_size\nlearning_rate\nnum_topics\ndelta\nen_units\nrho_size\nepochs\n🧬 Generación 47, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nrho_size\nepochs\ntheta_act\neta_nlayers\nnum_topics\nrho_size\nnum_topics\n🧬 Generación 48, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nrho_size\nepochs\neta_dropout\neta_nlayers\nepochs\neta_dropout\n🧬 Generación 49, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\ndelta\nnum_topics\nen_units\ndelta\neta_nlayers\n🧬 Generación 50, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\ndelta\neta_hidden_size\neta_nlayers\nrho_size\ntheta_act\nenc_drop\ndelta\n🧬 Generación 51, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\neta_dropout\neta_nlayers\ntheta_act\neta_hidden_size\neta_dropout\n🧬 Generación 52, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\neta_nlayers\ndelta\nrho_size\nen_units\neta_nlayers\nepochs\ndelta\n🧬 Generación 53, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nen_units\neta_nlayers\nnum_topics\nepochs\ndelta\n🧬 Generación 54, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nepochs\nen_units\n🧬 Generación 55, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\neta_dropout\nlearning_rate\nrho_size\n🧬 Generación 56, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nrho_size\nen_units\nnum_topics\neta_dropout\nepochs\nnum_topics\n🧬 Generación 57, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\neta_hidden_size\ntheta_act\neta_hidden_size\nnum_topics\n🧬 Generación 58, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\ntheta_act\ntheta_act\nrho_size\nepochs\n🧬 Generación 59, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nrho_size\nrho_size\n🧬 Generación 60, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nepochs\neta_hidden_size\nepochs\nenc_drop\nen_units\ntheta_act\nen_units\ntheta_act\neta_dropout\n🧬 Generación 61, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nlearning_rate\nrho_size\ndelta\nepochs\nenc_drop\n🧬 Generación 62, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nlearning_rate\ndelta\neta_nlayers\ndelta\nrho_size\n🧬 Generación 63, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\ntheta_act\nenc_drop\nen_units\nrho_size\nrho_size\nlearning_rate\neta_nlayers\n🧬 Generación 64, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\n🧬 Generación 65, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\ntheta_act\ndelta\nenc_drop\nenc_drop\ndelta\n🧬 Generación 66, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nrho_size\ntheta_act\n🧬 Generación 67, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nen_units\nenc_drop\neta_hidden_size\nnum_topics\neta_dropout\n🧬 Generación 68, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nlearning_rate\ndelta\nrho_size\nenc_drop\nnum_topics\neta_hidden_size\n🧬 Generación 69, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nrho_size\neta_dropout\nenc_drop\neta_hidden_size\nen_units\neta_hidden_size\nnum_topics\nnum_topics\ntheta_act\nrho_size\n🧬 Generación 70, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nepochs\nepochs\ntheta_act\n🧬 Generación 71, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nlearning_rate\nlearning_rate\nnum_topics\ntheta_act\neta_nlayers\nnum_topics\ntheta_act\ndelta\neta_hidden_size\n🧬 Generación 72, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nnum_topics\nrho_size\n🧬 Generación 73, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nrho_size\ntheta_act\nenc_drop\nen_units\n🧬 Generación 74, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nenc_drop\nrho_size\neta_dropout\nrho_size\neta_dropout\nnum_topics\n🧬 Generación 75, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\neta_nlayers\nepochs\nepochs\nlearning_rate\n🧬 Generación 76, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nlearning_rate\neta_nlayers\n🧬 Generación 77, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nepochs\nenc_drop\nenc_drop\nrho_size\n🧬 Generación 78, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nenc_drop\ndelta\nepochs\ntheta_act\nrho_size\n🧬 Generación 79, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\neta_hidden_size\neta_hidden_size\nenc_drop\nen_units\nnum_topics\nenc_drop\ndelta\n🧬 Generación 80, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nen_units\nepochs\n🧬 Generación 81, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\neta_hidden_size\neta_nlayers\neta_dropout\nlearning_rate\ndelta\nenc_drop\neta_nlayers\n🧬 Generación 82, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nlearning_rate\neta_hidden_size\nnum_topics\n🧬 Generación 83, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\ntheta_act\nlearning_rate\nrho_size\nlearning_rate\n🧬 Generación 84, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nnum_topics\neta_hidden_size\nrho_size\n🧬 Generación 85, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\ndelta\nrho_size\nenc_drop\n🧬 Generación 86, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nlearning_rate\nlearning_rate\neta_hidden_size\neta_nlayers\nnum_topics\nepochs\neta_hidden_size\neta_hidden_size\nrho_size\n🧬 Generación 87, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nenc_drop\nen_units\n🧬 Generación 88, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\neta_dropout\ntheta_act\ntheta_act\nepochs\nrho_size\nrho_size\n🧬 Generación 89, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\neta_nlayers\nlearning_rate\nepochs\nrho_size\n🧬 Generación 90, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nen_units\neta_dropout\nrho_size\neta_dropout\n🧬 Generación 91, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nen_units\nlearning_rate\nrho_size\nrho_size\ntheta_act\nepochs\n🧬 Generación 92, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\neta_hidden_size\nlearning_rate\neta_dropout\neta_nlayers\ntheta_act\neta_dropout\ntheta_act\nen_units\n🧬 Generación 93, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nrho_size\neta_nlayers\nepochs\nepochs\ntheta_act\nlearning_rate\n🧬 Generación 94, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\neta_hidden_size\nlearning_rate\nepochs\nlearning_rate\nnum_topics\nen_units\nen_units\n🧬 Generación 95, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\ndelta\neta_hidden_size\nrho_size\nlearning_rate\n🧬 Generación 96, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\neta_hidden_size\nrho_size\neta_hidden_size\nnum_topics\neta_nlayers\n🧬 Generación 97, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\neta_nlayers\nenc_drop\neta_dropout\nepochs\n🧬 Generación 98, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\neta_hidden_size\ntheta_act\nnum_topics\neta_hidden_size\nrho_size\neta_nlayers\n🧬 Generación 99, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\nenc_drop\neta_nlayers\ndelta\nlearning_rate\ntheta_act\nenc_drop\neta_hidden_size\ndelta\n🧬 Generación 100, mejor resultado: {'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\ndelta\neta_nlayers\nrho_size\n{'num_topics': 20, 'rho_size': 400, 'en_units': 1200, 'eta_hidden_size': 300, 'enc_drop': 0.2, 'eta_nlayers': 4, 'eta_dropout': 0.0, 'delta': 0.001, 'theta_act': 'selu', 'learning_rate': 0.0005, 'epochs': 400}\n{'dynamic_TC': 0.4475481219000681, 'dynamic_TD': 0.6240909090909091}\n","output_type":"stream"}],"execution_count":40},{"cell_type":"markdown","source":"## Evaluando resultados","metadata":{}},{"cell_type":"code","source":"import os\n\noutput_dir = '/kaggle/working/results'\nresults_path = [dir_.path for dir_ in os.scandir(output_dir) if not dir_.is_file()]\n\nprint(results_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T07:42:06.550763Z","iopub.execute_input":"2025-02-02T07:42:06.551058Z","iopub.status.idle":"2025-02-02T07:42:06.556443Z","shell.execute_reply.started":"2025-02-02T07:42:06.551034Z","shell.execute_reply":"2025-02-02T07:42:06.555581Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"old_tc = float('-inf')\nTC = []\nold_td = float('-inf')\nTD = []\nold_tc_td = float('-inf')\nTC_TD = []\n\nfor path in results_path:\n    with open(os.path.join(path, 'metrics_json.json'), 'r') as file:\n        metrics = json.load(file)\n\n    cr_tc = metrics[\"dynamic_TC\"]\n    if cr_tc >= old_tc:\n        with open(os.path.join(path, 'metrics_config.json'), 'r') as file:\n            new = json.load(file)\n        if cr_tc == old_tc:\n            TC.append((new, path))\n        else:\n            old_tc = cr_tc\n            TC = [(new, path)]\n\n    cr_td = metrics[\"dynamic_TD\"]\n    if cr_td >= old_td:\n        with open(os.path.join(path, 'metrics_config.json'), 'r') as file:\n            new = json.load(file)\n        if cr_td == old_td:\n            TD.append((new, path))\n        else:\n            old_td = cr_td\n            TD = [(new, path)]\n\n    cr_tc_td = 0.5 * cr_tc + 0.5 * cr_td\n    if cr_tc_td >= old_tc_td:\n        with open(os.path.join(path, 'metrics_config.json'), 'r') as file:\n            new = json.load(file)\n        if cr_tc_td == old_tc_td:\n            TC_TD.append((new, path))\n        else:\n            old_tc_td = cr_tc_td\n            TC_TD = [(new, path)]\n\nprint(TC)\nprint(len(TC))\nprint('-------------------------------------')\nprint(TD)\nprint(len(TD))\nprint('-------------------------------------')\nprint(TC_TD)\nprint(len(TC_TD))\n\nbest_results_path = './best_results'\nos.makedirs(best_results_path, exist_ok=True)\nsave_json(TC, os.path.join(best_results_path, 'best_tc.json'))\nsave_json(TD, os.path.join(best_results_path, 'best_td.json'))\nsave_json(TC_TD, os.path.join(best_results_path, 'best_tc_td.json'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T07:49:47.532635Z","iopub.execute_input":"2025-02-02T07:49:47.532911Z","iopub.status.idle":"2025-02-02T07:49:47.548155Z","shell.execute_reply.started":"2025-02-02T07:49:47.532888Z","shell.execute_reply":"2025-02-02T07:49:47.547450Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!zip -r best_results/best_results.zip /kaggle/working/results/13","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T07:57:05.222049Z","iopub.execute_input":"2025-02-02T07:57:05.222408Z","iopub.status.idle":"2025-02-02T07:57:05.348056Z","shell.execute_reply.started":"2025-02-02T07:57:05.222380Z","shell.execute_reply":"2025-02-02T07:57:05.347114Z"}},"outputs":[],"execution_count":null}]}