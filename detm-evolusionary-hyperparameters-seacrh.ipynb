{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10462241,"sourceType":"datasetVersion","datasetId":6460784},{"sourceId":218535353,"sourceType":"kernelVersion"},{"sourceId":218634361,"sourceType":"kernelVersion"}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install topmost","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:06:10.272375Z","iopub.execute_input":"2025-01-30T05:06:10.272669Z","iopub.status.idle":"2025-01-30T05:06:52.218407Z","shell.execute_reply.started":"2025-01-30T05:06:10.272644Z","shell.execute_reply":"2025-01-30T05:06:52.217154Z"}},"outputs":[{"name":"stdout","text":"Collecting topmost\n  Downloading topmost-1.0.1-py3-none-any.whl (93 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.6/93.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting gensim>=4.2.0\n  Downloading gensim-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: torchvision>=0.14.1 in /usr/local/lib/python3.10/site-packages (from topmost) (0.20.0)\nCollecting fastopic>=1.0.0\n  Downloading fastopic-1.0.0-py3-none-any.whl (89 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.6/89.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.10/site-packages (from topmost) (1.6.1)\nRequirement already satisfied: tqdm>=4.66.0 in /usr/local/lib/python3.10/site-packages (from topmost) (4.67.1)\nCollecting bertopic>=0.15.0\n  Downloading bertopic-0.16.4-py3-none-any.whl (143 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.7/143.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting numpy<1.27.0\n  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting scipy<=1.10.1\n  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting sentence-transformers<3.0.0,>=2.6.0\n  Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/site-packages (from bertopic>=0.15.0->topmost) (2.2.3)\nCollecting plotly>=4.7.0\n  Downloading plotly-6.0.0-py3-none-any.whl (14.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting umap-learn>=0.5.0\n  Downloading umap_learn-0.5.7-py3-none-any.whl (88 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting hdbscan>=0.8.29\n  Downloading hdbscan-0.8.40-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting smart-open>=1.8.1\n  Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn>=0.24.2->topmost) (3.5.0)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn>=0.24.2->topmost) (1.4.2)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.6.0->topmost) (2.5.0)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.6.0->topmost) (11.1.0)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.6.0->topmost) (0.27.1)\nRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.6.0->topmost) (4.48.0)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (9.1.0.70)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (10.3.5.147)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (12.3.1.170)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (12.4.127)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (11.6.1.9)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (3.1.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (3.16.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (12.4.127)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (11.2.1.3)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (1.13.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (2.21.5)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (3.1.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (4.12.2)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (12.4.5.8)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (2024.12.0)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (12.4.127)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (12.4.127)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (1.3.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (2.32.3)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (6.0.2)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (24.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas>=1.1.5->bertopic>=0.15.0->topmost) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas>=1.1.5->bertopic>=0.15.0->topmost) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas>=1.1.5->bertopic>=0.15.0->topmost) (2024.2)\nCollecting narwhals>=1.15.1\n  Downloading narwhals-1.24.1-py3-none-any.whl (309 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.5/309.5 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: wrapt in /usr/local/lib/python3.10/site-packages (from smart-open>=1.8.1->gensim>=4.2.0->topmost) (1.17.1)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (0.5.2)\nCollecting numba>=0.51.2\n  Downloading numba-0.61.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting pynndescent>=0.5\n  Downloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting llvmlite<0.45,>=0.44.0dev0\n  Downloading llvmlite-0.44.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic>=0.15.0->topmost) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (3.0.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (2024.12.14)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (3.10)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (3.4.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (2.3.0)\nInstalling collected packages: smart-open, numpy, narwhals, llvmlite, scipy, plotly, numba, gensim, pynndescent, hdbscan, umap-learn, sentence-transformers, bertopic, fastopic, topmost\n  Attempting uninstall: numpy\n    Found existing installation: numpy 2.0.2\n    Uninstalling numpy-2.0.2:\n      Successfully uninstalled numpy-2.0.2\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.15.1\n    Uninstalling scipy-1.15.1:\n      Successfully uninstalled scipy-1.15.1\nSuccessfully installed bertopic-0.16.4 fastopic-1.0.0 gensim-4.3.3 hdbscan-0.8.40 llvmlite-0.44.0 narwhals-1.24.1 numba-0.61.0 numpy-1.26.4 plotly-6.0.0 pynndescent-0.5.13 scipy-1.10.1 sentence-transformers-2.7.0 smart-open-7.1.0 topmost-1.0.1 umap-learn-0.5.7\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import topmost\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom topmost.models.dynamic.DETM import DETM\nfrom topmost import eva\nimport numpy as np\nimport itertools\nimport json\nimport joblib\nfrom tqdm import tqdm\nimport os\nimport json\nimport random","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:06:52.219042Z","iopub.execute_input":"2025-01-30T05:06:52.219274Z","iopub.status.idle":"2025-01-30T05:07:15.543325Z","shell.execute_reply.started":"2025-01-30T05:06:52.219249Z","shell.execute_reply":"2025-01-30T05:07:15.541454Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtopmost\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/topmost/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m data\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m eva\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m trainers\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/topmost/data/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasic_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BasicDataset\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasic_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RawDataset\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcrosslingual_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrosslingualDataset\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/topmost/data/basic_dataset.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m issparse\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/scipy/__init__.py:78\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m _fun \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_fun, _types\u001b[38;5;241m.\u001b[39mModuleType):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/numpy/__init__.py:364\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    363\u001b[0m     x \u001b[38;5;241m=\u001b[39m ones(\u001b[38;5;241m2\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mfloat32)\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(x\u001b[38;5;241m.\u001b[39mdot(x) \u001b[38;5;241m-\u001b[39m float32(\u001b[38;5;241m2.0\u001b[39m)) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-5\u001b[39m:\n\u001b[1;32m    365\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m()\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m:\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy.rec'"],"ename":"ModuleNotFoundError","evalue":"No module named 'numpy.rec'","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"from gensim.corpora import Dictionary\nfrom gensim.models import CoherenceModel\nfrom topmost.data.file_utils import split_text_word","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.544126Z","iopub.status.idle":"2025-01-30T05:07:15.544629Z","shell.execute_reply.started":"2025-01-30T05:07:15.544322Z","shell.execute_reply":"2025-01-30T05:07:15.544365Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Funciones externas","metadata":{}},{"cell_type":"code","source":"def get_theta_redefined(self, bows, times, eta=None): ## amortized inference\n        \"\"\"Returns the topic proportions.\n        \"\"\"\n        # normalized_bows = bows / bows.sum(1, keepdims=True)\n        # print(\"🍀 Before\", normalized_bows)\n\n        normalized_bows = bows / (bows.sum(1, keepdims=True) + 1e-12)\n        # print(\"🍀 After\", normalized_bows)\n    \n        if eta is None and self.training is False:\n            eta, kl_eta = self.get_eta(self.rnn_inp)\n\n        eta_td = eta[times]\n        inp = torch.cat([normalized_bows, eta_td], dim=1)\n        q_theta = self.q_theta(inp)\n        if self.enc_drop > 0:\n            q_theta = self.t_drop(q_theta)\n        mu_theta = self.mu_q_theta(q_theta)\n        logsigma_theta = self.logsigma_q_theta(q_theta)\n        z = self.reparameterize(mu_theta, logsigma_theta)\n        theta = F.softmax(z, dim=-1)\n        kl_theta = self.get_kl(mu_theta, logsigma_theta, eta_td, torch.zeros(self.num_topics).to(self.device))\n\n        if self.training:\n            return theta, kl_theta\n        else:\n            return theta\n\nDETM.get_theta = get_theta_redefined","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.545187Z","iopub.status.idle":"2025-01-30T05:07:15.545770Z","shell.execute_reply.started":"2025-01-30T05:07:15.545337Z","shell.execute_reply":"2025-01-30T05:07:15.545378Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class DETMFixed(DETM):\n    def __init__(self, vocab_size, num_times, train_size, train_time_wordfreq, num_topics=50, train_WE=True, pretrained_WE=None, en_units=800, eta_hidden_size=200, rho_size=300, enc_drop=0.0, eta_nlayers=3, eta_dropout=0.0, delta=0.005, theta_act='relu', device='cpu'):\n        super().__init__(vocab_size, num_times, train_size, train_time_wordfreq, num_topics, True, pretrained_WE, en_units, eta_hidden_size, rho_size, enc_drop, eta_nlayers, eta_dropout, delta, theta_act, device)\n        \n        ## define the word embedding matrix \\rho\n        if not self.train_WE:\n            rho = nn.Embedding(pretrained_WE.shape[1], pretrained_WE.shape[0])\n            rho.weight.data = torch.from_numpy(pretrained_WE)\n            self.rho = rho.weight.data.clone().float().to(self.device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.546751Z","iopub.status.idle":"2025-01-30T05:07:15.547890Z","shell.execute_reply.started":"2025-01-30T05:07:15.547158Z","shell.execute_reply":"2025-01-30T05:07:15.547205Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def _coherence_modified(reference_corpus, vocab, top_words, cv_type='c_v'):\n    # print('🍀')\n    \n    split_top_words = split_text_word(top_words)\n    num_top_words = len(split_top_words[0])\n    for item in split_top_words:\n        assert num_top_words == len(item)\n\n    split_reference_corpus = split_text_word(reference_corpus)\n    dictionary = Dictionary(split_text_word(vocab))\n\n    cm = CoherenceModel(texts=split_reference_corpus, dictionary=dictionary, topics=split_top_words, topn=num_top_words, coherence=cv_type)\n    cv_per_topic = cm.get_coherence_per_topic()\n    # print(f\"Coherence scores per topic: {cv_per_topic}\")\n\n    valid_scores = [score for score in cv_per_topic if not np.isnan(score)]\n    if not valid_scores:\n        raise ValueError(\"All coherence scores are NaN.\")\n    score = np.mean(valid_scores)\n\n    return score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.548795Z","iopub.status.idle":"2025-01-30T05:07:15.549654Z","shell.execute_reply.started":"2025-01-30T05:07:15.548961Z","shell.execute_reply":"2025-01-30T05:07:15.549006Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"eva.topic_coherence._coherence = _coherence_modified\n\ndef eval(dataset, trainer, top_words):\n    # get theta (doc-topic distributions)\n    train_theta, test_theta = trainer.export_theta()\n\n    train_times = dataset.train_times.cpu().numpy()\n    # compute topic coherence\n    dynamic_TC = eva.dynamic_coherence(dataset.train_texts, train_times, dataset.vocab, top_words, verbose=True)\n    print(\"dynamic_TC: \", dynamic_TC)\n\n    # compute topic diversity\n    dynamic_TD = eva.dynamic_diversity(top_words, dataset.train_bow.cpu().numpy(), train_times, dataset.vocab, verbose=False)\n    print(\"dynamic_TD: \", dynamic_TD)\n\n    # evaluate clustering\n    clustering = eva._clustering(test_theta, dataset.test_labels)\n    print(clustering)\n\n    # evaluate classification\n    classification = eva._cls(train_theta, test_theta, dataset.train_labels, dataset.test_labels)\n    print(classification)\n    \n    json = {\n        \"dynamic_TC\": dynamic_TC,\n        \"dynamic_TD\": dynamic_TD,\n        \"clustering\": clustering,\n        \"classification\": classification\n    }\n    \n    return json, dynamic_TC, dynamic_TD, clustering, classification","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.550232Z","iopub.status.idle":"2025-01-30T05:07:15.550732Z","shell.execute_reply.started":"2025-01-30T05:07:15.550371Z","shell.execute_reply":"2025-01-30T05:07:15.550419Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import joblib\nimport json\n\ndef save_txt(obj, path):\n    with open(path, 'w') as file:\n        file.write(obj)\n\ndef save_top_words_txt(top_words, path):\n    with open(os.path.join(path, 'top_words.txt'), 'w') as file:\n        for i, time in enumerate(top_words):\n            file.write(f'================= Time {i} ================= \\n')\n            for j, topic in enumerate(time):\n                file.write(f'================= Topic {j} ================= \\n')\n                file.write(f'{topic}')\n                file.write('\\n')\n            file.write('\\n')\n\ndef save_json(obj, path):\n    with open(path, 'w') as file:\n        json.dump(obj, file)\n\ndef save_joblib(obj, path):\n    joblib.dump(obj, path)\n\ndef get_desc(num_topics, rho_size, en_units, eta_hidden_size, enc_drop, eta_nlayers, eta_dropout, delta, theta_act, learning_rate, epochs):\n    return f'Trainig model with hyperparameters: \\n num_topics (K):  {num_topics} rho_size: {rho_size} \\n en_units: {en_units} \\n eta_hidden_size: {eta_hidden_size} \\n enc_drop: {eta_dropout} \\n eta_nlayers: {eta_nlayers} \\n eta_dropou: {eta_dropout} \\n delta: {delta} \\n theta_act: {theta_act} \\n learning_rate: {learning_rate} \\n epochs: {epochs}'\n\ndef get_hyperparameters_json(config):\n    return { \n        \"num_topics\" : config['num_topics'],\n        \"rho_size\": config['rho_size'],\n        \"en_units\" : config['en_units'],\n        \"eta_hidden_size\" : config['eta_hidden_size'],\n        \"enc_drop\": config['enc_drop'],\n        \"eta_nlayers\" : config['eta_nlayers'],\n        \"eta_dropou\" : config['eta_dropout'],\n        \"delta\" : config['delta'],\n        \"theta_act\" : config['theta_act'],\n        \"learning_rate\": config['learning_rate'],\n        \"epochs\": config['epochs']}\n    \n# def get_hyperparameter_space():\n    # with open('./hyperparameter_space.json', 'r') as f:\n        # return json.load(f)\n\ndef get_hyperparameter_space():\n    #with open(\"hyperparameter_space.json\", 'r') as f:\n        #return json.load(f)\n    return {\n        \"num_topics\": [20, 50, 100],\n        \"rho_size\": [200, 300, 400],\n        \"en_units\": [400, 800, 1200],\n        \"eta_nlayers\": [2, 3, 4],\n        \"delta\": [0.001, 0.005, 0.01, 0.05],\n        \"theta_act\": ['anh', 'softplus', 'relu', 'rrelu', 'leakyrelu', 'elu', 'selu', 'glu'],\n        \"eta_hidden_size\": [100, 200, 300],\n    \n        # Parametros del optimizador\n        \n        \"enc_drop\": [0.0, 0.2, 0.3, 0.5],\n        \"eta_dropout\": [0.0, 0.2, 0.3, 0.5],\n        \"learning_rate\": [1e-3, 5e-4, 0.02],\n        \"epochs\": [200, 400, 800]\n    }\n\ndef get_default_config():\n    return { \n        \"num_topics\" : 50,\n        \"rho_size\": 300,\n        \"en_units\" : 800,\n        \"eta_hidden_size\" : 200,\n        \"enc_drop\": 0.0,\n        \"eta_nlayers\" : 3,\n        \"eta_dropout\" : 0.0,\n        \"delta\" : 0.005,\n        \"theta_act\" : 'relu',\n        \"learning_rate\": 0.005,\n        \"epochs\": 100}\n\ndef random_configuration(hyperparameter_space):\n    return {\n        'num_topics': random.choice(hyperparameter_space[\"num_topics\"]),\n        'rho_size': random.choice(hyperparameter_space[\"rho_size\"]),\n        'en_units': random.choice(hyperparameter_space[\"en_units\"]),\n        'eta_hidden_size': random.choice(hyperparameter_space[\"eta_hidden_size\"]),\n        'enc_drop': random.choice(hyperparameter_space[\"enc_drop\"]),\n        'eta_nlayers': random.choice(hyperparameter_space[\"eta_nlayers\"]),\n        'eta_dropout': random.choice(hyperparameter_space[\"eta_dropout\"]),\n        'delta': random.choice(hyperparameter_space[\"delta\"]),\n        'theta_act': random.choice(hyperparameter_space[\"theta_act\"]),\n        'learning_rate': random.choice(hyperparameter_space[\"learning_rate\"]),\n        'epochs': random.choice(hyperparameter_space[\"epochs\"])}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.551450Z","iopub.status.idle":"2025-01-30T05:07:15.552109Z","shell.execute_reply.started":"2025-01-30T05:07:15.551606Z","shell.execute_reply":"2025-01-30T05:07:15.551647Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### --------------------------------------------------------","metadata":{}},{"cell_type":"code","source":"def save_result(top_words, trainer, config, metrics_json):\n    global samples \n    path = os.path.join(output_dir, f'{samples}')\n    os.makedirs(path, exist_ok=True)\n\n    try:\n        save_top_words_txt(top_words, path)\n        save_json(config, os.path.join(path, 'hyperparameters.json'))\n        save_json(metrics_json, os.path.join(path, 'metrics_json.json'))\n        save_joblib(trainer, os.path.join(path, 'trainer.joblib'))\n        save_joblib(top_words, os.path.join(path, 'top_words.joblib'))\n    except Exception as e:\n        traceback.print_exc()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.554205Z","iopub.status.idle":"2025-01-30T05:07:15.555053Z","shell.execute_reply.started":"2025-01-30T05:07:15.554404Z","shell.execute_reply":"2025-01-30T05:07:15.554450Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import traceback\n\ndef evaluate_configuration(config):\n    global samples, tested_configs, output_dir\n\n    if config.values() in tested_configs.keys():\n        return tested_configs[tuple(config.values())]\n    \n    model = DETMFixed(\n            num_topics=config['num_topics'], \n            vocab_size=dataset.vocab_size,\n            num_times=dataset.num_times,\n            train_size=dataset.train_size,\n            train_time_wordfreq=dataset.train_time_wordfreq,\n            train_WE=False, \n            pretrained_WE=dataset.pretrained_WE, \n            en_units=config['en_units'], \n            eta_hidden_size=config['eta_hidden_size'], \n            rho_size=config['rho_size'], \n            enc_drop=config['enc_drop'], \n            eta_nlayers=config['eta_nlayers'], \n            eta_dropout=config['eta_dropout'], \n            delta=config['delta'], \n            theta_act=config['theta_act'],\n            device=device)\n\n    model = model.to(device)\n    # trainer = topmost.DynamicTrainer(model, dataset, epochs=config['epochs'], learning_rate=config['learning_rate'], verbose=False)\n\n    try:\n        trainer = topmost.DynamicTrainer(model, dataset, epochs=config['epochs'], learning_rate=config['learning_rate'], verbose=False)\n        top_words, train_theta = trainer.train()\n        metrics_json, dynamic_TC, dynamic_TD, clustering, classification = eval(dataset, trainer, top_words)\n\n        save_result(top_words, trainer, config, metrics_json)\n\n        samples += 1\n    \n        # return 0.4 * dynamic_TC + 0.4 * dynamic_TD + 0.1 * clustering + 0.1 * classification\n        result = 0.5 * dynamic_TC + 0.5 * dynamic_TD\n\n    except Exception as e:\n        # print(f'❌ Error config {config}')\n        traceback.print_exc()\n        result = float('-inf')\n\n    tested_configs[tuple(config.values())] = result\n    joblib.dump(tested_configs, os.path.join(output_dir, 'tested_configs.joblib'))\n    return result\n ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.556320Z","iopub.status.idle":"2025-01-30T05:07:15.557516Z","shell.execute_reply.started":"2025-01-30T05:07:15.557009Z","shell.execute_reply":"2025-01-30T05:07:15.557058Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evolutionary_search(search_space, generations=10, mutation_rate=0.1, population_size=20, population=None, generation_count=0):\n    global samples\n    \n    if not population:\n        population = [random_configuration(search_space) for _ in range(population_size - 1)]\n        population.append(get_default_config())\n\n    # print(population)\n    \n    for generation in range(generation_count, generations):\n        scores = [(config, evaluate_configuration(config)) for config in population]\n        scores.sort(key=lambda value: value[1], reverse=True)  \n\n        joblib.dump(scores[0], f'best_per_generation_path_{generation}.joblib')\n        print(f\"🧬 Generación {generation + 1}, mejor resultado: {scores[0][1]:.4f}\")\n        \n        num_parents = population_size // 2\n        parents = [config for config, _ in scores[:num_parents]]\n        \n        children = []\n        while len(children) < population_size - num_parents:\n            parent_1, parent_2 = random.sample(parents, 2)\n            child = {key: random.choice([parent_1[key], parent_2[key]]) for key in search_space.keys()}\n            \n            if random.random() < mutation_rate:\n                param_to_mutate = random.choice(list(search_space[mutate_model_training].keys()))\n                print(param_to_mutate)\n                child[param_to_mutate] = random.choice(search_space[param_to_mutate])\n            \n            children.append(child)\n        \n        population = parents + children\n        joblib.dump(population, os.path.join(output_dir, 'population.joblib'))\n    \n    best_config, best_score = max(scores, key=lambda x: x[1])\n    return best_config, best_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.558826Z","iopub.status.idle":"2025-01-30T05:07:15.559301Z","shell.execute_reply.started":"2025-01-30T05:07:15.559005Z","shell.execute_reply":"2025-01-30T05:07:15.559050Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Main","metadata":{}},{"cell_type":"code","source":"device = \"cuda\"  # or \"cpu\"\ndataset_dir = \"/kaggle/input/revista-ciencias-mdicas-de-la-habana-cmed\"\noutput_dir = \"./results\"\nos.makedirs(output_dir, exist_ok=True)\ndataset = topmost.data.DynamicDataset(dataset_dir, batch_size=200, read_labels=True, device=device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.560158Z","iopub.status.idle":"2025-01-30T05:07:15.560663Z","shell.execute_reply.started":"2025-01-30T05:07:15.560300Z","shell.execute_reply":"2025-01-30T05:07:15.560342Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"output_dir = \"./results\"\nos.makedirs(output_dir, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.561441Z","iopub.status.idle":"2025-01-30T05:07:15.561846Z","shell.execute_reply.started":"2025-01-30T05:07:15.561601Z","shell.execute_reply":"2025-01-30T05:07:15.561644Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_json(path):\n    with open(os.path.join(path, 'metrics_config.json'), \"r\") as file:\n        return json.load(file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.562964Z","iopub.status.idle":"2025-01-30T05:07:15.563590Z","shell.execute_reply.started":"2025-01-30T05:07:15.563277Z","shell.execute_reply":"2025-01-30T05:07:15.563322Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\n\nresults_path = '/kaggle/working/results'\nresults_path = [dir_.path for dir_ in os.scandir(results_path) if not dir_.is_file()]\n\nprint(len(results_path))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.564437Z","iopub.status.idle":"2025-01-30T05:07:15.565030Z","shell.execute_reply.started":"2025-01-30T05:07:15.564590Z","shell.execute_reply":"2025-01-30T05:07:15.564630Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import joblib\n\n# population_size = 50\n# # population = None\n# population = [load_json(path) for path in results_path]\n# population.sort(key=lambda value: value[\"metrics\"][\"dynamic_TC\"] + value[\"metrics\"][\"dynamic_TD\"], reverse=True)\n# population = [item[\"config\"] for item in population[:population_size]]\n# print(population)\n# joblib.dump(population, os.path.join(output_dir, 'population.joblib'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.565733Z","iopub.status.idle":"2025-01-30T05:07:15.566496Z","shell.execute_reply.started":"2025-01-30T05:07:15.565869Z","shell.execute_reply":"2025-01-30T05:07:15.565915Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import joblib\npopulation_size = 50\n# population = None\npopulation = joblib.load(os.path.join(output_dir, 'population.joblib'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.567307Z","iopub.status.idle":"2025-01-30T05:07:15.567859Z","shell.execute_reply.started":"2025-01-30T05:07:15.567476Z","shell.execute_reply":"2025-01-30T05:07:15.567532Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import joblib\n# tested_configs = dict()\ntested_configs = joblib.load('/kaggle/working/results/tested_configs.joblib')\n# print(tested_configs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.568436Z","iopub.status.idle":"2025-01-30T05:07:15.569188Z","shell.execute_reply.started":"2025-01-30T05:07:15.568689Z","shell.execute_reply":"2025-01-30T05:07:15.568736Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_per_generation_path = './best_per_generation_path'\nos.makedirs(best_per_generation_path, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.570078Z","iopub.status.idle":"2025-01-30T05:07:15.571030Z","shell.execute_reply.started":"2025-01-30T05:07:15.570511Z","shell.execute_reply":"2025-01-30T05:07:15.570578Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"generation = len([dir_.path for dir_ in os.scandir(best_per_generation_path) if dir_.is_file()])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.572336Z","iopub.status.idle":"2025-01-30T05:07:15.572820Z","shell.execute_reply.started":"2025-01-30T05:07:15.572484Z","shell.execute_reply":"2025-01-30T05:07:15.572527Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"samples = len(results_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.574164Z","iopub.status.idle":"2025-01-30T05:07:15.575145Z","shell.execute_reply.started":"2025-01-30T05:07:15.574383Z","shell.execute_reply":"2025-01-30T05:07:15.574428Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"hyperparameter_space = get_hyperparameter_space()\n\nbest_config, best_score = evolutionary_search(hyperparameter_space, population_size=population_size, generations=100, mutation_rate=0.2, population=population, generation_count=generation)\nprint(best_config)\nprint(best_score)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.575931Z","iopub.status.idle":"2025-01-30T05:07:15.576592Z","shell.execute_reply.started":"2025-01-30T05:07:15.576242Z","shell.execute_reply":"2025-01-30T05:07:15.576290Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Evaluando resultados","metadata":{}},{"cell_type":"code","source":"import os\n\nresults_path = '/kaggle/working/results'\nresults_path = [dir_.path for dir_ in os.scandir(results_path) if not dir_.is_file()][0]\n# results_path = [dir_.path for dir_ in os.scandir(results_path) if not dir_.is_file()]\n\n# print(results_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.577164Z","iopub.status.idle":"2025-01-30T05:07:15.577937Z","shell.execute_reply.started":"2025-01-30T05:07:15.577326Z","shell.execute_reply":"2025-01-30T05:07:15.577368Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nfor result in results_path:\n    with open(os.path.join(result, 'hyperparameters.json'), 'r') as file:\n        config = json.load(file)\n\n    with open(os.path.join(result, 'metrics_json.json'), 'r') as file:\n        metrics = json.load(file)\n\n    with open(os.path.join(result, 'metrics_config.json'), 'w') as file:\n        json.dump({\"config\": config, \"metrics\": metrics}, file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.578780Z","iopub.status.idle":"2025-01-30T05:07:15.579216Z","shell.execute_reply.started":"2025-01-30T05:07:15.578931Z","shell.execute_reply":"2025-01-30T05:07:15.578975Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"file = 'trainer.joblib'\n    \nfor path in results_path:\n    file_path = os.path.join(path, file)\n    if os.path.isfile(file_path):\n        os.remove(file_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.579901Z","iopub.status.idle":"2025-01-30T05:07:15.580649Z","shell.execute_reply.started":"2025-01-30T05:07:15.580050Z","shell.execute_reply":"2025-01-30T05:07:15.580092Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!zip -r results.zip /kaggle/working/results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.581764Z","iopub.status.idle":"2025-01-30T05:07:15.582730Z","shell.execute_reply.started":"2025-01-30T05:07:15.582313Z","shell.execute_reply":"2025-01-30T05:07:15.582360Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"old_tc = float('-inf')\nTC = []\nold_td = float('-inf')\nTD = []\nold_tc_td = float('-inf')\nTC_TD = []\n\nfor path in results_path:\n    with open(os.path.join(path, 'metrics_json.json'), 'r') as file:\n        metrics = json.load(file)\n\n    cr_tc = metrics[\"dynamic_TC\"]\n    if cr_tc >= old_tc:\n        with open(os.path.join(path, 'metrics_config.json'), 'r') as file:\n            new = json.load(file)\n        if cr_tc == old_tc:\n            TC.append((new, path))\n        else:\n            old_tc = cr_tc\n            TC = [(new, path)]\n\n    cr_td = metrics[\"dynamic_TD\"]\n    if cr_td >= old_td:\n        with open(os.path.join(path, 'metrics_config.json'), 'r') as file:\n            new = json.load(file)\n        if cr_td == old_td:\n            TD.append((new, path))\n        else:\n            old_td = cr_td\n            TD = [(new, path)]\n\n    cr_tc_td = 0.5 * cr_tc + 0.5 * cr_td\n    if cr_tc_td >= old_tc_td:\n        with open(os.path.join(path, 'metrics_config.json'), 'r') as file:\n            new = json.load(file)\n        if cr_tc_td == old_tc_td:\n            TC_TD.append((new, path))\n        else:\n            old_tc_td = cr_tc_td\n            TC_TD = [(new, path)]\n\nprint(TC)\nprint(len(TC))\nprint('-------------------------------------')\nprint(TD)\nprint(len(TD))\nprint('-------------------------------------')\nprint(TC_TD)\nprint(len(TC_TD))\n\nbest_results_path = './best_results'\nos.makedirs(best_results_path, exist_ok=True)\nsave_json(TC, os.path.join(best_results_path, 'best_tc.json'))\nsave_json(TD, os.path.join(best_results_path, 'best_td.json'))\nsave_json(TC_TD, os.path.join(best_results_path, 'best_tc_td.json'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.583305Z","iopub.status.idle":"2025-01-30T05:07:15.584100Z","shell.execute_reply.started":"2025-01-30T05:07:15.583530Z","shell.execute_reply":"2025-01-30T05:07:15.583588Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!zip -r best_results/best_results.zip /kaggle/working/results/45","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.585505Z","iopub.status.idle":"2025-01-30T05:07:15.585944Z","shell.execute_reply.started":"2025-01-30T05:07:15.585675Z","shell.execute_reply":"2025-01-30T05:07:15.585720Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Obteniendo theta y beta del modelo con la mejor configuracion","metadata":{}},{"cell_type":"code","source":"import topmost","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.586593Z","iopub.status.idle":"2025-01-30T05:07:15.586986Z","shell.execute_reply.started":"2025-01-30T05:07:15.586741Z","shell.execute_reply":"2025-01-30T05:07:15.586792Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = \"cpu\" # or\"cuda\"\ndataset_dir = \"/kaggle/input/revista-ciencias-mdicas-de-la-habana-cmed\"\ndataset = topmost.data.DynamicDataset(dataset_dir, batch_size=200, read_labels=True, device=device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.587769Z","iopub.status.idle":"2025-01-30T05:07:15.588581Z","shell.execute_reply.started":"2025-01-30T05:07:15.588122Z","shell.execute_reply":"2025-01-30T05:07:15.588171Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_results_path = './best_results'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.589786Z","iopub.status.idle":"2025-01-30T05:07:15.590623Z","shell.execute_reply.started":"2025-01-30T05:07:15.590269Z","shell.execute_reply":"2025-01-30T05:07:15.590317Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"    config = {'num_topics': 20, 'rho_size': 400, 'en_units': 1200, 'eta_hidden_size': 300, 'enc_drop': 0.2, 'eta_nlayers': 4, 'eta_dropout': 0.0, 'delta': 0.001, 'theta_act': 'selu', 'learning_rate': 0.0005, 'epochs': 400}\n    model = DETMFixed(\n            num_topics=config['num_topics'], \n            vocab_size=dataset.vocab_size,\n            num_times=dataset.num_times,\n            train_size=dataset.train_size,\n            train_time_wordfreq=dataset.train_time_wordfreq,\n            train_WE=False, \n            pretrained_WE=dataset.pretrained_WE, \n            en_units=config['en_units'], \n            eta_hidden_size=config['eta_hidden_size'], \n            rho_size=config['rho_size'], \n            enc_drop=config['enc_drop'], \n            eta_nlayers=config['eta_nlayers'], \n            eta_dropout=config['eta_dropout'], \n            delta=config['delta'], \n            theta_act=config['theta_act'],\n            device=device)\n\n    model = model.to(device)\n    # trainer = topmost.DynamicTrainer(model, dataset, epochs=config['epochs'], learning_rate=config['learning_rate'], verbose=False)\n\n    try:\n        trainer = topmost.DynamicTrainer(model, dataset, epochs=config['epochs'], learning_rate=config['learning_rate'], verbose=False)\n        top_words, train_theta = trainer.train()\n        metrics_json, dynamic_TC, dynamic_TD, clustering, classification = eval(dataset, trainer, top_words)\n        save_joblib(trainer, best_results_path)\n    except Exception as e:\n        # print(f'❌ Error config {config}')\n        traceback.print_exc()\n        result = float('-inf')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.591204Z","iopub.status.idle":"2025-01-30T05:07:15.592096Z","shell.execute_reply.started":"2025-01-30T05:07:15.591365Z","shell.execute_reply":"2025-01-30T05:07:15.591407Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"save_joblib(trainer, os.path.join(best_results_path, 'trainer.joblib'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.593381Z","iopub.status.idle":"2025-01-30T05:07:15.594060Z","shell.execute_reply.started":"2025-01-30T05:07:15.593548Z","shell.execute_reply":"2025-01-30T05:07:15.593594Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"save_joblib(model, os.path.join(best_results_path, 'model.joblib'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.595293Z","iopub.status.idle":"2025-01-30T05:07:15.596077Z","shell.execute_reply.started":"2025-01-30T05:07:15.595442Z","shell.execute_reply":"2025-01-30T05:07:15.595487Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"top_words = joblib.load('/kaggle/working/results/45/top_words.joblib')\nprint(type(top_words))\nprint(len(top_words))\nprint(top_words)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.598296Z","iopub.status.idle":"2025-01-30T05:07:15.599093Z","shell.execute_reply.started":"2025-01-30T05:07:15.598755Z","shell.execute_reply":"2025-01-30T05:07:15.598807Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_theta, test_theta = trainer.export_theta()\nprint(type(train_theta))\nprint(train_theta)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.600089Z","iopub.status.idle":"2025-01-30T05:07:15.601364Z","shell.execute_reply.started":"2025-01-30T05:07:15.600476Z","shell.execute_reply":"2025-01-30T05:07:15.600524Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"beta = model.get_beta()\n# print(topic_matrix)\nprint(beta.shape[0]) # Numero de time_slices\nprint(beta.shape[1]) # Numero de tópicos\nprint(beta.shape[2]) # Numero de palabras","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.602565Z","iopub.status.idle":"2025-01-30T05:07:15.603574Z","shell.execute_reply.started":"2025-01-30T05:07:15.602921Z","shell.execute_reply":"2025-01-30T05:07:15.602968Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" ## Segun beta (matriz de topicos) ver la probabilidad de cada palabra en cada topico en cada time slice","metadata":{}},{"cell_type":"code","source":"import os\nvocab_path = '/kaggle/input/revista-ciencias-mdicas-de-la-habana-cmed/vocab.txt'\nwith open(vocab_path, 'r') as file:\n    words = file.readlines()\n    vocab = [word.replace('\\n', '') for word in words]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.604383Z","iopub.status.idle":"2025-01-30T05:07:15.604947Z","shell.execute_reply.started":"2025-01-30T05:07:15.604566Z","shell.execute_reply":"2025-01-30T05:07:15.604608Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"times_path = '/kaggle/input/revista-ciencias-mdicas-de-la-habana-cmed/time2id.txt'\nwith open(times_path, 'r') as file:\n    times = file.readlines()[0]\nprint(times)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.606313Z","iopub.status.idle":"2025-01-30T05:07:15.607027Z","shell.execute_reply.started":"2025-01-30T05:07:15.606564Z","shell.execute_reply":"2025-01-30T05:07:15.606613Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"timelist = list(json.loads(times.replace('\\'', '\\\"')).keys())\ntimelist = [int(time) for time in timelist]\nprint(type(timelist))\nprint(timelist)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.607907Z","iopub.status.idle":"2025-01-30T05:07:15.608492Z","shell.execute_reply.started":"2025-01-30T05:07:15.608087Z","shell.execute_reply":"2025-01-30T05:07:15.608133Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy\n\nprint(numpy.__version__)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.609333Z","iopub.status.idle":"2025-01-30T05:07:15.610314Z","shell.execute_reply.started":"2025-01-30T05:07:15.609510Z","shell.execute_reply":"2025-01-30T05:07:15.609579Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt \n\ndef get_word_index(words):\n    return [vocab.index(word) for word in words]\n\ndef get_words(words_index):\n    return [vocab[index] for index in words_index]\n\ndef get_betas(word_index, topic):\n    return [beta[time][topic][word_index].item() for time in range(len(timelist))]\n\ndef graphic(words, betas, topic_name):\n    T = len(timelist)\n    fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(18, 9), dpi=80, facecolor='w', edgecolor='k')\n    ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8 = axes.flatten()\n    ticks = [str(x) for x in timelist]\n    for i, comp in enumerate(betas):\n        ax1.plot(range(len(timelist)), comp, label=words[i], lw=2, linestyle='--', marker='o', markersize=4)\n    ax1.legend(frameon=False)\n    print('np.arange(T)[0::10]: ', np.arange(T)[0::10])\n    ax1.set_xticks(np.arange(len(timelist)))\n    ax1.set_xticklabels(timelist)\n    ax1.set_title(topic_name, fontsize=12)\n\n    plt.savefig(os.path.join(best_result_path, 'images', f\"word_evolution_{topic_name}.png\"))\n    plt.show()\n\ndef visualize_topic_evolution(num_top_words):\n    images_path = os.path.join(best_results_path, 'images')\n    os.makedirs(images_path, exist_ok=True)\n    \n    for topic in range(beta.shape[1]):\n        topic_name = ''\n\n        # words_index = list(set([np.argmax(beta[time][topic], n=num_top_words) for time in range(len(timelist))]))\n        # betas = [[np.nargmax(beta[time][topic][word], n=num_top_words) for time in range(timelist)] for word in words_index]\n        words = set([word for time in range(len(timelist)) for word in top_words[time][0].split(' ')])\n        betas = [get_betas(word, topic) for word in get_word_index(words)]        \n        graphic_(list(words), betas, topic_name, os.path.join(images_path, f'topic_{topic}.png'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.611622Z","iopub.status.idle":"2025-01-30T05:07:15.612007Z","shell.execute_reply.started":"2025-01-30T05:07:15.611767Z","shell.execute_reply":"2025-01-30T05:07:15.611809Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"visualize_topic_evolution(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.612836Z","iopub.status.idle":"2025-01-30T05:07:15.614043Z","shell.execute_reply.started":"2025-01-30T05:07:15.613040Z","shell.execute_reply":"2025-01-30T05:07:15.613099Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"a = set([word for time in range(len(timelist)) for word in top_words[time][0].split(' ')])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.615397Z","iopub.status.idle":"2025-01-30T05:07:15.616019Z","shell.execute_reply.started":"2025-01-30T05:07:15.615568Z","shell.execute_reply":"2025-01-30T05:07:15.615624Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"b = [get_betas(word, 0) for word in get_word_index(a)]\n#print(betas)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.616917Z","iopub.status.idle":"2025-01-30T05:07:15.617560Z","shell.execute_reply.started":"2025-01-30T05:07:15.617210Z","shell.execute_reply":"2025-01-30T05:07:15.617258Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nbest_results_path = './best_results'\ndef graphic_(words, betas, topic_name, images_path):\n    \"\"\"\n    Genera un único gráfico que muestra la evolución de las palabras a lo largo del tiempo.\n\n    Args:\n        words: Lista de palabras a graficar.\n        betas: Lista de listas, donde cada sublista contiene los valores beta para una palabra en cada timestamp.\n        topic_name: Nombre del tema.\n        timelist: Lista de timestamps.\n        best_result_path: Ruta para guardar el gráfico.\n    \"\"\"\n    T = len(timelist)\n    \n    # Crear una figura grande\n    fig, ax1 = plt.subplots(figsize=(20, 10), dpi=80, facecolor='w', edgecolor='k')\n\n    # Graficar las líneas para cada palabra\n    for i, comp in enumerate(betas):\n        ax1.plot(range(len(timelist)), comp, label=words[i], lw=2, linestyle='--', marker='o', markersize=4)\n\n    # Configurar la leyenda\n    ax1.legend(frameon=False, loc='upper center', ncol=5) # Ajusta la ubicación y el número de columnas de la leyenda\n\n    # Configurar las etiquetas del eje x\n    ax1.set_xticks(np.arange(len(timelist)))\n    ax1.set_xticklabels(timelist, rotation=45, ha='right') # Rota las etiquetas para que sean legibles\n\n    # Configurar el título\n    ax1.set_title(f'Evolución de las palabras en el tema: {topic_name}', fontsize=14)\n\n    # Añadir etiquetas a los ejes\n    ax1.set_xlabel(\"Tiempo\")\n    ax1.set_ylabel(\"Valor Beta\")\n    \n    # Ajustar el diseño para evitar que se superpongan los elementos\n    plt.tight_layout()\n\n    # Guardar el gráfico\n    plt.savefig(images_path)\n\n    # Mostrar el gráfico\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.619302Z","iopub.status.idle":"2025-01-30T05:07:15.619777Z","shell.execute_reply.started":"2025-01-30T05:07:15.619487Z","shell.execute_reply":"2025-01-30T05:07:15.619550Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"graphic_(list(a), b, 'test')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.620686Z","iopub.status.idle":"2025-01-30T05:07:15.621188Z","shell.execute_reply.started":"2025-01-30T05:07:15.620892Z","shell.execute_reply":"2025-01-30T05:07:15.620939Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!zip -r best_results/images/images.zip /kaggle/working/best_results/images","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:07:15.622435Z","iopub.status.idle":"2025-01-30T05:07:15.623071Z","shell.execute_reply.started":"2025-01-30T05:07:15.622589Z","shell.execute_reply":"2025-01-30T05:07:15.622630Z"}},"outputs":[],"execution_count":null}]}