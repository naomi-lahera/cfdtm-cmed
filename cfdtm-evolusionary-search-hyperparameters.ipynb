{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10685499,"sourceType":"datasetVersion","datasetId":6553770}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install topmost","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-20T04:24:20.666968Z","iopub.execute_input":"2025-02-20T04:24:20.667160Z","iopub.status.idle":"2025-02-20T04:24:32.537086Z","shell.execute_reply.started":"2025-02-20T04:24:20.667142Z","shell.execute_reply":"2025-02-20T04:24:32.536006Z"}},"outputs":[{"name":"stdout","text":"Collecting topmost\n  Downloading topmost-1.0.1-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: numpy<1.27.0 in /usr/local/lib/python3.10/dist-packages (from topmost) (1.26.4)\nCollecting scipy<=1.10.1 (from topmost)\n  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting sentence-transformers<3.0.0,>=2.6.0 (from topmost)\n  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: torchvision>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from topmost) (0.20.1+cu121)\nRequirement already satisfied: gensim>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from topmost) (4.3.3)\nRequirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from topmost) (1.2.2)\nRequirement already satisfied: tqdm>=4.66.0 in /usr/local/lib/python3.10/dist-packages (from topmost) (4.67.1)\nCollecting fastopic>=1.0.0 (from topmost)\n  Downloading fastopic-1.0.0-py3-none-any.whl.metadata (11 kB)\nCollecting bertopic>=0.15.0 (from topmost)\n  Downloading bertopic-0.16.4-py3-none-any.whl.metadata (23 kB)\nCollecting hdbscan>=0.8.29 (from bertopic>=0.15.0->topmost)\n  Downloading hdbscan-0.8.40-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\nRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from bertopic>=0.15.0->topmost) (2.2.2)\nRequirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from bertopic>=0.15.0->topmost) (5.24.1)\nCollecting umap-learn>=0.5.0 (from bertopic>=0.15.0->topmost)\n  Downloading umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim>=4.2.0->topmost) (7.0.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<1.27.0->topmost) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<1.27.0->topmost) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<1.27.0->topmost) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<1.27.0->topmost) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<1.27.0->topmost) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<1.27.0->topmost) (2.4.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->topmost) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->topmost) (3.5.0)\nRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.6.0->topmost) (4.47.0)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.6.0->topmost) (2.5.1+cu121)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.6.0->topmost) (0.27.0)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.6.0->topmost) (11.0.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (2024.9.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (1.3.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (2.32.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic>=0.15.0->topmost) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic>=0.15.0->topmost) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic>=0.15.0->topmost) (2024.2)\nRequirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic>=0.15.0->topmost) (9.0.0)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim>=4.2.0->topmost) (1.17.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (0.4.5)\nRequirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.0->bertopic>=0.15.0->topmost) (0.60.0)\nCollecting pynndescent>=0.5 (from umap-learn>=0.5.0->bertopic>=0.15.0->topmost)\n  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<1.27.0->topmost) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<1.27.0->topmost) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<1.27.0->topmost) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<1.27.0->topmost) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<1.27.0->topmost) (2024.2.0)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic>=0.15.0->topmost) (0.43.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic>=0.15.0->topmost) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (2024.12.14)\nDownloading topmost-1.0.1-py3-none-any.whl (93 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.6/93.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bertopic-0.16.4-py3-none-any.whl (143 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.7/143.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastopic-1.0.0-py3-none-any.whl (89 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.6/89.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading hdbscan-0.8.40-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading umap_learn-0.5.7-py3-none-any.whl (88 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: scipy, pynndescent, umap-learn, sentence-transformers, hdbscan, fastopic, bertopic, topmost\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.13.1\n    Uninstalling scipy-1.13.1:\n      Successfully uninstalled scipy-1.13.1\n  Attempting uninstall: sentence-transformers\n    Found existing installation: sentence-transformers 3.3.1\n    Uninstalling sentence-transformers-3.3.1:\n      Successfully uninstalled sentence-transformers-3.3.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkaggle-environments 1.16.10 requires scipy>=1.11.2, but you have scipy 1.10.1 which is incompatible.\nmlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\nplotnine 0.14.4 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\nscikit-image 0.25.0 requires scipy>=1.11.2, but you have scipy 1.10.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bertopic-0.16.4 fastopic-1.0.0 hdbscan-0.8.40 pynndescent-0.5.13 scipy-1.10.1 sentence-transformers-2.7.0 topmost-1.0.1 umap-learn-0.5.7\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import topmost\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T04:24:40.031050Z","iopub.execute_input":"2025-02-20T04:24:40.031362Z","iopub.status.idle":"2025-02-20T04:25:38.767711Z","shell.execute_reply.started":"2025-02-20T04:24:40.031331Z","shell.execute_reply":"2025-02-20T04:25:38.767068Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"device = \"cuda\"  # or \"cpu\"\ndataset_dir = \"/kaggle/input/revista-de-ciencias-mdicas-de-la-habana-cuba\"\noutput_dir = \"./results\"\nos.makedirs(output_dir, exist_ok=True)\n\ndataset = topmost.data.DynamicDataset(dataset_dir, batch_size=200, read_labels=True, device=device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T04:26:40.988888Z","iopub.execute_input":"2025-02-20T04:26:40.989627Z","iopub.status.idle":"2025-02-20T04:26:43.147044Z","shell.execute_reply.started":"2025-02-20T04:26:40.989600Z","shell.execute_reply":"2025-02-20T04:26:43.146150Z"}},"outputs":[{"name":"stdout","text":"train size:  1208\ntest size:  658\nvocab size:  19384\naverage length: 1335.378\nnum of each time slice:  22 [20 34 46 41 56 20 76 58 43 54 83 71 64 67 63 60 55 83 75 58 57 24]\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import random\nimport joblib\nimport json\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T04:26:51.051421Z","iopub.execute_input":"2025-02-20T04:26:51.051750Z","iopub.status.idle":"2025-02-20T04:26:51.055614Z","shell.execute_reply.started":"2025-02-20T04:26:51.051727Z","shell.execute_reply":"2025-02-20T04:26:51.054675Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def save_txt(obj, path):\n    with open(path, 'w') as file:\n        file.write(obj)\n\ndef save_top_words_txt(top_words, path):\n    with open(os.path.join(path, 'top_words.txt'), 'w') as file:\n        for i, time in enumerate(top_words):\n            file.write(f'================= Time {i} ================= \\n')\n            for j, topic in enumerate(time):\n                file.write(f'================= Topic {j} ================= \\n')\n                file.write(f'{topic}')\n                file.write('\\n')\n            file.write('\\n')\n\ndef save_json(obj, path):\n    with open(path, 'w') as file:\n        json.dump(obj, file)\n\ndef save_joblib(obj, path):\n    joblib.dump(obj, path)\n\ndef save_result(top_words, trainer, config, metrics_json):\n    global samples \n    path = os.path.join(output_dir, f'{samples}')\n    os.makedirs(path, exist_ok=True)\n\n    try:\n        save_top_words_txt(top_words, path)\n        save_json(config, os.path.join(path, 'hyperparameters.json'))\n        save_json(metrics_json, os.path.join(path, 'metrics_json.json'))\n        save_json({\"config\": config, \"metrics\": metrics_json}, os.path.join(path, 'metrics_config.json'))\n        # save_joblib(trainer, os.path.join(path, 'trainer.joblib'))\n        save_joblib(top_words, os.path.join(path, 'top_words.joblib'))\n        print('🍀 Saved')\n    except Exception as e:\n        traceback.print_exc(e)        \n\ndef get_hyperparameter_space():\n    return {\n  \"training\": {\n    \"learning_rate\": [0.001, 0.002, 0.005, 0.01],\n    \"batch_size\": [100, 200, 300, 500],\n    \"num_epoch\": [400, 600, 800, 1000]\n  },\n  \"model\": {\n    \"num_topics\": [20, 50, 100],\n    \"en1_units\": [50, 100, 200, 300],\n    \"dropout\": [0.0, 0.1, 0.3, 0.5],\n    \"beta_temp\": [0.5, 1.0, 1.5, 2.0],\n    \"temperature\": [0.05, 0.1, 0.2, 0.5],\n    \"weight_neg\": [1e6, 5e6, 1e7, 1e8],\n    \"weight_pos\": [1.0, 10.0, 100.0],\n    \"weight_UWE\": [1e2, 1e3, 1e4],\n    \"neg_topk\": [5, 10, 15, 20, 30]\n  }\n}\n\ndef get_default_config():\n    return { \"training\": {\n                \"learning_rate\": 0.002,\n                \"batch_size\": 200,\n                \"num_epoch\": 800 },\n\n            \"model\": {\n                \"num_topics\": 50,\n                \"en1_units\": 100,\n                \"dropout\": 0. , \n                \"beta_temp\": 1.0,\n                \"temperature\": 0.1,\n                \"weight_neg\": 1.0e+7,\n                \"weight_pos\": 1.0e+1,\n                \"weight_UWE\": 1.0e+3,\n                \"neg_topk\": 15 }\n           }\n\ndef random_configuration(hyperparameter_space):\n    return { \"training\": {\n                \"learning_rate\": random.choice(hyperparameter_space[\"training\"][\"learning_rate\"]),\n                \"batch_size\": random.choice(hyperparameter_space[\"training\"][\"batch_size\"]),\n                \"num_epoch\": random.choice(hyperparameter_space[\"training\"][\"num_epoch\"]) },\n\n            \"model\": {\n                \"num_topics\": random.choice(hyperparameter_space[\"model\"][\"num_topics\"]),\n                \"en1_units\": random.choice(hyperparameter_space[\"model\"][\"en1_units\"]),\n                \"dropout\": random.choice(hyperparameter_space[\"model\"][\"dropout\"]) , \n                \"beta_temp\": random.choice(hyperparameter_space[\"model\"][\"beta_temp\"]),\n                \"temperature\": random.choice(hyperparameter_space[\"model\"][\"temperature\"]),\n                \"weight_neg\": random.choice(hyperparameter_space[\"model\"][\"weight_neg\"]),\n                \"weight_pos\": random.choice(hyperparameter_space[\"model\"][\"weight_pos\"]),\n                \"weight_UWE\": random.choice(hyperparameter_space[\"model\"][\"weight_UWE\"]),\n                \"neg_topk\":random.choice(hyperparameter_space[\"model\"][\"neg_topk\"]) }\n           }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T04:26:54.364933Z","iopub.execute_input":"2025-02-20T04:26:54.365326Z","iopub.status.idle":"2025-02-20T04:26:54.380839Z","shell.execute_reply.started":"2025-02-20T04:26:54.365290Z","shell.execute_reply":"2025-02-20T04:26:54.379906Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Hyperparameters Search","metadata":{}},{"cell_type":"markdown","source":"## - Evaluacion","metadata":{}},{"cell_type":"code","source":"########################### Evaluate ####################################\nimport numpy as np\nfrom topmost import eva\nfrom gensim.corpora import Dictionary\nfrom gensim.models import CoherenceModel\nfrom topmost.data.file_utils import split_text_word","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T04:27:00.635911Z","iopub.execute_input":"2025-02-20T04:27:00.636190Z","iopub.status.idle":"2025-02-20T04:27:00.640094Z","shell.execute_reply.started":"2025-02-20T04:27:00.636170Z","shell.execute_reply":"2025-02-20T04:27:00.639133Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def _coherence_modified(reference_corpus, vocab, top_words, cv_type='c_v'):\n    # print('🍀')\n    \n    split_top_words = split_text_word(top_words)\n    num_top_words = len(split_top_words[0])\n    for item in split_top_words:\n        assert num_top_words == len(item)\n\n    split_reference_corpus = split_text_word(reference_corpus)\n    dictionary = Dictionary(split_text_word(vocab))\n\n    cm = CoherenceModel(texts=split_reference_corpus, dictionary=dictionary, topics=split_top_words, topn=num_top_words, coherence=cv_type)\n    cv_per_topic = cm.get_coherence_per_topic()\n    # print(f\"Coherence scores per topic: {cv_per_topic}\")\n\n    valid_scores = [score for score in cv_per_topic if not np.isnan(score)]\n    if not valid_scores:\n        # raise ValueError(\"All coherence scores are NaN.\")\n        return 0\n    score = np.mean(valid_scores)\n\n    return score\n    \neva.topic_coherence._coherence = _coherence_modified","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T04:27:03.740212Z","iopub.execute_input":"2025-02-20T04:27:03.740530Z","iopub.status.idle":"2025-02-20T04:27:03.745606Z","shell.execute_reply.started":"2025-02-20T04:27:03.740504Z","shell.execute_reply":"2025-02-20T04:27:03.744774Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def eval(top_words, trainer):\n    # get theta (doc-topic distributions)\n    train_theta, test_theta = trainer.export_theta()\n\n    train_times = dataset.train_times.cpu().numpy()\n    # compute topic coherence\n    dynamic_TC = eva.dynamic_coherence(dataset.train_texts, train_times, dataset.vocab, top_words)\n    print(\"dynamic_TC: \", dynamic_TC)\n\n    # compute topic diversity\n    dynamic_TD = eva.dynamic_diversity(top_words, dataset.train_bow.cpu().numpy(), train_times, dataset.vocab)\n    print(\"dynamic_TD: \", dynamic_TD)\n\n    # evaluate clustering\n    clustering = eva._clustering(test_theta, dataset.test_labels)\n    print(clustering)\n\n    # evaluate classification\n    classification = eva._cls(train_theta, test_theta, dataset.train_labels, dataset.test_labels)\n    print(classification)\n\n    json = {\n        \"dynamic_TC\": dynamic_TC,\n        \"dynamic_TD\": dynamic_TD,\n        \"clustering\": clustering,\n        \"classification\": classification\n    }\n    \n    return json, dynamic_TC, dynamic_TD, clustering, classification","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T04:27:07.612276Z","iopub.execute_input":"2025-02-20T04:27:07.612571Z","iopub.status.idle":"2025-02-20T04:27:07.617871Z","shell.execute_reply.started":"2025-02-20T04:27:07.612551Z","shell.execute_reply":"2025-02-20T04:27:07.616819Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## - Modelo","metadata":{}},{"cell_type":"code","source":"import traceback","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T04:27:12.735814Z","iopub.execute_input":"2025-02-20T04:27:12.736100Z","iopub.status.idle":"2025-02-20T04:27:12.739648Z","shell.execute_reply.started":"2025-02-20T04:27:12.736078Z","shell.execute_reply":"2025-02-20T04:27:12.738727Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def evaluate_configuration(config):\n    global tested_configs, samples\n    \n    config_key = json.dumps(config, sort_keys=True) \n    \n    if config_key in tested_configs:\n        return tested_configs[config_key]\n    \n    model = topmost.CFDTM(\n        vocab_size=dataset.vocab_size,\n        train_time_wordfreq=dataset.train_time_wordfreq,\n        num_times=dataset.num_times,\n        pretrained_WE=dataset.pretrained_WE,\n        num_topics=config[\"model\"][\"num_topics\"],\n        en_units=config[\"model\"][\"en1_units\"],\n        temperature=config[\"model\"][\"temperature\"],\n        beta_temp=config[\"model\"][\"beta_temp\"],\n        weight_neg=config[\"model\"][\"weight_neg\"],\n        weight_pos=config[\"model\"][\"weight_pos\"],\n        weight_UWE=config[\"model\"][\"weight_UWE\"],\n        neg_topk=config[\"model\"][\"neg_topk\"],\n        dropout=config[\"model\"][\"dropout\"],\n        embed_size=300\n    )\n  \n    model = model.to(device)  \n    trainer = topmost.DynamicTrainer(model, dataset, batch_size=config[\"training\"][\"batch_size\"], learning_rate=config[\"training\"][\"learning_rate\"], epochs=config[\"training\"][\"num_epoch\"])\n    top_words, _ = trainer.train()\n    \n    try:\n        metrics_json, dynamic_TC, dynamic_TD, clustering, classification = eval(top_words, trainer)\n        #tested_configs[config_key] = 0.5 * dynamic_TC + 0.5 * dynamic_TD\n        tested_configs[config_key] = {\"dynamic_TC\": dynamic_TC, \"dynamic_TD\": dynamic_TD}\n        save_result(top_words, trainer, config, metrics_json)\n        samples += 1\n    except Exception as e:\n        tested_configs[config_key] = {\"dynamic_TC\": float('-inf'), \"dynamic_TD\": float('-inf')}\n        print(e)\n        \n    save_joblib(tested_configs, os.path.join(output_dir, 'tested_configs.joblib'))\n    \n    return tested_configs[config_key]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T04:27:17.333133Z","iopub.execute_input":"2025-02-20T04:27:17.333427Z","iopub.status.idle":"2025-02-20T04:27:17.340437Z","shell.execute_reply.started":"2025-02-20T04:27:17.333407Z","shell.execute_reply":"2025-02-20T04:27:17.339516Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## - Algortimo evolutivo","metadata":{}},{"cell_type":"code","source":"def key_func(value):\n    try:\n        return 0.5 * value[1][\"dynamic_TC\"] + 0.5 * value[1][\"dynamic_TD\"]\n    except: \n        return value[1]\n\ndef evolutionary_search(search_space, generations=10, mutation_rate=0.1, population_size=20, population=None, generation_count=0):\n    global samples\n    \n    if not population:\n        population = [random_configuration(search_space) for _ in range(population_size - 1)]\n        population.append(get_default_config())\n\n    # print(population)\n    \n    for generation in range(generation_count, generations):\n        scores = [(config, evaluate_configuration(config)) for config in population]\n        scores.sort(key=key_func, reverse=True)  \n\n        print(f\"🧬 Generación {generation + 1}, mejor resultado: {scores[0][1]}\")\n        \n        num_parents = population_size // 2\n        parents = [config for config, _ in scores[:num_parents]]\n        \n        children = []\n        while len(children) < population_size - num_parents:\n            parent_1, parent_2 = random.sample(parents, 2)\n            child = {\n                \"model\": {key: random.choice([parent_1[\"model\"][key], parent_2[\"model\"][key]]) for key in search_space[\"model\"].keys()},\n                \"training\": {key: random.choice([parent_1[\"training\"][key], parent_2[\"training\"][key]]) for key in search_space[\"training\"].keys()},\n            }\n            \n            if random.random() < mutation_rate:\n                mutate_model_training = random.choice(list(search_space.keys()))\n                print(mutate_model_training)\n                param_to_mutate = random.choice(list(search_space[mutate_model_training].keys()))\n                print(param_to_mutate)\n                child[mutate_model_training][param_to_mutate] = random.choice(search_space[mutate_model_training][param_to_mutate])\n            \n            children.append(child)\n        \n        population = parents + children\n        joblib.dump(population, os.path.join(output_dir, 'population.joblib'))\n    \n    best_config, best_score = max(scores, key=key_func)\n    return best_config, best_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T04:28:52.045298Z","iopub.execute_input":"2025-02-20T04:28:52.045626Z","iopub.status.idle":"2025-02-20T04:28:52.054227Z","shell.execute_reply.started":"2025-02-20T04:28:52.045598Z","shell.execute_reply":"2025-02-20T04:28:52.053243Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"## Main","metadata":{}},{"cell_type":"code","source":"population_size = 50\n# population = None\npopulation = joblib.load(os.path.join(output_dir, 'population.joblib'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T04:27:33.451965Z","iopub.execute_input":"2025-02-20T04:27:33.452251Z","iopub.status.idle":"2025-02-20T04:27:33.458336Z","shell.execute_reply.started":"2025-02-20T04:27:33.452230Z","shell.execute_reply":"2025-02-20T04:27:33.457666Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"import joblib\n# tested_configs = dict()\ntested_configs = joblib.load('/kaggle/working/results/tested_configs.joblib')\n# print(tested_configs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T04:27:41.148070Z","iopub.execute_input":"2025-02-20T04:27:41.148340Z","iopub.status.idle":"2025-02-20T04:27:41.154027Z","shell.execute_reply.started":"2025-02-20T04:27:41.148320Z","shell.execute_reply":"2025-02-20T04:27:41.153160Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"results_path = '/kaggle/working/results'\nresults_path = [dir_.path for dir_ in os.scandir(results_path) if not dir_.is_file()]\n\nprint(len(results_path))\n\nsamples = len(results_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T04:27:50.443762Z","iopub.execute_input":"2025-02-20T04:27:50.444079Z","iopub.status.idle":"2025-02-20T04:27:50.449479Z","shell.execute_reply.started":"2025-02-20T04:27:50.444051Z","shell.execute_reply":"2025-02-20T04:27:50.448825Z"}},"outputs":[{"name":"stdout","text":"121\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"hyperparameter_space = get_hyperparameter_space()\n\nbest_config, best_score = evolutionary_search(hyperparameter_space, population_size=population_size, generations=100, mutation_rate=0.2, population=population)\nprint(best_config)\nprint(best_score)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T04:27:58.731545Z","iopub.execute_input":"2025-02-20T04:27:58.731878Z","iopub.status.idle":"2025-02-20T04:27:58.897110Z","shell.execute_reply.started":"2025-02-20T04:27:58.731852Z","shell.execute_reply":"2025-02-20T04:27:58.896238Z"}},"outputs":[{"name":"stdout","text":"🧬 Generación 1, mejor resultado: 0.7346252187845747\nmodel\nweight_pos\nmodel\ntemperature\nmodel\nweight_UWE\nmodel\nneg_topk\nmodel\nweight_pos\ntraining\nnum_epoch\n🧬 Generación 2, mejor resultado: 0.7346252187845747\ntraining\nbatch_size\ntraining\nnum_epoch\nmodel\ndropout\nmodel\nnum_topics\ntraining\nnum_epoch\ntraining\nbatch_size\ntraining\nbatch_size\n🧬 Generación 3, mejor resultado: 0.7346252187845747\nmodel\nneg_topk\ntraining\nnum_epoch\ntraining\nnum_epoch\ntraining\nbatch_size\ntraining\nbatch_size\nmodel\nweight_pos\nmodel\ndropout\n🧬 Generación 4, mejor resultado: 0.7346252187845747\ntraining\nnum_epoch\nmodel\ndropout\nmodel\nnum_topics\nmodel\nbeta_temp\nmodel\nneg_topk\n🧬 Generación 5, mejor resultado: 0.7346252187845747\nmodel\nen1_units\nmodel\nbeta_temp\ntraining\nnum_epoch\ntraining\nnum_epoch\n🧬 Generación 6, mejor resultado: 0.7346252187845747\ntraining\nnum_epoch\ntraining\nbatch_size\nmodel\nnum_topics\nmodel\nnum_topics\ntraining\nnum_epoch\ntraining\nlearning_rate\ntraining\nlearning_rate\ntraining\nnum_epoch\n🧬 Generación 7, mejor resultado: 0.7346252187845747\ntraining\nlearning_rate\nmodel\nneg_topk\n🧬 Generación 8, mejor resultado: 0.7346252187845747\nmodel\ndropout\nmodel\nnum_topics\nmodel\nen1_units\ntraining\nnum_epoch\nmodel\nen1_units\n🧬 Generación 9, mejor resultado: 0.7346252187845747\nmodel\ntemperature\ntraining\nbatch_size\ntraining\nnum_epoch\n🧬 Generación 10, mejor resultado: 0.7346252187845747\nmodel\nbeta_temp\n🧬 Generación 11, mejor resultado: 0.7346252187845747\ntraining\nbatch_size\ntraining\nbatch_size\nmodel\ndropout\n🧬 Generación 12, mejor resultado: 0.7346252187845747\nmodel\nbeta_temp\ntraining\nbatch_size\ntraining\nlearning_rate\nmodel\nbeta_temp\nmodel\nnum_topics\n🧬 Generación 13, mejor resultado: 0.7346252187845747\ntraining\nlearning_rate\ntraining\nlearning_rate\nmodel\nweight_UWE\ntraining\nnum_epoch\ntraining\nlearning_rate\nmodel\nneg_topk\nmodel\nnum_topics\ntraining\nlearning_rate\n🧬 Generación 14, mejor resultado: 0.7346252187845747\nmodel\nbeta_temp\ntraining\nnum_epoch\ntraining\nbatch_size\nmodel\nneg_topk\n🧬 Generación 15, mejor resultado: 0.7346252187845747\nmodel\nneg_topk\ntraining\nnum_epoch\ntraining\nbatch_size\ntraining\nnum_epoch\nmodel\ntemperature\nmodel\nneg_topk\nmodel\nneg_topk\ntraining\nbatch_size\nmodel\nweight_pos\n🧬 Generación 16, mejor resultado: 0.7346252187845747\ntraining\nnum_epoch\nmodel\ntemperature\n🧬 Generación 17, mejor resultado: 0.7346252187845747\nmodel\ndropout\ntraining\nbatch_size\ntraining\nbatch_size\ntraining\nlearning_rate\ntraining\nlearning_rate\ntraining\nbatch_size\n🧬 Generación 18, mejor resultado: 0.7346252187845747\nmodel\nweight_UWE\ntraining\nlearning_rate\ntraining\nbatch_size\ntraining\nnum_epoch\ntraining\nlearning_rate\nmodel\nweight_neg\n🧬 Generación 19, mejor resultado: 0.7346252187845747\ntraining\nlearning_rate\nmodel\nweight_UWE\nmodel\nen1_units\n🧬 Generación 20, mejor resultado: 0.7346252187845747\nmodel\nweight_UWE\nmodel\nweight_neg\nmodel\ntemperature\nmodel\nweight_UWE\n🧬 Generación 21, mejor resultado: 0.7346252187845747\nmodel\nnum_topics\ntraining\nbatch_size\nmodel\nbeta_temp\ntraining\nnum_epoch\ntraining\nlearning_rate\n🧬 Generación 22, mejor resultado: 0.7346252187845747\nmodel\nweight_pos\nmodel\nweight_UWE\n🧬 Generación 23, mejor resultado: 0.7346252187845747\nmodel\nneg_topk\nmodel\nneg_topk\nmodel\nweight_UWE\nmodel\nen1_units\ntraining\nnum_epoch\n🧬 Generación 24, mejor resultado: 0.7346252187845747\ntraining\nbatch_size\ntraining\nlearning_rate\nmodel\nneg_topk\ntraining\nnum_epoch\nmodel\nweight_UWE\n🧬 Generación 25, mejor resultado: 0.7346252187845747\ntraining\nlearning_rate\nmodel\ntemperature\ntraining\nlearning_rate\nmodel\nen1_units\nmodel\nnum_topics\ntraining\nlearning_rate\nmodel\nbeta_temp\ntraining\nnum_epoch\n🧬 Generación 26, mejor resultado: 0.7346252187845747\ntraining\nnum_epoch\nmodel\nweight_pos\ntraining\nnum_epoch\ntraining\nlearning_rate\nmodel\nnum_topics\n🧬 Generación 27, mejor resultado: 0.7346252187845747\ntraining\nbatch_size\ntraining\nnum_epoch\ntraining\nbatch_size\ntraining\nnum_epoch\nmodel\ntemperature\n🧬 Generación 28, mejor resultado: 0.7346252187845747\nmodel\nweight_pos\nmodel\ndropout\nmodel\nneg_topk\n🧬 Generación 29, mejor resultado: 0.7346252187845747\ntraining\nlearning_rate\nmodel\nnum_topics\ntraining\nnum_epoch\nmodel\nbeta_temp\nmodel\nneg_topk\n🧬 Generación 30, mejor resultado: 0.7346252187845747\nmodel\nweight_neg\ntraining\nlearning_rate\ntraining\nlearning_rate\nmodel\nweight_neg\nmodel\nweight_pos\ntraining\nnum_epoch\n🧬 Generación 31, mejor resultado: 0.7346252187845747\ntraining\nnum_epoch\ntraining\nlearning_rate\ntraining\nlearning_rate\nmodel\nweight_neg\ntraining\nnum_epoch\n🧬 Generación 32, mejor resultado: 0.7346252187845747\ntraining\nnum_epoch\ntraining\nlearning_rate\nmodel\nnum_topics\ntraining\nbatch_size\nmodel\nbeta_temp\nmodel\nnum_topics\nmodel\nneg_topk\n🧬 Generación 33, mejor resultado: 0.7346252187845747\ntraining\nbatch_size\ntraining\nnum_epoch\ntraining\nnum_epoch\nmodel\nneg_topk\nmodel\nbeta_temp\ntraining\nbatch_size\ntraining\nnum_epoch\ntraining\nnum_epoch\nmodel\nen1_units\n🧬 Generación 34, mejor resultado: 0.7346252187845747\nmodel\nweight_neg\ntraining\nbatch_size\nmodel\ntemperature\nmodel\nweight_UWE\ntraining\nnum_epoch\nmodel\nen1_units\n🧬 Generación 35, mejor resultado: 0.7346252187845747\nmodel\nnum_topics\nmodel\nweight_UWE\ntraining\nnum_epoch\n🧬 Generación 36, mejor resultado: 0.7346252187845747\ntraining\nlearning_rate\nmodel\nneg_topk\ntraining\nnum_epoch\nmodel\nneg_topk\nmodel\nweight_pos\ntraining\nlearning_rate\n🧬 Generación 37, mejor resultado: 0.7346252187845747\ntraining\nlearning_rate\ntraining\nbatch_size\nmodel\ntemperature\ntraining\nlearning_rate\ntraining\nlearning_rate\nmodel\ndropout\n🧬 Generación 38, mejor resultado: 0.7346252187845747\nmodel\nweight_pos\ntraining\nlearning_rate\ntraining\nlearning_rate\nmodel\nen1_units\nmodel\nneg_topk\n🧬 Generación 39, mejor resultado: 0.7346252187845747\nmodel\nweight_UWE\ntraining\nlearning_rate\nmodel\nweight_pos\ntraining\nnum_epoch\n🧬 Generación 40, mejor resultado: 0.7346252187845747\nmodel\ntemperature\ntraining\nbatch_size\ntraining\nbatch_size\nmodel\ntemperature\nmodel\nnum_topics\n🧬 Generación 41, mejor resultado: 0.7346252187845747\nmodel\nweight_neg\nmodel\nbeta_temp\nmodel\nweight_neg\nmodel\ntemperature\ntraining\nnum_epoch\n🧬 Generación 42, mejor resultado: 0.7346252187845747\ntraining\nlearning_rate\ntraining\nbatch_size\ntraining\nlearning_rate\nmodel\nweight_pos\nmodel\ndropout\n🧬 Generación 43, mejor resultado: 0.7346252187845747\nmodel\nneg_topk\nmodel\ndropout\nmodel\nweight_neg\nmodel\nneg_topk\n🧬 Generación 44, mejor resultado: 0.7346252187845747\ntraining\nlearning_rate\nmodel\nneg_topk\nmodel\ntemperature\nmodel\nneg_topk\ntraining\nbatch_size\ntraining\nlearning_rate\nmodel\nen1_units\n🧬 Generación 45, mejor resultado: 0.7346252187845747\ntraining\nnum_epoch\nmodel\nnum_topics\nmodel\nnum_topics\n🧬 Generación 46, mejor resultado: 0.7346252187845747\nmodel\nbeta_temp\nmodel\nweight_pos\ntraining\nnum_epoch\n🧬 Generación 47, mejor resultado: 0.7346252187845747\ntraining\nlearning_rate\nmodel\nen1_units\nmodel\nweight_UWE\n🧬 Generación 48, mejor resultado: 0.7346252187845747\ntraining\nnum_epoch\ntraining\nlearning_rate\n🧬 Generación 49, mejor resultado: 0.7346252187845747\ntraining\nlearning_rate\nmodel\nweight_pos\ntraining\nlearning_rate\nmodel\nweight_neg\ntraining\nbatch_size\nmodel\ntemperature\n🧬 Generación 50, mejor resultado: 0.7346252187845747\ntraining\nbatch_size\nmodel\nnum_topics\nmodel\nbeta_temp\ntraining\nnum_epoch\nmodel\nneg_topk\n🧬 Generación 51, mejor resultado: 0.7346252187845747\ntraining\nlearning_rate\ntraining\nnum_epoch\nmodel\nnum_topics\ntraining\nnum_epoch\nmodel\nnum_topics\n🧬 Generación 52, mejor resultado: 0.7346252187845747\ntraining\nlearning_rate\ntraining\nnum_epoch\ntraining\nnum_epoch\nmodel\nbeta_temp\nmodel\nnum_topics\n🧬 Generación 53, mejor resultado: 0.7346252187845747\ntraining\nnum_epoch\ntraining\nbatch_size\ntraining\nlearning_rate\ntraining\nnum_epoch\nmodel\nweight_pos\nmodel\nen1_units\nmodel\nnum_topics\n🧬 Generación 54, mejor resultado: 0.7346252187845747\ntraining\nlearning_rate\nmodel\nweight_UWE\ntraining\nlearning_rate\n🧬 Generación 55, mejor resultado: 0.7346252187845747\ntraining\nlearning_rate\ntraining\nbatch_size\nmodel\ndropout\ntraining\nlearning_rate\n🧬 Generación 56, mejor resultado: 0.7346252187845747\ntraining\nnum_epoch\ntraining\nbatch_size\nmodel\nbeta_temp\ntraining\nlearning_rate\nmodel\ntemperature\n🧬 Generación 57, mejor resultado: 0.7346252187845747\nmodel\nbeta_temp\ntraining\nbatch_size\ntraining\nbatch_size\nmodel\nen1_units\n🧬 Generación 58, mejor resultado: 0.7346252187845747\ntraining\nlearning_rate\nmodel\nnum_topics\nmodel\nen1_units\ntraining\nbatch_size\nmodel\nnum_topics\n🧬 Generación 59, mejor resultado: 0.7346252187845747\ntraining\nlearning_rate\nmodel\nnum_topics\ntraining\nnum_epoch\ntraining\nlearning_rate\nmodel\nweight_UWE\n🧬 Generación 60, mejor resultado: 0.7346252187845747\ntraining\nlearning_rate\nmodel\nnum_topics\ntraining\nlearning_rate\nmodel\nweight_UWE\nmodel\ndropout\n🧬 Generación 61, mejor resultado: 0.7346252187845747\ntraining\nbatch_size\nmodel\nen1_units\n🧬 Generación 62, mejor resultado: 0.7346252187845747\nmodel\ndropout\n🧬 Generación 63, mejor resultado: 0.7346252187845747\nmodel\ntemperature\ntraining\nnum_epoch\ntraining\nnum_epoch\nmodel\nweight_pos\ntraining\nnum_epoch\nmodel\nweight_UWE\nmodel\nneg_topk\n🧬 Generación 64, mejor resultado: 0.7346252187845747\nmodel\nweight_neg\nmodel\ndropout\nmodel\nweight_pos\nmodel\nweight_neg\nmodel\ntemperature\n🧬 Generación 65, mejor resultado: 0.7346252187845747\ntraining\nlearning_rate\ntraining\nbatch_size\nmodel\nweight_pos\ntraining\nlearning_rate\ntraining\nlearning_rate\ntraining\nbatch_size\n🧬 Generación 66, mejor resultado: 0.7346252187845747\nmodel\nweight_neg\nmodel\nen1_units\ntraining\nbatch_size\nmodel\nnum_topics\ntraining\nnum_epoch\n🧬 Generación 67, mejor resultado: 0.7346252187845747\ntraining\nbatch_size\nmodel\nweight_neg\ntraining\nbatch_size\ntraining\nnum_epoch\nmodel\nen1_units\nmodel\nnum_topics\ntraining\nlearning_rate\nmodel\nnum_topics\nmodel\nbeta_temp\ntraining\nnum_epoch\n🧬 Generación 68, mejor resultado: 0.7346252187845747\nmodel\nweight_pos\nmodel\nbeta_temp\nmodel\nweight_pos\ntraining\nlearning_rate\nmodel\nbeta_temp\nmodel\nweight_pos\n🧬 Generación 69, mejor resultado: 0.7346252187845747\ntraining\nlearning_rate\ntraining\nlearning_rate\nmodel\ntemperature\nmodel\ntemperature\ntraining\nbatch_size\n🧬 Generación 70, mejor resultado: 0.7346252187845747\nmodel\ntemperature\nmodel\nweight_neg\nmodel\nweight_neg\n🧬 Generación 71, mejor resultado: 0.7346252187845747\ntraining\nnum_epoch\nmodel\nweight_neg\nmodel\ndropout\ntraining\nbatch_size\n🧬 Generación 72, mejor resultado: 0.7346252187845747\ntraining\nnum_epoch\nmodel\nbeta_temp\ntraining\nbatch_size\ntraining\nlearning_rate\n🧬 Generación 73, mejor resultado: 0.7346252187845747\ntraining\nnum_epoch\nmodel\ndropout\nmodel\ntemperature\nmodel\nnum_topics\ntraining\nbatch_size\nmodel\nweight_neg\n🧬 Generación 74, mejor resultado: 0.7346252187845747\ntraining\nnum_epoch\nmodel\nneg_topk\nmodel\nneg_topk\nmodel\nneg_topk\nmodel\nen1_units\n🧬 Generación 75, mejor resultado: 0.7346252187845747\ntraining\nlearning_rate\nmodel\nweight_pos\ntraining\nnum_epoch\nmodel\nweight_UWE\ntraining\nlearning_rate\ntraining\nbatch_size\nmodel\nen1_units\n🧬 Generación 76, mejor resultado: 0.7346252187845747\nmodel\nbeta_temp\ntraining\nlearning_rate\ntraining\nnum_epoch\nmodel\nnum_topics\nmodel\nbeta_temp\nmodel\nen1_units\n🧬 Generación 77, mejor resultado: 0.7346252187845747\ntraining\nlearning_rate\ntraining\nbatch_size\nmodel\nnum_topics\nmodel\nen1_units\n🧬 Generación 78, mejor resultado: 0.7346252187845747\nmodel\nweight_pos\nmodel\nnum_topics\ntraining\nlearning_rate\nmodel\nweight_neg\ntraining\nnum_epoch\nmodel\nbeta_temp\n🧬 Generación 79, mejor resultado: 0.7346252187845747\nmodel\nweight_pos\nmodel\nweight_pos\ntraining\nlearning_rate\n🧬 Generación 80, mejor resultado: 0.7346252187845747\nmodel\nnum_topics\ntraining\nlearning_rate\n🧬 Generación 81, mejor resultado: 0.7346252187845747\ntraining\nnum_epoch\nmodel\nneg_topk\n🧬 Generación 82, mejor resultado: 0.7346252187845747\ntraining\nlearning_rate\nmodel\nneg_topk\ntraining\nlearning_rate\nmodel\nbeta_temp\ntraining\nlearning_rate\n🧬 Generación 83, mejor resultado: 0.7346252187845747\nmodel\nbeta_temp\nmodel\nen1_units\ntraining\nlearning_rate\ntraining\nnum_epoch\nmodel\ntemperature\ntraining\nbatch_size\ntraining\nnum_epoch\ntraining\nlearning_rate\ntraining\nbatch_size\n🧬 Generación 84, mejor resultado: 0.7346252187845747\nmodel\nen1_units\ntraining\nbatch_size\ntraining\nbatch_size\nmodel\nbeta_temp\nmodel\nweight_pos\ntraining\nbatch_size\n🧬 Generación 85, mejor resultado: 0.7346252187845747\nmodel\nnum_topics\nmodel\ndropout\nmodel\nweight_UWE\nmodel\ndropout\ntraining\nbatch_size\nmodel\nweight_pos\ntraining\nbatch_size\ntraining\nnum_epoch\nmodel\nweight_pos\n🧬 Generación 86, mejor resultado: 0.7346252187845747\ntraining\nbatch_size\ntraining\nbatch_size\nmodel\nneg_topk\ntraining\nnum_epoch\ntraining\nbatch_size\n🧬 Generación 87, mejor resultado: 0.7346252187845747\nmodel\nweight_UWE\nmodel\nweight_neg\ntraining\nlearning_rate\ntraining\nbatch_size\ntraining\nlearning_rate\nmodel\ntemperature\ntraining\nnum_epoch\ntraining\nbatch_size\ntraining\nbatch_size\nmodel\nweight_UWE\n🧬 Generación 88, mejor resultado: 0.7346252187845747\nmodel\nweight_pos\nmodel\nen1_units\nmodel\nneg_topk\nmodel\nbeta_temp\nmodel\ndropout\n🧬 Generación 89, mejor resultado: 0.7346252187845747\ntraining\nlearning_rate\ntraining\nnum_epoch\ntraining\nnum_epoch\ntraining\nlearning_rate\ntraining\nbatch_size\ntraining\nnum_epoch\n🧬 Generación 90, mejor resultado: 0.7346252187845747\ntraining\nbatch_size\ntraining\nbatch_size\ntraining\nbatch_size\nmodel\nnum_topics\n🧬 Generación 91, mejor resultado: 0.7346252187845747\nmodel\nneg_topk\nmodel\nweight_pos\nmodel\nweight_neg\ntraining\nnum_epoch\nmodel\ntemperature\n🧬 Generación 92, mejor resultado: 0.7346252187845747\ntraining\nbatch_size\ntraining\nbatch_size\nmodel\nneg_topk\ntraining\nlearning_rate\ntraining\nbatch_size\ntraining\nlearning_rate\nmodel\ndropout\ntraining\nbatch_size\n🧬 Generación 93, mejor resultado: 0.7346252187845747\nmodel\nen1_units\nmodel\nbeta_temp\n🧬 Generación 94, mejor resultado: 0.7346252187845747\ntraining\nbatch_size\ntraining\nlearning_rate\ntraining\nlearning_rate\nmodel\nnum_topics\nmodel\nneg_topk\ntraining\nbatch_size\nmodel\nnum_topics\ntraining\nbatch_size\nmodel\nnum_topics\n🧬 Generación 95, mejor resultado: 0.7346252187845747\ntraining\nnum_epoch\nmodel\nneg_topk\n🧬 Generación 96, mejor resultado: 0.7346252187845747\nmodel\nneg_topk\nmodel\nbeta_temp\ntraining\nbatch_size\ntraining\nlearning_rate\ntraining\nbatch_size\nmodel\nweight_neg\n🧬 Generación 97, mejor resultado: 0.7346252187845747\nmodel\nweight_neg\ntraining\nbatch_size\n🧬 Generación 98, mejor resultado: 0.7346252187845747\ntraining\nnum_epoch\nmodel\ndropout\ntraining\nnum_epoch\nmodel\ntemperature\ntraining\nlearning_rate\ntraining\nnum_epoch\ntraining\nlearning_rate\n🧬 Generación 99, mejor resultado: 0.7346252187845747\nmodel\nen1_units\ntraining\nbatch_size\nmodel\nnum_topics\nmodel\ntemperature\ntraining\nbatch_size\nmodel\ndropout\n🧬 Generación 100, mejor resultado: 0.7346252187845747\ntraining\nnum_epoch\ntraining\nnum_epoch\ntraining\nbatch_size\ntraining\nbatch_size\nmodel\nweight_neg\nmodel\nweight_neg\n{'model': {'num_topics': 20, 'en1_units': 50, 'dropout': 0.1, 'beta_temp': 1.5, 'temperature': 0.1, 'weight_neg': 5000000.0, 'weight_pos': 100.0, 'weight_UWE': 10000.0, 'neg_topk': 20}, 'training': {'learning_rate': 0.001, 'batch_size': 500, 'num_epoch': 800}}\n0.7346252187845747\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"## Evaluando resultados","metadata":{}},{"cell_type":"code","source":"results_path = '/kaggle/working/results'\nresults_path = [dir_.path for dir_ in os.scandir(results_path) if not dir_.is_file()]\n\nprint(len(results_path))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"old_tc = float('-inf')\nTC = []\nold_td = float('-inf')\nTD = []\nold_tc_td = float('-inf')\nTC_TD = []\n\nfor path in results_path:\n    with open(os.path.join(path, 'metrics_json.json'), 'r') as file:\n        metrics = json.load(file)\n\n    cr_tc = metrics[\"dynamic_TC\"]\n    if cr_tc >= old_tc:\n        with open(os.path.join(path, 'metrics_config.json'), 'r') as file:\n            new = json.load(file)\n        if cr_tc == old_tc:\n            TC.append((new, path))\n        else:\n            old_tc = cr_tc\n            TC = [(new, path)]\n\n    cr_td = metrics[\"dynamic_TD\"]\n    if cr_td >= old_td:\n        with open(os.path.join(path, 'metrics_config.json'), 'r') as file:\n            new = json.load(file)\n        if cr_td == old_td:\n            TD.append((new, path))\n        else:\n            old_td = cr_td\n            TD = [(new, path)]\n\n    cr_tc_td = 0.5 * cr_tc + 0.5 * cr_td\n    if cr_tc_td >= old_tc_td:\n        with open(os.path.join(path, 'metrics_config.json'), 'r') as file:\n            new = json.load(file)\n        if cr_tc_td == old_tc_td:\n            TC_TD.append((new, path))\n        else:\n            old_tc_td = cr_tc_td\n            TC_TD = [(new, path)]\n\nprint(TC)\nprint(len(TC))\nprint('-------------------------------------')\nprint(TD)\nprint(len(TD))\nprint('-------------------------------------')\nprint(TC_TD)\nprint(len(TC_TD))\n\nbest_results_path = './best_results'\nos.makedirs(best_results_path, exist_ok=True)\nsave_json(TC, os.path.join(best_results_path, 'best_tc.json'))\nsave_json(TD, os.path.join(best_results_path, 'best_td.json'))\nsave_json(TC_TD, os.path.join(best_results_path, 'best_tc_td.json'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T02:47:00.991244Z","iopub.execute_input":"2025-02-20T02:47:00.991553Z","iopub.status.idle":"2025-02-20T02:47:01.012252Z","shell.execute_reply.started":"2025-02-20T02:47:00.991530Z","shell.execute_reply":"2025-02-20T02:47:01.011313Z"}},"outputs":[{"name":"stdout","text":"[({'config': {'training': {'learning_rate': 0.01, 'batch_size': 500, 'num_epoch': 1000}, 'model': {'num_topics': 100, 'en1_units': 50, 'dropout': 0.5, 'beta_temp': 1.5, 'temperature': 0.2, 'weight_neg': 5000000.0, 'weight_pos': 100.0, 'weight_UWE': 10000.0, 'neg_topk': 10}}, 'metrics': {'dynamic_TC': 0.6263097214101826, 'dynamic_TD': 0.335939393939394, 'clustering': {'Purity': 0.34498480243161095, 'NMI': 0.21334602154627538}, 'classification': {'acc': 0.3541033434650456, 'macro-F1': 0.12100456580356023}}}, '/kaggle/working/results/55')]\n1\n-------------------------------------\n[({'config': {'model': {'num_topics': 20, 'en1_units': 50, 'dropout': 0.1, 'beta_temp': 1.5, 'temperature': 0.1, 'weight_neg': 5000000.0, 'weight_pos': 100.0, 'weight_UWE': 10000.0, 'neg_topk': 20}, 'training': {'learning_rate': 0.001, 'batch_size': 500, 'num_epoch': 800}}, 'metrics': {'dynamic_TC': 0.5281898315085433, 'dynamic_TD': 0.941060606060606, 'clustering': {'Purity': 0.3844984802431611, 'NMI': 0.27302451565895586}, 'classification': {'acc': 0.44072948328267475, 'macro-F1': 0.25758355345077905}}}, '/kaggle/working/results/84')]\n1\n-------------------------------------\n[({'config': {'model': {'num_topics': 20, 'en1_units': 50, 'dropout': 0.1, 'beta_temp': 1.5, 'temperature': 0.1, 'weight_neg': 5000000.0, 'weight_pos': 100.0, 'weight_UWE': 10000.0, 'neg_topk': 20}, 'training': {'learning_rate': 0.001, 'batch_size': 500, 'num_epoch': 800}}, 'metrics': {'dynamic_TC': 0.5281898315085433, 'dynamic_TD': 0.941060606060606, 'clustering': {'Purity': 0.3844984802431611, 'NMI': 0.27302451565895586}, 'classification': {'acc': 0.44072948328267475, 'macro-F1': 0.25758355345077905}}}, '/kaggle/working/results/84')]\n1\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"!zip -r best_results/best_results.zip /kaggle/working/results/84","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:20:34.638850Z","iopub.execute_input":"2025-01-31T06:20:34.639162Z","iopub.status.idle":"2025-01-31T06:20:34.779459Z","shell.execute_reply.started":"2025-01-31T06:20:34.639138Z","shell.execute_reply":"2025-01-31T06:20:34.778116Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import joblib\ntop_words = joblib.load('/kaggle/working/results/84/top_words.joblib')\nprint(top_words)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Prueba unica","metadata":{}},{"cell_type":"code","source":"        config = {\"model\": {\"num_topics\": 20, \"en1_units\": 50, \"dropout\": 0.1, \"beta_temp\": 1.5, \"temperature\": 0.1, \"weight_neg\": 5000000.0, \"weight_pos\": 100.0, \"weight_UWE\": 10000.0, \"neg_topk\": 20}, \"training\": {\"learning_rate\": 0.001, \"batch_size\": 500, \"num_epoch\": 800}}\n\n        model = topmost.CFDTM(\n        vocab_size=dataset.vocab_size,\n        train_time_wordfreq=dataset.train_time_wordfreq,\n        num_times=dataset.num_times,\n        pretrained_WE=dataset.pretrained_WE,\n        num_topics=config[\"model\"][\"num_topics\"],\n        en_units=config[\"model\"][\"en1_units\"],\n        temperature=config[\"model\"][\"temperature\"],\n        beta_temp=config[\"model\"][\"beta_temp\"],\n        weight_neg=config[\"model\"][\"weight_neg\"],\n        weight_pos=config[\"model\"][\"weight_pos\"],\n        weight_UWE=config[\"model\"][\"weight_UWE\"],\n        neg_topk=config[\"model\"][\"neg_topk\"],\n        dropout=config[\"model\"][\"dropout\"],\n        embed_size=300\n        )\n  \n        model = model.to(device)  \n        trainer = topmost.DynamicTrainer(model, dataset, batch_size=config[\"training\"][\"batch_size\"], learning_rate=config[\"training\"][\"learning_rate\"], epochs=config[\"training\"][\"num_epoch\"])\n        top_words, _ = trainer.train()\n        metrics_json, dynamic_TC, dynamic_TD, clustering, classification = eval(top_words, trainer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:09:33.689392Z","iopub.execute_input":"2025-02-07T08:09:33.689750Z","iopub.status.idle":"2025-02-07T08:21:18.968931Z","shell.execute_reply.started":"2025-02-07T08:09:33.689721Z","shell.execute_reply":"2025-02-07T08:21:18.968053Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" ## beta (================= es este)","metadata":{}},{"cell_type":"code","source":"import joblib\n#beta = model.get_beta()\n#print(beta)\nbeta = joblib.load('top_words/beta.joblib')\n\n#joblib.dump(beta, 'top_words/beta.joblib')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T21:10:35.173174Z","iopub.execute_input":"2025-02-07T21:10:35.173515Z","iopub.status.idle":"2025-02-07T21:10:38.473146Z","shell.execute_reply.started":"2025-02-07T21:10:35.173485Z","shell.execute_reply":"2025-02-07T21:10:38.472199Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(beta.shape[0])\nprint(beta.shape[1])\nprint(beta.shape[2])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T21:14:01.476641Z","iopub.execute_input":"2025-02-07T21:14:01.476943Z","iopub.status.idle":"2025-02-07T21:14:01.482173Z","shell.execute_reply.started":"2025-02-07T21:14:01.476923Z","shell.execute_reply":"2025-02-07T21:14:01.481488Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\ndef get_top_words(num=10):\n    top_words_path = f'./top_words/{num}top_words_per_topics_model149'\n    path_0 = os.path.join(top_words_path, 'separate_by_space')\n    path_1 = os.path.join(top_words_path, 'separate_by_\\n')\n    # os.makedirs(top_words_path, exist_ok=True)\n    os.makedirs(path_0, exist_ok=True)\n    os.makedirs(path_1, exist_ok=True)\n\n    top_words = []\n    for topic in range(beta.shape[1]):\n        # el range comienza en 9 para comenzar a partir del anno 2010\n        top_words.append([[vocab[idx.item()] for idx in torch.topk(beta[time][topic], k=num).indices] for time in range(9, beta.shape[0])])\n    # print(len(top_words))\n    # print(len(top_words[0]))\n    joblib.dump(top_words, f'{top_words_path}/{num}top_words_topic_149.joblib')\n\n    print('Numero de topicos: ', len(top_words))\n    print('Numero de annos: ', len(top_words[0]))\n\n    \n    for j, topic in enumerate(top_words):\n        text = '' # 'Time 2003-2024 \\n\\n'\n        text_1 = ''\n        for i, time in enumerate(topic):\n            text += f'{2012 + i}: ' + ' '.join(time) + '\\n\\n'\n            text_1 += f'{2012 + i}\\n' + '\\n'.join(time) + '\\n\\n'\n        with open(os.path.join(path_0, f'{j}.txt'), 'w') as file:\n            file.write(text)\n        with open(os.path.join(path_1, f'{j}.txt'), 'w') as file:\n            file.write(text_1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T18:35:21.954600Z","iopub.execute_input":"2025-02-08T18:35:21.954911Z","iopub.status.idle":"2025-02-08T18:35:21.962154Z","shell.execute_reply.started":"2025-02-08T18:35:21.954888Z","shell.execute_reply":"2025-02-08T18:35:21.961227Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!zip -r /kaggle/working/top_words/top_words_per_topics_model149.zip /kaggle/working/top_words","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T18:35:43.347152Z","iopub.execute_input":"2025-02-08T18:35:43.347446Z","iopub.status.idle":"2025-02-08T18:35:45.729804Z","shell.execute_reply.started":"2025-02-08T18:35:43.347424Z","shell.execute_reply":"2025-02-08T18:35:45.728502Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nvocab_path = '/kaggle/input/revista-de-ciencias-mdicas-de-la-habana-cuba/vocab.txt'\nwith open(vocab_path, 'r') as file:\n    words = file.readlines()\n    vocab = [word.replace('\\n', '') for word in words]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T21:10:56.645485Z","iopub.execute_input":"2025-02-07T21:10:56.645845Z","iopub.status.idle":"2025-02-07T21:10:56.667752Z","shell.execute_reply.started":"2025-02-07T21:10:56.645818Z","shell.execute_reply":"2025-02-07T21:10:56.667066Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for num in [10, 15, 20, 25, 30]:\n    get_top_words(num)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T18:35:32.842151Z","iopub.execute_input":"2025-02-08T18:35:32.842439Z","iopub.status.idle":"2025-02-08T18:35:33.606741Z","shell.execute_reply.started":"2025-02-08T18:35:32.842415Z","shell.execute_reply":"2025-02-08T18:35:33.606037Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for num in [10, 15, 20, 25, 30]:\n    os.remove(f'/kaggle/working/{num}top_words_topic_149.joblib')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualizar heatmap","metadata":{}},{"cell_type":"markdown","source":"## Visualize (================= es este)","metadata":{}},{"cell_type":"code","source":"import os\nvocab_path = '/kaggle/input/revista-de-ciencias-mdicas-de-la-habana-cuba/vocab.txt'\nwith open(vocab_path, 'r') as file:\n    words = file.readlines()\n    vocab = [word.replace('\\n', '') for word in words]\n\nimport joblib\nbeta = joblib.load('top_words/beta.joblib')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T00:56:27.472409Z","iopub.execute_input":"2025-02-10T00:56:27.472597Z","iopub.status.idle":"2025-02-10T00:56:27.578950Z","shell.execute_reply.started":"2025-02-10T00:56:27.472578Z","shell.execute_reply":"2025-02-10T00:56:27.578181Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install unidecode","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T00:58:06.258713Z","iopub.execute_input":"2025-02-10T00:58:06.259021Z","iopub.status.idle":"2025-02-10T00:58:10.936372Z","shell.execute_reply.started":"2025-02-10T00:58:06.258997Z","shell.execute_reply":"2025-02-10T00:58:10.935503Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef get_mapa_color(words, word_idxs, topic_name, path, annot_kws_size=8):\n    data = dict()\n    for time in range(9, 22):\n        for word_idx in word_idxs:\n            data[2003 + time] = data.get(2003 + time, []) + [beta[time][topic][word_idx].item()]\n\n    df = pd.DataFrame(data, index=words)\n\n    plt.figure(figsize=(10, 8))\n    #sns.heatmap(df, cmap='Spectral', annot=True, fmt='d', cbar=True)\n    sns.heatmap(df, cmap='Reds', annot=True, fmt='.2f', cbar=True, annot_kws={'size': annot_kws_size})\n    #sns.heatmap(df, cmap='Blues', annot=True, fmt='d', cbar=True)\n    #sns.heatmap(df, cmap='Reds', annot=True, fmt='d', cbar=True)\n\n    # Leyenda\n    plt.title(f\"Mapa de Calor de Palabras por Año. {topic_name}\", fontsize=16)\n    plt.xlabel(\"Año\", fontsize=10)\n    plt.ylabel(\"Palabras Clave\", fontsize=12)\n\n    plt.savefig(path)\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T00:58:48.580658Z","iopub.execute_input":"2025-02-10T00:58:48.581165Z","iopub.status.idle":"2025-02-10T00:58:49.662781Z","shell.execute_reply.started":"2025-02-10T00:58:48.581118Z","shell.execute_reply":"2025-02-10T00:58:49.661915Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from unidecode import unidecode\nimages_path = './images'\n\ndef get_word_index(word):\n    return vocab.index(unidecode(word)) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T00:58:30.179139Z","iopub.execute_input":"2025-02-10T00:58:30.179473Z","iopub.status.idle":"2025-02-10T00:58:30.188105Z","shell.execute_reply.started":"2025-02-10T00:58:30.179444Z","shell.execute_reply":"2025-02-10T00:58:30.187275Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Topic 0","metadata":{}},{"cell_type":"code","source":"topic = 0\ntopic_name = 'Tópico#0'\ntopic_path_img = f'{images_path}/topic_0/probabilidad.png'\nos.makedirs(f'{images_path}/topic_0', exist_ok=True)\ntopic_path_img = f'{images_path}/topic_0/mapa_de_color.png'\n\nwords = ['laboral', 'uso', 'medio', 'nivel', 'permite', 'mala', 'abierto', 'cuestionario', \n             'confianza', 'burnout', 'anemia', 'acceso', 'comerciales', 'estudiantes', 'conocimiento', \n             'fatiga', 'digitales', 'ruido', 'videos']\nword_index = [get_word_index(word) for word in words] \nget_mapa_color(words, word_index, topic_name, topic_path_img)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T00:59:00.730772Z","iopub.execute_input":"2025-02-10T00:59:00.731183Z","iopub.status.idle":"2025-02-10T00:59:02.095805Z","shell.execute_reply.started":"2025-02-10T00:59:00.731160Z","shell.execute_reply":"2025-02-10T00:59:02.094781Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Topico 1","metadata":{}},{"cell_type":"code","source":"import os\ntopic = 1\ntopic_name = f'Tópico#{topic}'\nos.makedirs(f'{images_path}/topic_{topic}', exist_ok=True)\n# topic_path_img = f'{images_path}/topic_0/probabilidad.png'\ntopic_path_img = f'{images_path}/topic_{topic}/mapa_de_color.png'\n\nwords = [\n    'historia', 'universidad', 'habana', 'medicina', 'cubana', 'cuba', 'cubanos', 'doctor', 'bloqueo', 'unidos', 'tropical', 'academia',\n    'dorta', 'contreras', 'angiostrongylus', 'cantonensis', 'siglo', 'xix', 'carlos', 'instituto', 'universidad', 'hospital'\n]\n\nword_index = [get_word_index(word) for word in words]       \nget_mapa_color(words, word_index, topic_name, topic_path_img)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T00:59:22.161209Z","iopub.execute_input":"2025-02-10T00:59:22.161535Z","iopub.status.idle":"2025-02-10T00:59:23.386727Z","shell.execute_reply.started":"2025-02-10T00:59:22.161505Z","shell.execute_reply":"2025-02-10T00:59:23.385965Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Topic 3","metadata":{}},{"cell_type":"code","source":"import os\ntopic = 3\ntopic_name = f'Tópico#{topic}'\nos.makedirs(f'{images_path}/topic_{topic}', exist_ok=True)\n# topic_path_img = f'{images_path}/topic_0/probabilidad.png'\ntopic_path_img = f'{images_path}/topic_{topic}/mapa_de_color.png'\n\nwords = [\n    'contenidos', 'habilidades', 'estudiante', 'plan', 'preguntas', 'carrera', 'instrumento', 'voz', 'lengua', 'sonidos', 'fuerza', 'english', \n    'sugerencias', 'clases', 'palabras', 'puntos', 'instrumento', 'ejercicio', 'preguntas', 'profesores', 'encuesta', 'cada', 'etapa', \n    'pruebas', 'entrenamiento', 'dificultad', 'recomendaciones', 'vacuna', 'vacunas', 'paso', 'producto','estrategia', 'etapa',\n    'asignatura', 'basadas', 'examen'\n]\n\nget_mapa_color(words, word_index, topic_name, topic_path_img)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T00:59:41.922218Z","iopub.execute_input":"2025-02-10T00:59:41.922507Z","iopub.status.idle":"2025-02-10T00:59:43.897415Z","shell.execute_reply.started":"2025-02-10T00:59:41.922483Z","shell.execute_reply":"2025-02-10T00:59:43.896468Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\ntopic = 7\ntopic_name = f'Tópico#{topic}'\nos.makedirs(f'{images_path}/topic_{topic}', exist_ok=True)\n# topic_path_img = f'{images_path}/topic_0/probabilidad.png'\ntopic_path_img = f'{images_path}/topic_{topic}/mapa_de_color.png'\n\nwords = [\n    'sida', 'vih', 'sexual', 'familiar', 'familia', 'vida', 'padres', 'mujeres', 'ancianos', 'envejecimiento', 'suicidio', 'relaciones', 'adolescentes',\n    'personas', 'sexual', 'consumo', 'mental', 'estigma', 'conductas', 'cuidadores', 'trastorno', 'bipolar', 'intento', 'alcohol', 'demencia', 'estilos',\n     'conducta', 'adultos'\n]\n\nget_mapa_color(words, word_index, topic_name, topic_path_img)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T01:01:24.701864Z","iopub.execute_input":"2025-02-10T01:01:24.702228Z","iopub.status.idle":"2025-02-10T01:01:26.268153Z","shell.execute_reply.started":"2025-02-10T01:01:24.702198Z","shell.execute_reply":"2025-02-10T01:01:26.267172Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\ntopic = 8\ntopic_name = f'Tópico#{topic}'\nos.makedirs(f'{images_path}/topic_{topic}', exist_ok=True)\n# topic_path_img = f'{images_path}/topic_0/probabilidad.png'\ntopic_path_img = f'{images_path}/topic_{topic}/mapa_de_color.png'\n\nwords = [ 'vigilancia', 'datos', 'casos', 'provincia', 'centros', 'fallecidos', 'red', 'disponible', 'muestras', 'fuente', 'intoxicaciones', 'ocurrencia',\n         'consultas', 'agudos', 'fuente', 'alarma', 'dengue', 'lambayeque', 'pandemia', 'resistencia', 'impacto',\n'cubanas', 'covid', 'competitividad', 'gobiernos', 'coronavirus', 'mortalidad', 'cov', 'sars', 'modelos', 'internet', 'dosis'\n]\n\nget_mapa_color(words, word_index, topic_name, topic_path_img)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T01:01:45.718669Z","iopub.execute_input":"2025-02-10T01:01:45.718983Z","iopub.status.idle":"2025-02-10T01:01:47.411936Z","shell.execute_reply.started":"2025-02-10T01:01:45.718958Z","shell.execute_reply":"2025-02-10T01:01:47.411047Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\ntopic = 9\ntopic_name = f'Tópico#{topic}'\nos.makedirs(f'{images_path}/topic_{topic}', exist_ok=True)\n# topic_path_img = f'{images_path}/topic_0/probabilidad.png'\ntopic_path_img = f'{images_path}/topic_{topic}/mapa_de_color.png'\n\nwords = [ 'hallazgos', 'lesiones', 'complicaciones', 'frecuentes', 'imagen', 'abdominal', 'fiebre', 'caso',  'quistes', 'intestinal', 'biopsia', 'frecuentes',\n         'carcinoma', 'von']\n\nget_mapa_color(words, word_index, topic_name, topic_path_img)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T01:02:07.408672Z","iopub.execute_input":"2025-02-10T01:02:07.408984Z","iopub.status.idle":"2025-02-10T01:02:08.487013Z","shell.execute_reply.started":"2025-02-10T01:02:07.408959Z","shell.execute_reply":"2025-02-10T01:02:08.486078Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\ntopic = 10\ntopic_name = f'Tópico#{topic}'\nos.makedirs(f'{images_path}/topic_{topic}', exist_ok=True)\n# topic_path_img = f'{images_path}/topic_0/probabilidad.png'\ntopic_path_img = f'{images_path}/topic_{topic}/mapa_de_color.png'\n\nwords = [\n    'pylori', 'seguimiento', 'helicobacter', 'reportado', 'temporal',\n'linfoma', 'manifestaciones', 'varicela', 'zoster', 'serial',\n'gigantes', 'fetal', 'nervio', 'mano', 'ojo', 'síndrome', 'visual', 'seco', \n    'johnson', 'mediano', 'superficie', 'seguimiento', 'cuadro', \n    'aparece', 'entidad', 'consulta'\n]\n\nget_mapa_color(words, word_index, topic_name, topic_path_img)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T01:02:51.406659Z","iopub.execute_input":"2025-02-10T01:02:51.406999Z","iopub.status.idle":"2025-02-10T01:02:52.813254Z","shell.execute_reply.started":"2025-02-10T01:02:51.406971Z","shell.execute_reply":"2025-02-10T01:02:52.812425Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!zip -r /kaggle/working/images.zip /kaggle/working/images","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T01:03:55.157260Z","iopub.execute_input":"2025-02-10T01:03:55.157557Z","iopub.status.idle":"2025-02-10T01:03:55.343708Z","shell.execute_reply.started":"2025-02-10T01:03:55.157532Z","shell.execute_reply":"2025-02-10T01:03:55.342904Z"}},"outputs":[],"execution_count":null}]}