{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10685499,"sourceType":"datasetVersion","datasetId":6553770}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install topmost","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:14:10.823478Z","iopub.execute_input":"2025-02-22T17:14:10.823820Z","iopub.status.idle":"2025-02-22T17:14:14.261715Z","shell.execute_reply.started":"2025-02-22T17:14:10.823792Z","shell.execute_reply":"2025-02-22T17:14:14.260694Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: topmost in /usr/local/lib/python3.10/dist-packages (1.0.1)\nRequirement already satisfied: numpy<1.27.0 in /usr/local/lib/python3.10/dist-packages (from topmost) (1.26.4)\nRequirement already satisfied: scipy<=1.10.1 in /usr/local/lib/python3.10/dist-packages (from topmost) (1.10.1)\nRequirement already satisfied: sentence-transformers<3.0.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from topmost) (2.7.0)\nRequirement already satisfied: torchvision>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from topmost) (0.20.1+cu121)\nRequirement already satisfied: gensim>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from topmost) (4.3.3)\nRequirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from topmost) (1.2.2)\nRequirement already satisfied: tqdm>=4.66.0 in /usr/local/lib/python3.10/dist-packages (from topmost) (4.67.1)\nRequirement already satisfied: fastopic>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from topmost) (1.0.0)\nRequirement already satisfied: bertopic>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from topmost) (0.16.4)\nRequirement already satisfied: hdbscan>=0.8.29 in /usr/local/lib/python3.10/dist-packages (from bertopic>=0.15.0->topmost) (0.8.40)\nRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from bertopic>=0.15.0->topmost) (2.2.2)\nRequirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from bertopic>=0.15.0->topmost) (5.24.1)\nRequirement already satisfied: umap-learn>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from bertopic>=0.15.0->topmost) (0.5.7)\nRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim>=4.2.0->topmost) (7.0.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<1.27.0->topmost) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<1.27.0->topmost) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<1.27.0->topmost) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<1.27.0->topmost) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<1.27.0->topmost) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<1.27.0->topmost) (2.4.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->topmost) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->topmost) (3.5.0)\nRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.6.0->topmost) (4.47.0)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.6.0->topmost) (2.5.1+cu121)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.6.0->topmost) (0.27.0)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.6.0->topmost) (11.0.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (2024.9.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (1.3.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (2.32.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic>=0.15.0->topmost) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic>=0.15.0->topmost) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic>=0.15.0->topmost) (2024.2)\nRequirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic>=0.15.0->topmost) (9.0.0)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim>=4.2.0->topmost) (1.17.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (0.4.5)\nRequirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.0->bertopic>=0.15.0->topmost) (0.60.0)\nRequirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.0->bertopic>=0.15.0->topmost) (0.5.13)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<1.27.0->topmost) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<1.27.0->topmost) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<1.27.0->topmost) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<1.27.0->topmost) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<1.27.0->topmost) (2024.2.0)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic>=0.15.0->topmost) (0.43.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic>=0.15.0->topmost) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (2024.12.14)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import topmost\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:14:19.782693Z","iopub.execute_input":"2025-02-22T17:14:19.783026Z","iopub.status.idle":"2025-02-22T17:14:46.081423Z","shell.execute_reply.started":"2025-02-22T17:14:19.782997Z","shell.execute_reply":"2025-02-22T17:14:46.080746Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"device = \"cuda\"  # or \"cpu\"\ndataset_dir = \"/kaggle/input/revista-de-ciencias-mdicas-de-la-habana-cuba\"\noutput_dir = \"./results\"\nos.makedirs(output_dir, exist_ok=True)\n\ndataset = topmost.data.DynamicDataset(dataset_dir, batch_size=200, read_labels=True, device=device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:15:03.306156Z","iopub.execute_input":"2025-02-22T17:15:03.306957Z","iopub.status.idle":"2025-02-22T17:15:04.591983Z","shell.execute_reply.started":"2025-02-22T17:15:03.306922Z","shell.execute_reply":"2025-02-22T17:15:04.590967Z"}},"outputs":[{"name":"stdout","text":"train size:  1208\ntest size:  658\nvocab size:  19384\naverage length: 1335.378\nnum of each time slice:  22 [20 34 46 41 56 20 76 58 43 54 83 71 64 67 63 60 55 83 75 58 57 24]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import random\nimport joblib\nimport json\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:15:27.142789Z","iopub.execute_input":"2025-02-22T17:15:27.143133Z","iopub.status.idle":"2025-02-22T17:15:27.146927Z","shell.execute_reply.started":"2025-02-22T17:15:27.143105Z","shell.execute_reply":"2025-02-22T17:15:27.145960Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def save_txt(obj, path):\n    with open(path, 'w') as file:\n        file.write(obj)\n\ndef save_top_words_txt(top_words, path):\n    with open(os.path.join(path, 'top_words.txt'), 'w') as file:\n        for i, time in enumerate(top_words):\n            file.write(f'================= Time {i} ================= \\n')\n            for j, topic in enumerate(time):\n                file.write(f'================= Topic {j} ================= \\n')\n                file.write(f'{topic}')\n                file.write('\\n')\n            file.write('\\n')\n\ndef save_json(obj, path):\n    with open(path, 'w') as file:\n        json.dump(obj, file)\n\ndef save_joblib(obj, path):\n    joblib.dump(obj, path)\n\ndef save_result(top_words, trainer, config, metrics_json):\n    global samples \n    path = os.path.join(output_dir, f'{samples}')\n    os.makedirs(path, exist_ok=True)\n\n    try:\n        save_top_words_txt(top_words, path)\n        save_json(config, os.path.join(path, 'hyperparameters.json'))\n        save_json(metrics_json, os.path.join(path, 'metrics_json.json'))\n        save_json({\"config\": config, \"metrics\": metrics_json}, os.path.join(path, 'metrics_config.json'))\n        # save_joblib(trainer, os.path.join(path, 'trainer.joblib'))\n        save_joblib(top_words, os.path.join(path, 'top_words.joblib'))\n        print('🍀 Saved')\n    except Exception as e:\n        traceback.print_exc(e)        \n\ndef get_hyperparameter_space():\n    return {\n  \"training\": {\n    \"learning_rate\": [0.001, 0.002, 0.005, 0.01],\n    \"batch_size\": [100, 200, 300, 500],\n    \"num_epoch\": [400, 600, 800, 1000]\n  },\n  \"model\": {\n    \"num_topics\": [20, 50, 100],\n    \"en1_units\": [50, 100, 200, 300],\n    \"dropout\": [0.0, 0.1, 0.3, 0.5],\n    \"beta_temp\": [0.5, 1.0, 1.5, 2.0],\n    \"temperature\": [0.05, 0.1, 0.2, 0.5],\n    \"weight_neg\": [1e6, 5e6, 1e7, 1e8],\n    \"weight_pos\": [1.0, 10.0, 100.0],\n    \"weight_UWE\": [1e2, 1e3, 1e4],\n    \"neg_topk\": [5, 10, 15, 20, 30]\n  }\n}\n\ndef get_default_config():\n    return { \"training\": {\n                \"learning_rate\": 0.002,\n                \"batch_size\": 200,\n                \"num_epoch\": 800 },\n\n            \"model\": {\n                \"num_topics\": 50,\n                \"en1_units\": 100,\n                \"dropout\": 0. , \n                \"beta_temp\": 1.0,\n                \"temperature\": 0.1,\n                \"weight_neg\": 1.0e+7,\n                \"weight_pos\": 1.0e+1,\n                \"weight_UWE\": 1.0e+3,\n                \"neg_topk\": 15 }\n           }\n\ndef random_configuration(hyperparameter_space):\n    return { \"training\": {\n                \"learning_rate\": random.choice(hyperparameter_space[\"training\"][\"learning_rate\"]),\n                \"batch_size\": random.choice(hyperparameter_space[\"training\"][\"batch_size\"]),\n                \"num_epoch\": random.choice(hyperparameter_space[\"training\"][\"num_epoch\"]) },\n\n            \"model\": {\n                \"num_topics\": random.choice(hyperparameter_space[\"model\"][\"num_topics\"]),\n                \"en1_units\": random.choice(hyperparameter_space[\"model\"][\"en1_units\"]),\n                \"dropout\": random.choice(hyperparameter_space[\"model\"][\"dropout\"]) , \n                \"beta_temp\": random.choice(hyperparameter_space[\"model\"][\"beta_temp\"]),\n                \"temperature\": random.choice(hyperparameter_space[\"model\"][\"temperature\"]),\n                \"weight_neg\": random.choice(hyperparameter_space[\"model\"][\"weight_neg\"]),\n                \"weight_pos\": random.choice(hyperparameter_space[\"model\"][\"weight_pos\"]),\n                \"weight_UWE\": random.choice(hyperparameter_space[\"model\"][\"weight_UWE\"]),\n                \"neg_topk\":random.choice(hyperparameter_space[\"model\"][\"neg_topk\"]) }\n           }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:15:33.330536Z","iopub.execute_input":"2025-02-22T17:15:33.330856Z","iopub.status.idle":"2025-02-22T17:15:33.343351Z","shell.execute_reply.started":"2025-02-22T17:15:33.330832Z","shell.execute_reply":"2025-02-22T17:15:33.342334Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Hyperparameters Search","metadata":{}},{"cell_type":"markdown","source":"## - Evaluacion","metadata":{}},{"cell_type":"code","source":"########################### Evaluate ####################################\nimport numpy as np\nfrom topmost import eva\nfrom gensim.corpora import Dictionary\nfrom gensim.models import CoherenceModel\nfrom topmost.data.file_utils import split_text_word","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:15:39.045995Z","iopub.execute_input":"2025-02-22T17:15:39.046359Z","iopub.status.idle":"2025-02-22T17:15:39.050425Z","shell.execute_reply.started":"2025-02-22T17:15:39.046325Z","shell.execute_reply":"2025-02-22T17:15:39.049494Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def _coherence_modified(reference_corpus, vocab, top_words, cv_type='c_v'):\n    # print('🍀')\n    \n    split_top_words = split_text_word(top_words)\n    num_top_words = len(split_top_words[0])\n    for item in split_top_words:\n        assert num_top_words == len(item)\n\n    split_reference_corpus = split_text_word(reference_corpus)\n    dictionary = Dictionary(split_text_word(vocab))\n\n    cm = CoherenceModel(texts=split_reference_corpus, dictionary=dictionary, topics=split_top_words, topn=num_top_words, coherence=cv_type)\n    cv_per_topic = cm.get_coherence_per_topic()\n    # print(f\"Coherence scores per topic: {cv_per_topic}\")\n\n    valid_scores = [score for score in cv_per_topic if not np.isnan(score)]\n    if not valid_scores:\n        # raise ValueError(\"All coherence scores are NaN.\")\n        return 0\n    score = np.mean(valid_scores)\n\n    return score\n    \neva.topic_coherence._coherence = _coherence_modified","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:15:43.139257Z","iopub.execute_input":"2025-02-22T17:15:43.139610Z","iopub.status.idle":"2025-02-22T17:15:43.144977Z","shell.execute_reply.started":"2025-02-22T17:15:43.139585Z","shell.execute_reply":"2025-02-22T17:15:43.143996Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def eval(trainer, top_words):\n    # get theta (doc-topic distributions)\n    train_theta, test_theta = trainer.export_theta()\n\n    train_times = dataset.train_times.cpu().numpy()\n    # compute topic coherence\n    dynamic_TC = eva.dynamic_coherence(dataset.train_texts, train_times, dataset.vocab, top_words)\n    print(\"dynamic_TC: \", dynamic_TC)\n\n    # compute topic diversity\n    dynamic_TD = eva.dynamic_diversity(top_words, dataset.train_bow.cpu().numpy(), train_times, dataset.vocab)\n    print(\"dynamic_TD: \", dynamic_TD)\n\n    # evaluate clustering\n    clustering = eva._clustering(test_theta, dataset.test_labels)\n    print(clustering)\n\n    # evaluate classification\n    classification = eva._cls(train_theta, test_theta, dataset.train_labels, dataset.test_labels)\n    print(classification)\n\n    json = {\n        \"dynamic_TC\": dynamic_TC,\n        \"dynamic_TD\": dynamic_TD,\n        \"clustering\": clustering,\n        \"classification\": classification\n    }\n    \n    return json, dynamic_TC, dynamic_TD, clustering, classification","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T04:39:39.265197Z","iopub.execute_input":"2025-02-22T04:39:39.265526Z","iopub.status.idle":"2025-02-22T04:39:39.270912Z","shell.execute_reply.started":"2025-02-22T04:39:39.265500Z","shell.execute_reply":"2025-02-22T04:39:39.270120Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## - Modelo","metadata":{}},{"cell_type":"code","source":"import traceback","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T04:28:05.463024Z","iopub.execute_input":"2025-02-22T04:28:05.463428Z","iopub.status.idle":"2025-02-22T04:28:05.467533Z","shell.execute_reply.started":"2025-02-22T04:28:05.463393Z","shell.execute_reply":"2025-02-22T04:28:05.466445Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def evaluate_configuration(config):\n    global tested_configs, samples\n    \n    config_key = json.dumps(config, sort_keys=True) \n    \n    if config_key in tested_configs:\n        return tested_configs[config_key]\n    \n    model = topmost.CFDTM(\n        vocab_size=dataset.vocab_size,\n        train_time_wordfreq=dataset.train_time_wordfreq,\n        num_times=dataset.num_times,\n        pretrained_WE=dataset.pretrained_WE,\n        num_topics=config[\"model\"][\"num_topics\"],\n        en_units=config[\"model\"][\"en1_units\"],\n        temperature=config[\"model\"][\"temperature\"],\n        beta_temp=config[\"model\"][\"beta_temp\"],\n        weight_neg=config[\"model\"][\"weight_neg\"],\n        weight_pos=config[\"model\"][\"weight_pos\"],\n        weight_UWE=config[\"model\"][\"weight_UWE\"],\n        neg_topk=config[\"model\"][\"neg_topk\"],\n        dropout=config[\"model\"][\"dropout\"],\n        embed_size=300\n    )\n  \n    model = model.to(device)  \n    trainer = topmost.DynamicTrainer(model, dataset, batch_size=config[\"training\"][\"batch_size\"], learning_rate=config[\"training\"][\"learning_rate\"], epochs=config[\"training\"][\"num_epoch\"])\n    top_words, _ = trainer.train()\n    \n    try:\n        metrics_json, dynamic_TC, dynamic_TD, clustering, classification = eval(top_words, trainer)\n        #tested_configs[config_key] = 0.5 * dynamic_TC + 0.5 * dynamic_TD\n        tested_configs[config_key] = {\"dynamic_TC\": dynamic_TC, \"dynamic_TD\": dynamic_TD}\n        save_result(top_words, trainer, config, metrics_json)\n        samples += 1\n    except Exception as e:\n        tested_configs[config_key] = {\"dynamic_TC\": float('-inf'), \"dynamic_TD\": float('-inf')}\n        print(e)\n        \n    save_joblib(tested_configs, os.path.join(output_dir, 'tested_configs.joblib'))\n    \n    return tested_configs[config_key]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T04:27:17.333133Z","iopub.execute_input":"2025-02-20T04:27:17.333427Z","iopub.status.idle":"2025-02-20T04:27:17.340437Z","shell.execute_reply.started":"2025-02-20T04:27:17.333407Z","shell.execute_reply":"2025-02-20T04:27:17.339516Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## - Algortimo evolutivo","metadata":{}},{"cell_type":"code","source":"def key_func(value):\n    try:\n        return 0.5 * value[1][\"dynamic_TC\"] + 0.5 * value[1][\"dynamic_TD\"]\n    except: \n        return value[1]\n\ndef evolutionary_search(search_space, generations=10, mutation_rate=0.1, population_size=20, population=None, generation_count=0):\n    global samples\n    \n    if not population:\n        population = [random_configuration(search_space) for _ in range(population_size - 1)]\n        population.append(get_default_config())\n\n    # print(population)\n    \n    for generation in range(generation_count, generations):\n        scores = [(config, evaluate_configuration(config)) for config in population]\n        scores.sort(key=key_func, reverse=True)  \n\n        print(f\"🧬 Generación {generation + 1}, mejor resultado: {scores[0][1]}\")\n        \n        num_parents = population_size // 2\n        parents = [config for config, _ in scores[:num_parents]]\n        \n        children = []\n        while len(children) < population_size - num_parents:\n            parent_1, parent_2 = random.sample(parents, 2)\n            child = {\n                \"model\": {key: random.choice([parent_1[\"model\"][key], parent_2[\"model\"][key]]) for key in search_space[\"model\"].keys()},\n                \"training\": {key: random.choice([parent_1[\"training\"][key], parent_2[\"training\"][key]]) for key in search_space[\"training\"].keys()},\n            }\n            \n            if random.random() < mutation_rate:\n                mutate_model_training = random.choice(list(search_space.keys()))\n                print(mutate_model_training)\n                param_to_mutate = random.choice(list(search_space[mutate_model_training].keys()))\n                print(param_to_mutate)\n                child[mutate_model_training][param_to_mutate] = random.choice(search_space[mutate_model_training][param_to_mutate])\n            \n            children.append(child)\n        \n        population = parents + children\n        joblib.dump(population, os.path.join(output_dir, 'population.joblib'))\n    \n    best_config, best_score = max(scores, key=key_func)\n    return best_config, best_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T04:28:12.046719Z","iopub.execute_input":"2025-02-22T04:28:12.047004Z","iopub.status.idle":"2025-02-22T04:28:12.054880Z","shell.execute_reply.started":"2025-02-22T04:28:12.046983Z","shell.execute_reply":"2025-02-22T04:28:12.054094Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Main","metadata":{}},{"cell_type":"code","source":"population_size = 50\n# population = None\npopulation = joblib.load(os.path.join(output_dir, 'population.joblib'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T04:27:33.451965Z","iopub.execute_input":"2025-02-20T04:27:33.452251Z","iopub.status.idle":"2025-02-20T04:27:33.458336Z","shell.execute_reply.started":"2025-02-20T04:27:33.452230Z","shell.execute_reply":"2025-02-20T04:27:33.457666Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"import joblib\n# tested_configs = dict()\ntested_configs = joblib.load('/kaggle/working/results/tested_configs.joblib')\n# print(tested_configs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T04:27:41.148070Z","iopub.execute_input":"2025-02-20T04:27:41.148340Z","iopub.status.idle":"2025-02-20T04:27:41.154027Z","shell.execute_reply.started":"2025-02-20T04:27:41.148320Z","shell.execute_reply":"2025-02-20T04:27:41.153160Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"results_path = '/kaggle/working/results'\nresults_path = [dir_.path for dir_ in os.scandir(results_path) if not dir_.is_file()]\n\nprint(len(results_path))\n\nsamples = len(results_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T04:27:50.443762Z","iopub.execute_input":"2025-02-20T04:27:50.444079Z","iopub.status.idle":"2025-02-20T04:27:50.449479Z","shell.execute_reply.started":"2025-02-20T04:27:50.444051Z","shell.execute_reply":"2025-02-20T04:27:50.448825Z"}},"outputs":[{"name":"stdout","text":"121\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"hyperparameter_space = get_hyperparameter_space()\n\nbest_config, best_score = evolutionary_search(hyperparameter_space, population_size=population_size, generations=100, mutation_rate=0.2, population=population)\nprint(best_config)\nprint(best_score)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Evaluando resultados","metadata":{}},{"cell_type":"code","source":"results_path = '/kaggle/working/results'\nresults_path = [dir_.path for dir_ in os.scandir(results_path) if not dir_.is_file()]\n\nprint(len(results_path))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"old_tc = float('-inf')\nTC = []\nold_td = float('-inf')\nTD = []\nold_tc_td = float('-inf')\nTC_TD = []\n\nfor path in results_path:\n    with open(os.path.join(path, 'metrics_json.json'), 'r') as file:\n        metrics = json.load(file)\n\n    cr_tc = metrics[\"dynamic_TC\"]\n    if cr_tc >= old_tc:\n        with open(os.path.join(path, 'metrics_config.json'), 'r') as file:\n            new = json.load(file)\n        if cr_tc == old_tc:\n            TC.append((new, path))\n        else:\n            old_tc = cr_tc\n            TC = [(new, path)]\n\n    cr_td = metrics[\"dynamic_TD\"]\n    if cr_td >= old_td:\n        with open(os.path.join(path, 'metrics_config.json'), 'r') as file:\n            new = json.load(file)\n        if cr_td == old_td:\n            TD.append((new, path))\n        else:\n            old_td = cr_td\n            TD = [(new, path)]\n\n    cr_tc_td = 0.5 * cr_tc + 0.5 * cr_td\n    if cr_tc_td >= old_tc_td:\n        with open(os.path.join(path, 'metrics_config.json'), 'r') as file:\n            new = json.load(file)\n        if cr_tc_td == old_tc_td:\n            TC_TD.append((new, path))\n        else:\n            old_tc_td = cr_tc_td\n            TC_TD = [(new, path)]\n\nprint(TC)\nprint(len(TC))\nprint('-------------------------------------')\nprint(TD)\nprint(len(TD))\nprint('-------------------------------------')\nprint(TC_TD)\nprint(len(TC_TD))\n\nbest_results_path = './best_results'\nos.makedirs(best_results_path, exist_ok=True)\nsave_json(TC, os.path.join(best_results_path, 'best_tc.json'))\nsave_json(TD, os.path.join(best_results_path, 'best_td.json'))\nsave_json(TC_TD, os.path.join(best_results_path, 'best_tc_td.json'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T02:47:00.991244Z","iopub.execute_input":"2025-02-20T02:47:00.991553Z","iopub.status.idle":"2025-02-20T02:47:01.012252Z","shell.execute_reply.started":"2025-02-20T02:47:00.991530Z","shell.execute_reply":"2025-02-20T02:47:01.011313Z"}},"outputs":[{"name":"stdout","text":"[({'config': {'training': {'learning_rate': 0.01, 'batch_size': 500, 'num_epoch': 1000}, 'model': {'num_topics': 100, 'en1_units': 50, 'dropout': 0.5, 'beta_temp': 1.5, 'temperature': 0.2, 'weight_neg': 5000000.0, 'weight_pos': 100.0, 'weight_UWE': 10000.0, 'neg_topk': 10}}, 'metrics': {'dynamic_TC': 0.6263097214101826, 'dynamic_TD': 0.335939393939394, 'clustering': {'Purity': 0.34498480243161095, 'NMI': 0.21334602154627538}, 'classification': {'acc': 0.3541033434650456, 'macro-F1': 0.12100456580356023}}}, '/kaggle/working/results/55')]\n1\n-------------------------------------\n[({'config': {'model': {'num_topics': 20, 'en1_units': 50, 'dropout': 0.1, 'beta_temp': 1.5, 'temperature': 0.1, 'weight_neg': 5000000.0, 'weight_pos': 100.0, 'weight_UWE': 10000.0, 'neg_topk': 20}, 'training': {'learning_rate': 0.001, 'batch_size': 500, 'num_epoch': 800}}, 'metrics': {'dynamic_TC': 0.5281898315085433, 'dynamic_TD': 0.941060606060606, 'clustering': {'Purity': 0.3844984802431611, 'NMI': 0.27302451565895586}, 'classification': {'acc': 0.44072948328267475, 'macro-F1': 0.25758355345077905}}}, '/kaggle/working/results/84')]\n1\n-------------------------------------\n[({'config': {'model': {'num_topics': 20, 'en1_units': 50, 'dropout': 0.1, 'beta_temp': 1.5, 'temperature': 0.1, 'weight_neg': 5000000.0, 'weight_pos': 100.0, 'weight_UWE': 10000.0, 'neg_topk': 20}, 'training': {'learning_rate': 0.001, 'batch_size': 500, 'num_epoch': 800}}, 'metrics': {'dynamic_TC': 0.5281898315085433, 'dynamic_TD': 0.941060606060606, 'clustering': {'Purity': 0.3844984802431611, 'NMI': 0.27302451565895586}, 'classification': {'acc': 0.44072948328267475, 'macro-F1': 0.25758355345077905}}}, '/kaggle/working/results/84')]\n1\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"!zip -r best_results/best_results.zip /kaggle/working/results/84","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:20:34.638850Z","iopub.execute_input":"2025-01-31T06:20:34.639162Z","iopub.status.idle":"2025-01-31T06:20:34.779459Z","shell.execute_reply.started":"2025-01-31T06:20:34.639138Z","shell.execute_reply":"2025-01-31T06:20:34.778116Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import joblib\ntop_words = joblib.load('/kaggle/working/results/84/top_words.joblib')\nprint(top_words)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Prueba unica","metadata":{}},{"cell_type":"code","source":"        config = {\"model\": {\"num_topics\": 20, \"en1_units\": 50, \"dropout\": 0.1, \"beta_temp\": 1.5, \"temperature\": 0.1, \"weight_neg\": 5000000.0, \"weight_pos\": 100.0, \"weight_UWE\": 10000.0, \"neg_topk\": 20}, \"training\": {\"learning_rate\": 0.001, \"batch_size\": 500, \"num_epoch\": 800}}\n\n        model = topmost.CFDTM(\n        vocab_size=dataset.vocab_size,\n        train_time_wordfreq=dataset.train_time_wordfreq,\n        num_times=dataset.num_times,\n        pretrained_WE=dataset.pretrained_WE,\n        num_topics=config[\"model\"][\"num_topics\"],\n        en_units=config[\"model\"][\"en1_units\"],\n        temperature=config[\"model\"][\"temperature\"],\n        beta_temp=config[\"model\"][\"beta_temp\"],\n        weight_neg=config[\"model\"][\"weight_neg\"],\n        weight_pos=config[\"model\"][\"weight_pos\"],\n        weight_UWE=config[\"model\"][\"weight_UWE\"],\n        neg_topk=config[\"model\"][\"neg_topk\"],\n        dropout=config[\"model\"][\"dropout\"],\n        embed_size=300\n        )\n  \n        model = model.to(device)  \n        trainer = topmost.DynamicTrainer(model, dataset, batch_size=config[\"training\"][\"batch_size\"], learning_rate=config[\"training\"][\"learning_rate\"], epochs=config[\"training\"][\"num_epoch\"])\n        top_words, _ = trainer.train()\n        metrics_json, dynamic_TC, dynamic_TD, clustering, classification = eval(top_words, trainer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T08:09:33.689392Z","iopub.execute_input":"2025-02-07T08:09:33.689750Z","iopub.status.idle":"2025-02-07T08:21:18.968931Z","shell.execute_reply.started":"2025-02-07T08:09:33.689721Z","shell.execute_reply":"2025-02-07T08:21:18.968053Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" ## beta (================= es este)","metadata":{}},{"cell_type":"code","source":"import joblib\n#beta = model.get_beta()\n#print(beta)\nbeta = joblib.load('top_words/beta.joblib')\n\n#joblib.dump(beta, 'top_words/beta.joblib')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T21:10:35.173174Z","iopub.execute_input":"2025-02-07T21:10:35.173515Z","iopub.status.idle":"2025-02-07T21:10:38.473146Z","shell.execute_reply.started":"2025-02-07T21:10:35.173485Z","shell.execute_reply":"2025-02-07T21:10:38.472199Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(beta.shape[0])\nprint(beta.shape[1])\nprint(beta.shape[2])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T21:14:01.476641Z","iopub.execute_input":"2025-02-07T21:14:01.476943Z","iopub.status.idle":"2025-02-07T21:14:01.482173Z","shell.execute_reply.started":"2025-02-07T21:14:01.476923Z","shell.execute_reply":"2025-02-07T21:14:01.481488Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\ndef get_top_words(num=10):\n    top_words_path = f'./top_words/{num}top_words_per_topics_model149'\n    path_0 = os.path.join(top_words_path, 'separate_by_space')\n    path_1 = os.path.join(top_words_path, 'separate_by_\\n')\n    # os.makedirs(top_words_path, exist_ok=True)\n    os.makedirs(path_0, exist_ok=True)\n    os.makedirs(path_1, exist_ok=True)\n\n    top_words = []\n    for topic in range(beta.shape[1]):\n        # el range comienza en 9 para comenzar a partir del anno 2010\n        top_words.append([[vocab[idx.item()] for idx in torch.topk(beta[time][topic], k=num).indices] for time in range(9, beta.shape[0])])\n    # print(len(top_words))\n    # print(len(top_words[0]))\n    joblib.dump(top_words, f'{top_words_path}/{num}top_words_topic_149.joblib')\n\n    print('Numero de topicos: ', len(top_words))\n    print('Numero de annos: ', len(top_words[0]))\n\n    \n    for j, topic in enumerate(top_words):\n        text = '' # 'Time 2003-2024 \\n\\n'\n        text_1 = ''\n        for i, time in enumerate(topic):\n            text += f'{2012 + i}: ' + ' '.join(time) + '\\n\\n'\n            text_1 += f'{2012 + i}\\n' + '\\n'.join(time) + '\\n\\n'\n        with open(os.path.join(path_0, f'{j}.txt'), 'w') as file:\n            file.write(text)\n        with open(os.path.join(path_1, f'{j}.txt'), 'w') as file:\n            file.write(text_1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T18:35:21.954600Z","iopub.execute_input":"2025-02-08T18:35:21.954911Z","iopub.status.idle":"2025-02-08T18:35:21.962154Z","shell.execute_reply.started":"2025-02-08T18:35:21.954888Z","shell.execute_reply":"2025-02-08T18:35:21.961227Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!zip -r /kaggle/working/top_words/top_words_per_topics_model149.zip /kaggle/working/top_words","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T18:35:43.347152Z","iopub.execute_input":"2025-02-08T18:35:43.347446Z","iopub.status.idle":"2025-02-08T18:35:45.729804Z","shell.execute_reply.started":"2025-02-08T18:35:43.347424Z","shell.execute_reply":"2025-02-08T18:35:45.728502Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nvocab_path = '/kaggle/input/revista-de-ciencias-mdicas-de-la-habana-cuba/vocab.txt'\nwith open(vocab_path, 'r') as file:\n    words = file.readlines()\n    vocab = [word.replace('\\n', '') for word in words]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T21:10:56.645485Z","iopub.execute_input":"2025-02-07T21:10:56.645845Z","iopub.status.idle":"2025-02-07T21:10:56.667752Z","shell.execute_reply.started":"2025-02-07T21:10:56.645818Z","shell.execute_reply":"2025-02-07T21:10:56.667066Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for num in [10, 15, 20, 25, 30]:\n    get_top_words(num)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T18:35:32.842151Z","iopub.execute_input":"2025-02-08T18:35:32.842439Z","iopub.status.idle":"2025-02-08T18:35:33.606741Z","shell.execute_reply.started":"2025-02-08T18:35:32.842415Z","shell.execute_reply":"2025-02-08T18:35:33.606037Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for num in [10, 15, 20, 25, 30]:\n    os.remove(f'/kaggle/working/{num}top_words_topic_149.joblib')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualizar heatmap","metadata":{}},{"cell_type":"markdown","source":"## Visualize (================= es este)","metadata":{}},{"cell_type":"code","source":"import os\nvocab_path = '/kaggle/input/revista-de-ciencias-mdicas-de-la-habana-cuba/vocab.txt'\nwith open(vocab_path, 'r') as file:\n    words = file.readlines()\n    vocab = [word.replace('\\n', '') for word in words]\n\nimport joblib\nbeta = joblib.load('top_words/beta.joblib')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T00:56:27.472409Z","iopub.execute_input":"2025-02-10T00:56:27.472597Z","iopub.status.idle":"2025-02-10T00:56:27.578950Z","shell.execute_reply.started":"2025-02-10T00:56:27.472578Z","shell.execute_reply":"2025-02-10T00:56:27.578181Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install unidecode","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T00:58:06.258713Z","iopub.execute_input":"2025-02-10T00:58:06.259021Z","iopub.status.idle":"2025-02-10T00:58:10.936372Z","shell.execute_reply.started":"2025-02-10T00:58:06.258997Z","shell.execute_reply":"2025-02-10T00:58:10.935503Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef get_mapa_color(words, word_idxs, topic_name, path, annot_kws_size=8):\n    data = dict()\n    for time in range(9, 22):\n        for word_idx in word_idxs:\n            data[2003 + time] = data.get(2003 + time, []) + [beta[time][topic][word_idx].item()]\n\n    df = pd.DataFrame(data, index=words)\n\n    plt.figure(figsize=(10, 8))\n    #sns.heatmap(df, cmap='Spectral', annot=True, fmt='d', cbar=True)\n    sns.heatmap(df, cmap='Reds', annot=True, fmt='.2f', cbar=True, annot_kws={'size': annot_kws_size})\n    #sns.heatmap(df, cmap='Blues', annot=True, fmt='d', cbar=True)\n    #sns.heatmap(df, cmap='Reds', annot=True, fmt='d', cbar=True)\n\n    # Leyenda\n    plt.title(f\"Mapa de Calor de Palabras por Año. {topic_name}\", fontsize=16)\n    plt.xlabel(\"Año\", fontsize=10)\n    plt.ylabel(\"Palabras Clave\", fontsize=12)\n\n    plt.savefig(path)\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T00:58:48.580658Z","iopub.execute_input":"2025-02-10T00:58:48.581165Z","iopub.status.idle":"2025-02-10T00:58:49.662781Z","shell.execute_reply.started":"2025-02-10T00:58:48.581118Z","shell.execute_reply":"2025-02-10T00:58:49.661915Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from unidecode import unidecode\nimages_path = './images'\n\ndef get_word_index(word):\n    return vocab.index(unidecode(word)) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T00:58:30.179139Z","iopub.execute_input":"2025-02-10T00:58:30.179473Z","iopub.status.idle":"2025-02-10T00:58:30.188105Z","shell.execute_reply.started":"2025-02-10T00:58:30.179444Z","shell.execute_reply":"2025-02-10T00:58:30.187275Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Topic 0","metadata":{}},{"cell_type":"code","source":"topic = 0\ntopic_name = 'Tópico#0'\ntopic_path_img = f'{images_path}/topic_0/probabilidad.png'\nos.makedirs(f'{images_path}/topic_0', exist_ok=True)\ntopic_path_img = f'{images_path}/topic_0/mapa_de_color.png'\n\nwords = ['laboral', 'uso', 'medio', 'nivel', 'permite', 'mala', 'abierto', 'cuestionario', \n             'confianza', 'burnout', 'anemia', 'acceso', 'comerciales', 'estudiantes', 'conocimiento', \n             'fatiga', 'digitales', 'ruido', 'videos']\nword_index = [get_word_index(word) for word in words] \nget_mapa_color(words, word_index, topic_name, topic_path_img)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T00:59:00.730772Z","iopub.execute_input":"2025-02-10T00:59:00.731183Z","iopub.status.idle":"2025-02-10T00:59:02.095805Z","shell.execute_reply.started":"2025-02-10T00:59:00.731160Z","shell.execute_reply":"2025-02-10T00:59:02.094781Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Topico 1","metadata":{}},{"cell_type":"code","source":"import os\ntopic = 1\ntopic_name = f'Tópico#{topic}'\nos.makedirs(f'{images_path}/topic_{topic}', exist_ok=True)\n# topic_path_img = f'{images_path}/topic_0/probabilidad.png'\ntopic_path_img = f'{images_path}/topic_{topic}/mapa_de_color.png'\n\nwords = [\n    'historia', 'universidad', 'habana', 'medicina', 'cubana', 'cuba', 'cubanos', 'doctor', 'bloqueo', 'unidos', 'tropical', 'academia',\n    'dorta', 'contreras', 'angiostrongylus', 'cantonensis', 'siglo', 'xix', 'carlos', 'instituto', 'universidad', 'hospital'\n]\n\nword_index = [get_word_index(word) for word in words]       \nget_mapa_color(words, word_index, topic_name, topic_path_img)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T00:59:22.161209Z","iopub.execute_input":"2025-02-10T00:59:22.161535Z","iopub.status.idle":"2025-02-10T00:59:23.386727Z","shell.execute_reply.started":"2025-02-10T00:59:22.161505Z","shell.execute_reply":"2025-02-10T00:59:23.385965Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Topic 3","metadata":{}},{"cell_type":"code","source":"import os\ntopic = 3\ntopic_name = f'Tópico#{topic}'\nos.makedirs(f'{images_path}/topic_{topic}', exist_ok=True)\n# topic_path_img = f'{images_path}/topic_0/probabilidad.png'\ntopic_path_img = f'{images_path}/topic_{topic}/mapa_de_color.png'\n\nwords = [\n    'contenidos', 'habilidades', 'estudiante', 'plan', 'preguntas', 'carrera', 'instrumento', 'voz', 'lengua', 'sonidos', 'fuerza', 'english', \n    'sugerencias', 'clases', 'palabras', 'puntos', 'instrumento', 'ejercicio', 'preguntas', 'profesores', 'encuesta', 'cada', 'etapa', \n    'pruebas', 'entrenamiento', 'dificultad', 'recomendaciones', 'vacuna', 'vacunas', 'paso', 'producto','estrategia', 'etapa',\n    'asignatura', 'basadas', 'examen'\n]\n\nget_mapa_color(words, word_index, topic_name, topic_path_img)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T00:59:41.922218Z","iopub.execute_input":"2025-02-10T00:59:41.922507Z","iopub.status.idle":"2025-02-10T00:59:43.897415Z","shell.execute_reply.started":"2025-02-10T00:59:41.922483Z","shell.execute_reply":"2025-02-10T00:59:43.896468Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\ntopic = 7\ntopic_name = f'Tópico#{topic}'\nos.makedirs(f'{images_path}/topic_{topic}', exist_ok=True)\n# topic_path_img = f'{images_path}/topic_0/probabilidad.png'\ntopic_path_img = f'{images_path}/topic_{topic}/mapa_de_color.png'\n\nwords = [\n    'sida', 'vih', 'sexual', 'familiar', 'familia', 'vida', 'padres', 'mujeres', 'ancianos', 'envejecimiento', 'suicidio', 'relaciones', 'adolescentes',\n    'personas', 'sexual', 'consumo', 'mental', 'estigma', 'conductas', 'cuidadores', 'trastorno', 'bipolar', 'intento', 'alcohol', 'demencia', 'estilos',\n     'conducta', 'adultos'\n]\n\nget_mapa_color(words, word_index, topic_name, topic_path_img)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T01:01:24.701864Z","iopub.execute_input":"2025-02-10T01:01:24.702228Z","iopub.status.idle":"2025-02-10T01:01:26.268153Z","shell.execute_reply.started":"2025-02-10T01:01:24.702198Z","shell.execute_reply":"2025-02-10T01:01:26.267172Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\ntopic = 8\ntopic_name = f'Tópico#{topic}'\nos.makedirs(f'{images_path}/topic_{topic}', exist_ok=True)\n# topic_path_img = f'{images_path}/topic_0/probabilidad.png'\ntopic_path_img = f'{images_path}/topic_{topic}/mapa_de_color.png'\n\nwords = [ 'vigilancia', 'datos', 'casos', 'provincia', 'centros', 'fallecidos', 'red', 'disponible', 'muestras', 'fuente', 'intoxicaciones', 'ocurrencia',\n         'consultas', 'agudos', 'fuente', 'alarma', 'dengue', 'lambayeque', 'pandemia', 'resistencia', 'impacto',\n'cubanas', 'covid', 'competitividad', 'gobiernos', 'coronavirus', 'mortalidad', 'cov', 'sars', 'modelos', 'internet', 'dosis'\n]\n\nget_mapa_color(words, word_index, topic_name, topic_path_img)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T01:01:45.718669Z","iopub.execute_input":"2025-02-10T01:01:45.718983Z","iopub.status.idle":"2025-02-10T01:01:47.411936Z","shell.execute_reply.started":"2025-02-10T01:01:45.718958Z","shell.execute_reply":"2025-02-10T01:01:47.411047Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\ntopic = 9\ntopic_name = f'Tópico#{topic}'\nos.makedirs(f'{images_path}/topic_{topic}', exist_ok=True)\n# topic_path_img = f'{images_path}/topic_0/probabilidad.png'\ntopic_path_img = f'{images_path}/topic_{topic}/mapa_de_color.png'\n\nwords = [ 'hallazgos', 'lesiones', 'complicaciones', 'frecuentes', 'imagen', 'abdominal', 'fiebre', 'caso',  'quistes', 'intestinal', 'biopsia', 'frecuentes',\n         'carcinoma', 'von']\n\nget_mapa_color(words, word_index, topic_name, topic_path_img)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T01:02:07.408672Z","iopub.execute_input":"2025-02-10T01:02:07.408984Z","iopub.status.idle":"2025-02-10T01:02:08.487013Z","shell.execute_reply.started":"2025-02-10T01:02:07.408959Z","shell.execute_reply":"2025-02-10T01:02:08.486078Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\ntopic = 10\ntopic_name = f'Tópico#{topic}'\nos.makedirs(f'{images_path}/topic_{topic}', exist_ok=True)\n# topic_path_img = f'{images_path}/topic_0/probabilidad.png'\ntopic_path_img = f'{images_path}/topic_{topic}/mapa_de_color.png'\n\nwords = [\n    'pylori', 'seguimiento', 'helicobacter', 'reportado', 'temporal',\n'linfoma', 'manifestaciones', 'varicela', 'zoster', 'serial',\n'gigantes', 'fetal', 'nervio', 'mano', 'ojo', 'síndrome', 'visual', 'seco', \n    'johnson', 'mediano', 'superficie', 'seguimiento', 'cuadro', \n    'aparece', 'entidad', 'consulta'\n]\n\nget_mapa_color(words, word_index, topic_name, topic_path_img)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T01:02:51.406659Z","iopub.execute_input":"2025-02-10T01:02:51.406999Z","iopub.status.idle":"2025-02-10T01:02:52.813254Z","shell.execute_reply.started":"2025-02-10T01:02:51.406971Z","shell.execute_reply":"2025-02-10T01:02:52.812425Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!zip -r /kaggle/working/images.zip /kaggle/working/images","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T01:03:55.157260Z","iopub.execute_input":"2025-02-10T01:03:55.157557Z","iopub.status.idle":"2025-02-10T01:03:55.343708Z","shell.execute_reply.started":"2025-02-10T01:03:55.157532Z","shell.execute_reply":"2025-02-10T01:03:55.342904Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Defensa","metadata":{}},{"cell_type":"markdown","source":"## Modificacion: Número de tópicos = 14","metadata":{}},{"cell_type":"code","source":"defensa_path = './defensa'\nos.makedirs(defensa_path, exist_ok=True)\n\ndef save_result_defensa(top_words, trainer, config, metrics_json, path):\n    global samples \n    os.makedirs(path, exist_ok=True)\n\n    try:\n        save_top_words_txt(top_words, path)\n        save_json(config, os.path.join(path, 'hyperparameters.json'))\n        save_json(metrics_json, os.path.join(path, 'metrics_json.json'))\n        save_json({\"config\": config, \"metrics\": metrics_json}, os.path.join(path, 'metrics_config.json'))\n        #save_joblib(trainer, os.path.join(path, 'trainer.joblib'))\n        save_joblib(top_words, os.path.join(path, 'top_words.joblib'))\n    except Exception as e:\n        traceback.print_exc()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:15:59.853412Z","iopub.execute_input":"2025-02-22T17:15:59.853712Z","iopub.status.idle":"2025-02-22T17:15:59.859213Z","shell.execute_reply.started":"2025-02-22T17:15:59.853691Z","shell.execute_reply":"2025-02-22T17:15:59.858210Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"        config = {\"model\": {\"num_topics\": 14, \"en1_units\": 50, \"dropout\": 0.1, \"beta_temp\": 1.5, \"temperature\": 0.1, \"weight_neg\": 5000000.0, \"weight_pos\": 100.0, \"weight_UWE\": 10000.0, \"neg_topk\": 20}, \"training\": {\"learning_rate\": 0.001, \"batch_size\": 500, \"num_epoch\": 800}}\n\n        model = topmost.CFDTM(\n        vocab_size=dataset.vocab_size,\n        train_time_wordfreq=dataset.train_time_wordfreq,\n        num_times=dataset.num_times,\n        pretrained_WE=dataset.pretrained_WE,\n        num_topics=config[\"model\"][\"num_topics\"],\n        en_units=config[\"model\"][\"en1_units\"],\n        temperature=config[\"model\"][\"temperature\"],\n        beta_temp=config[\"model\"][\"beta_temp\"],\n        weight_neg=config[\"model\"][\"weight_neg\"],\n        weight_pos=config[\"model\"][\"weight_pos\"],\n        weight_UWE=config[\"model\"][\"weight_UWE\"],\n        neg_topk=config[\"model\"][\"neg_topk\"],\n        dropout=config[\"model\"][\"dropout\"],\n        embed_size=300\n        )\n  \n        model = model.to(device)  \n        trainer = topmost.DynamicTrainer(model, dataset, batch_size=config[\"training\"][\"batch_size\"], learning_rate=config[\"training\"][\"learning_rate\"], epochs=config[\"training\"][\"num_epoch\"])\n        top_words, train_theta = trainer.train()\n\n        metrics_json, dynamic_TC, dynamic_TD, clustering, classification = eval(trainer, top_words)\n        save_result_defensa(top_words, trainer, config, metrics_json, os.path.join(defensa_path, 'num_topics'))\n\n        beta = model.get_beta()\n        save_joblib(beta, os.path.join(defensa_path, 'num_topics', 'beta.joblib'))\n        save_joblib(train_theta, os.path.join(defensa_path, 'num_topics', 'train_theta.joblib'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Modificacion: Clasificacion","metadata":{}},{"cell_type":"code","source":"        os.makedirs(os.path.join(defensa_path, 'metrics', 'model'), exist_ok=True)\n\n        config = {\"model\": {\"num_topics\": 20, \"en1_units\": 50, \"dropout\": 0.1, \"beta_temp\": 1.5, \"temperature\": 0.1, \"weight_neg\": 5000000.0, \"weight_pos\": 100.0, \"weight_UWE\": 10000.0, \"neg_topk\": 20}, \"training\": {\"learning_rate\": 0.001, \"batch_size\": 500, \"num_epoch\": 800}}\n\n        model = topmost.CFDTM(\n        vocab_size=dataset.vocab_size,\n        train_time_wordfreq=dataset.train_time_wordfreq,\n        num_times=dataset.num_times,\n        pretrained_WE=dataset.pretrained_WE,\n        num_topics=config[\"model\"][\"num_topics\"],\n        en_units=config[\"model\"][\"en1_units\"],\n        temperature=config[\"model\"][\"temperature\"],\n        beta_temp=config[\"model\"][\"beta_temp\"],\n        weight_neg=config[\"model\"][\"weight_neg\"],\n        weight_pos=config[\"model\"][\"weight_pos\"],\n        weight_UWE=config[\"model\"][\"weight_UWE\"],\n        neg_topk=config[\"model\"][\"neg_topk\"],\n        dropout=config[\"model\"][\"dropout\"],\n        embed_size=300\n        )\n\n        model = model.to(device)  \n        trainer = topmost.DynamicTrainer(model, dataset, batch_size=config[\"training\"][\"batch_size\"], learning_rate=config[\"training\"][\"learning_rate\"], epochs=config[\"training\"][\"num_epoch\"])\n        top_words, train_theta = trainer.train()\n\n        metrics_json, _, _ = eval_clustering_cls(trainer, top_words)\n        save_result_defensa(top_words, trainer, config, metrics_json, os.path.join(defensa_path, 'metrics', 'model'))\n\n        beta = model.get_beta()\n        save_joblib(beta, os.path.join(defensa_path, 'metrics', 'model', 'beta.joblib'))\n        save_joblib(train_theta, os.path.join(defensa_path, 'metrics', 'model', 'train_theta.joblib'))\n        save_joblib(model, os.path.join(defensa_path, 'metrics', 'model', 'model.joblib'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:27:57.138877Z","iopub.execute_input":"2025-02-22T17:27:57.139180Z","iopub.status.idle":"2025-02-22T17:39:28.622170Z","shell.execute_reply.started":"2025-02-22T17:27:57.139153Z","shell.execute_reply":"2025-02-22T17:39:28.621070Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 800/800 [10:37<00:00,  1.25it/s]\n22it [00:51,  2.33s/it]\n","output_type":"stream"},{"name":"stdout","text":"dynamic TC list: [0.5677019265741741, 0.5473264402428053, 0.4923456246749159, 0.5432723375767776, 0.5042466019057775, 0.5522335065730417, 0.46608371362633494, 0.4993536214825299, 0.5213787349096782, 0.5174301246351893, 0.484013886743911, 0.5166642946714922, 0.5122213067585798, 0.45103387386478866, 0.4735774175769333, 0.4924615524516569, 0.49274238274259, 0.506652567639084, 0.5366530483354509, 0.4846558897407993, 0.49443885537141186, 0.586195160347525]\ndynamic_TC:  0.5110310394747931\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 22/22 [00:00<00:00, 74.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"dynamic_TD:  0.9163636363636364\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"def eval_clustering_cls(trainer, top_words):\n    # get theta (doc-topic distributions)\n    train_theta, test_theta = trainer.export_theta()\n\n    train_times = dataset.train_times.cpu().numpy()\n    # compute topic coherence\n    dynamic_TC = eva.dynamic_coherence(dataset.train_texts, train_times, dataset.vocab, top_words, verbose=True)\n    print(\"dynamic_TC: \", dynamic_TC)\n\n    # compute topic diversity\n    dynamic_TD = eva.dynamic_diversity(top_words, dataset.train_bow.cpu().numpy(), train_times, dataset.vocab, verbose=False)\n    print(\"dynamic_TD: \", dynamic_TD)\n    \n    json = {\n        \"dynamic_TC\": dynamic_TC,\n        \"dynamic_TD\": dynamic_TD,\n    }\n    \n    save_json(json,  os.path.join(defensa_path, 'metrics', 'tc_td.joblib'))\n    return json, dynamic_TC, dynamic_TD\n\neval_clustering_cls(trainer, top_words)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:26:59.411431Z","iopub.execute_input":"2025-02-22T17:26:59.411752Z","iopub.status.idle":"2025-02-22T17:27:47.332147Z","shell.execute_reply.started":"2025-02-22T17:26:59.411728Z","shell.execute_reply":"2025-02-22T17:27:47.330973Z"}},"outputs":[{"name":"stderr","text":"0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/gensim/topic_coherence/direct_confirmation_measure.py:204: RuntimeWarning: divide by zero encountered in scalar divide\n  m_lr_i = np.log(numerator / denominator)\n/usr/local/lib/python3.10/dist-packages/gensim/topic_coherence/indirect_confirmation_measure.py:323: RuntimeWarning: invalid value encountered in scalar divide\n  return cv1.T.dot(cv2)[0, 0] / (_magnitude(cv1) * _magnitude(cv2))\n22it [00:47,  2.16s/it]\n","output_type":"stream"},{"name":"stdout","text":"dynamic TC list: [0.5474639207609946, 0.5485055440911806, 0.538093315991761, 0.5595035827013972, 0.5571586879373494, 0.5710942423312598, 0.49727653490284063, 0.5057157578628461, 0.5364983797496669, 0.5380682684098397, 0.5307859345809531, 0.5361257264203786, 0.5426859438886168, 0.5097462204554137, 0.5385772852900975, 0.49183257804142605, 0.5622213206511859, 0.5586238061437698, 0.5825828057721377, 0.5403927587880044, 0.5232952103670785, 0.5312220862599667]\ndynamic_TC:  0.5385213596090075\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 22/22 [00:00<00:00, 64.48it/s]","output_type":"stream"},{"name":"stdout","text":"dynamic_TD:  0.8746969696969699\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"({'dynamic_TC': 0.5385213596090075, 'dynamic_TD': 0.8746969696969699},\n 0.5385213596090075,\n 0.8746969696969699)"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import accuracy_score, classification_report, f1_score\n\ndef train_and_evaluate(X_train, X_test, y_train, y_test, model, params):\n    scaler = StandardScaler()\n    X_train = scaler.fit_transform(X_train) \n    X_test = scaler.transform(X_test)\n    \n    # for name, (model, params) in models.items():\n    if params:  # Naive Bayes no requiere hiperparámetros\n        grid_search = GridSearchCV(model, params, scoring='accuracy', cv=5)\n        grid_search.fit(X_train, y_train)\n        best_estimator = grid_search.best_estimator_\n    else:\n        model.fit(X_train, y_train)\n        best_estimator = model\n        \n    y_pred = best_estimator.predict(X_test)\n    acc = accuracy_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred, average='weighted')\n\n    print(f\"Params: {grid_search.best_params_}\")\n    print(f\"Accuracy: {acc:.4f}\")\n    print(f\"F1 Score: {f1:.4f}\")\n    print(\"Reporte de clasificación:\")\n    print(classification_report(y_test, y_pred))\n        \n    return {\n        \"params\": grid_search.best_params_,\n        \"metrics\": {\n            \"acc\": acc,\n            \"macro-f1\": f1},\n        \"classification_report\": classification_report(y_test, y_pred)\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:12:41.614769Z","iopub.execute_input":"2025-02-22T17:12:41.615111Z","iopub.status.idle":"2025-02-22T17:12:42.041876Z","shell.execute_reply.started":"2025-02-22T17:12:41.615078Z","shell.execute_reply":"2025-02-22T17:12:42.041225Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\n\ndef eval_cls(X_train, X_test, y_train, y_test):\n    n_train, n_features = X_train.shape\n    \n    rf_params = {\"n_estimators\": [n_train // 10, n_train // 5, n_train // 2]}\n    rf = train_and_evaluate(X_train, X_test, y_train, y_test, RandomForestClassifier(), rf_params)\n    print(\"Random Forest: \", rf)\n    \n    knn_params = {\"n_neighbors\": [int(np.sqrt(n_train)) // 2, int(np.sqrt(n_train)), int(np.sqrt(n_train)) * 2]}\n    knn = train_and_evaluate(X_train, X_test, y_train, y_test, KNeighborsClassifier(), knn_params)\n    print(\"KNN: \", knn)\n\n    svm_params = {\"kernel\": ['linear', 'rbf']} #, \"C\": [0.1, 1, n_features]\n    svm = train_and_evaluate(X_train, X_test, y_train, y_test, SVC(), svm_params)\n    print(\"SVM: \", svm)\n    \n    return {\n        \"rf\": rf,\n        \"knn\": knn,\n        \"svm\": svm\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:12:46.928961Z","iopub.execute_input":"2025-02-22T17:12:46.929297Z","iopub.status.idle":"2025-02-22T17:12:47.062121Z","shell.execute_reply.started":"2025-02-22T17:12:46.929247Z","shell.execute_reply":"2025-02-22T17:12:47.061481Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"train_theta, test_theta = trainer.export_theta()\ntrain_times = dataset.train_times.cpu().numpy()\n\nclassification = eval_cls(train_theta, test_theta, dataset.train_labels, dataset.test_labels)\nsave_json(classification, os.path.join(defensa_path, 'metrics', 'classification.json'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T15:03:16.053928Z","iopub.execute_input":"2025-02-22T15:03:16.054227Z","iopub.status.idle":"2025-02-22T15:03:39.816315Z","shell.execute_reply.started":"2025-02-22T15:03:16.054205Z","shell.execute_reply":"2025-02-22T15:03:39.815550Z"}},"outputs":[{"name":"stdout","text":"Params: {'n_estimators': 241}\nAccuracy: 0.4726\nF1 Score: 0.4288\nReporte de clasificación:\n              precision    recall  f1-score   support\n\n           0       1.00      0.04      0.08        23\n           1       1.00      0.13      0.23        39\n           2       0.43      0.87      0.58       145\n           3       0.58      0.67      0.62        64\n           4       0.49      0.34      0.40        56\n           5       0.56      0.12      0.19        43\n           6       0.67      0.21      0.32        38\n           7       1.00      0.09      0.17        22\n           8       0.53      0.45      0.48        65\n           9       1.00      0.14      0.25         7\n          10       0.37      0.52      0.43       106\n          11       0.00      0.00      0.00         9\n          12       1.00      0.14      0.25         7\n          13       0.84      0.47      0.60        34\n\n    accuracy                           0.47       658\n   macro avg       0.68      0.30      0.33       658\nweighted avg       0.57      0.47      0.43       658\n\nRandom Forest:  {'params': {'n_estimators': 241}, 'metrics': {'acc': 0.4726443768996961, 'macro-f1': 0.4287633730128114}, 'classification_report': '              precision    recall  f1-score   support\\n\\n           0       1.00      0.04      0.08        23\\n           1       1.00      0.13      0.23        39\\n           2       0.43      0.87      0.58       145\\n           3       0.58      0.67      0.62        64\\n           4       0.49      0.34      0.40        56\\n           5       0.56      0.12      0.19        43\\n           6       0.67      0.21      0.32        38\\n           7       1.00      0.09      0.17        22\\n           8       0.53      0.45      0.48        65\\n           9       1.00      0.14      0.25         7\\n          10       0.37      0.52      0.43       106\\n          11       0.00      0.00      0.00         9\\n          12       1.00      0.14      0.25         7\\n          13       0.84      0.47      0.60        34\\n\\n    accuracy                           0.47       658\\n   macro avg       0.68      0.30      0.33       658\\nweighted avg       0.57      0.47      0.43       658\\n'}\nParams: {'n_neighbors': 34}\nAccuracy: 0.4088\nF1 Score: 0.3520\nReporte de clasificación:\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00        23\n           1       1.00      0.10      0.19        39\n           2       0.37      0.86      0.52       145\n           3       0.62      0.59      0.61        64\n           4       0.38      0.14      0.21        56\n           5       0.00      0.00      0.00        43\n           6       0.52      0.37      0.43        38\n           7       0.00      0.00      0.00        22\n           8       0.49      0.35      0.41        65\n           9       0.00      0.00      0.00         7\n          10       0.28      0.36      0.31       106\n          11       0.00      0.00      0.00         9\n          12       0.00      0.00      0.00         7\n          13       0.79      0.56      0.66        34\n\n    accuracy                           0.41       658\n   macro avg       0.32      0.24      0.24       658\nweighted avg       0.40      0.41      0.35       658\n\nKNN:  {'params': {'n_neighbors': 34}, 'metrics': {'acc': 0.4088145896656535, 'macro-f1': 0.3520401581724803}, 'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.00      0.00      0.00        23\\n           1       1.00      0.10      0.19        39\\n           2       0.37      0.86      0.52       145\\n           3       0.62      0.59      0.61        64\\n           4       0.38      0.14      0.21        56\\n           5       0.00      0.00      0.00        43\\n           6       0.52      0.37      0.43        38\\n           7       0.00      0.00      0.00        22\\n           8       0.49      0.35      0.41        65\\n           9       0.00      0.00      0.00         7\\n          10       0.28      0.36      0.31       106\\n          11       0.00      0.00      0.00         9\\n          12       0.00      0.00      0.00         7\\n          13       0.79      0.56      0.66        34\\n\\n    accuracy                           0.41       658\\n   macro avg       0.32      0.24      0.24       658\\nweighted avg       0.40      0.41      0.35       658\\n'}\nParams: {'kernel': 'rbf'}\nAccuracy: 0.4210\nF1 Score: 0.3649\nReporte de clasificación:\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00        23\n           1       0.60      0.15      0.24        39\n           2       0.42      0.86      0.56       145\n           3       0.59      0.61      0.60        64\n           4       0.33      0.09      0.14        56\n           5       0.50      0.05      0.09        43\n           6       0.42      0.45      0.44        38\n           7       0.00      0.00      0.00        22\n           8       0.51      0.31      0.38        65\n           9       0.00      0.00      0.00         7\n          10       0.28      0.42      0.34       106\n          11       0.00      0.00      0.00         9\n          12       0.00      0.00      0.00         7\n          13       0.79      0.56      0.66        34\n\n    accuracy                           0.42       658\n   macro avg       0.32      0.25      0.25       658\nweighted avg       0.41      0.42      0.36       658\n\nSVM:  {'params': {'kernel': 'rbf'}, 'metrics': {'acc': 0.4209726443768997, 'macro-f1': 0.3649068590832392}, 'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.00      0.00      0.00        23\\n           1       0.60      0.15      0.24        39\\n           2       0.42      0.86      0.56       145\\n           3       0.59      0.61      0.60        64\\n           4       0.33      0.09      0.14        56\\n           5       0.50      0.05      0.09        43\\n           6       0.42      0.45      0.44        38\\n           7       0.00      0.00      0.00        22\\n           8       0.51      0.31      0.38        65\\n           9       0.00      0.00      0.00         7\\n          10       0.28      0.42      0.34       106\\n          11       0.00      0.00      0.00         9\\n          12       0.00      0.00      0.00         7\\n          13       0.79      0.56      0.66        34\\n\\n    accuracy                           0.42       658\\n   macro avg       0.32      0.25      0.25       658\\nweighted avg       0.41      0.42      0.36       658\\n'}\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## Clustering","metadata":{}},{"cell_type":"code","source":"from scipy.stats import mode\ndef purity_score(y_true, y_pred):\n    labels = np.unique(y_pred)\n    majority_sum = 0\n    for label in labels:\n        mask = y_pred == label\n        majority_class = mode(y_true[mask])[0][0]\n        majority_sum += np.sum(y_true[mask] == majority_class)\n    return majority_sum / len(y_true)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:40:05.089663Z","iopub.execute_input":"2025-02-22T17:40:05.089991Z","iopub.status.idle":"2025-02-22T17:40:05.095585Z","shell.execute_reply.started":"2025-02-22T17:40:05.089965Z","shell.execute_reply":"2025-02-22T17:40:05.094529Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"from sklearn import metrics\nimport numpy as np\n\ndef purity_score(y_true, y_pred):\n    # compute contingency matrix (also called confusion matrix)\n    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:40:09.055411Z","iopub.execute_input":"2025-02-22T17:40:09.055730Z","iopub.status.idle":"2025-02-22T17:40:09.060791Z","shell.execute_reply.started":"2025-02-22T17:40:09.055701Z","shell.execute_reply":"2025-02-22T17:40:09.059964Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"from sklearn.model_selection import ParameterGrid\nfrom sklearn.metrics import normalized_mutual_info_score\nfrom tqdm import tqdm\n\ndef best_config(X_test, y_test, model, model_name, params):\n    best_local_model = None\n    best_local_score = -1\n    best_local_nmi = -1\n    best_local_purity = -1\n    best_local_params = None\n        \n    for param_set in tqdm(ParameterGrid(params), desc=model_name):\n        model.set_params(**param_set)\n        labels = model.fit_predict(X_test)\n        if len(set(labels)) > 1:  # Evitar errores con un solo cluster\n            purity = purity_score(y_test, labels)\n            nmi = normalized_mutual_info_score(y_test, labels)\n            score = (purity + nmi) / 2  # Promedio de ambas métricas\n                \n            if score > best_local_score:\n                best_local_score = score\n                best_local_model = model\n                best_local_params = param_set\n                best_local_nmi = nmi\n                best_local_purity = purity\n\n    print(f\"Params: {best_local_params}\")\n    print(f\"Purity: {purity:.4f}\")\n    print(f\"NMI: {nmi:.4f}\")\n    \n    return {\n        \"params\": best_local_params,\n        \"metrics\": {\n            \"purity\": purity,\n            \"nmi\": nmi},\n        # \"classification_report\": classification_report(y_test, y_pred)\n        }\n\ndef clustermax_probability(theta, labels):\n    preds = np.argmax(theta, axis=1)\n    purity = purity_score(labels, preds)\n    nmi = normalized_mutual_info_score(labels, preds)\n    \n    print(\"Max Probability\")\n    print(f\"Purity: {purity:.4f}\")\n    print(f\"NMI: {nmi:.4f}\")\n    \n    return {\n        \"purity\": purity,\n        \"nmi\": nmi\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:41:35.172252Z","iopub.execute_input":"2025-02-22T17:41:35.172605Z","iopub.status.idle":"2025-02-22T17:41:35.179967Z","shell.execute_reply.started":"2025-02-22T17:41:35.172578Z","shell.execute_reply":"2025-02-22T17:41:35.179061Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\nimport numpy as np\n\ndef eval_clustering(test_theta, test_labels):\n    kmeans_params = {\"n_clusters\": [5, 10, 14, 20], \"init\": ['k-means++', 'random'], \"max_iter\": [300, 500]}\n    kmeans = best_config(test_theta, test_labels, KMeans(), 'K-Means', kmeans_params)\n\n    \n    dbscan_params = {\"eps\": [0.1, 0.2, 0.5], \"min_samples\": [3, 5, 10], \"metric\": ['euclidean', 'cosine']}\n    dbscan = best_config(test_theta, test_labels, DBSCAN(), 'DBSCAN', dbscan_params)\n\n    hierarchical_params = {\"n_clusters\": [5, 10, 14, 20], \"affinity\": ['euclidean', 'cosine'], \"linkage\": ['complete', 'average']}\n    hierarchical = best_config(test_theta, test_labels, AgglomerativeClustering(), 'Agglomerative Clustering', hierarchical_params)\n\n    max_probability = clustermax_probability(test_theta, test_labels)\n\n    return {\n        \"kmeans\": kmeans,\n        \"dbscan\": dbscan,\n        \"hierarchical\": hierarchical,\n        \"max_probability\": max_probability\n    }\n\ntrain_theta, test_theta = trainer.export_theta()\ntrain_times = dataset.train_times.cpu().numpy()\nclustering = eval_clustering(test_theta, dataset.test_labels)\nsave_json(clustering, os.path.join(defensa_path, 'metrics', 'clustering.json'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:41:39.510935Z","iopub.execute_input":"2025-02-22T17:41:39.511226Z","iopub.status.idle":"2025-02-22T17:41:40.559396Z","shell.execute_reply.started":"2025-02-22T17:41:39.511203Z","shell.execute_reply":"2025-02-22T17:41:40.558388Z"}},"outputs":[{"name":"stderr","text":"K-Means: 100%|██████████| 16/16 [00:00<00:00, 22.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Params: {'init': 'k-means++', 'max_iter': 300, 'n_clusters': 20}\nPurity: 0.4210\nNMI: 0.2979\n","output_type":"stream"},{"name":"stderr","text":"DBSCAN: 100%|██████████| 18/18 [00:00<00:00, 130.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Params: {'eps': 0.1, 'metric': 'euclidean', 'min_samples': 3}\nPurity: 0.2219\nNMI: 0.0030\n","output_type":"stream"},{"name":"stderr","text":"Agglomerative Clustering: 100%|██████████| 16/16 [00:00<00:00, 91.39it/s]","output_type":"stream"},{"name":"stdout","text":"Params: {'affinity': 'cosine', 'linkage': 'average', 'n_clusters': 20}\nPurity: 0.4149\nNMI: 0.2992\nMax Probability\nPurity: 0.4164\nNMI: 0.2973\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"print('hello')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T20:27:03.058489Z","iopub.execute_input":"2025-02-23T20:27:03.059718Z","iopub.status.idle":"2025-02-23T20:27:03.065085Z","shell.execute_reply.started":"2025-02-23T20:27:03.059613Z","shell.execute_reply":"2025-02-23T20:27:03.064142Z"}},"outputs":[{"name":"stdout","text":"hello\n","output_type":"stream"}],"execution_count":1}]}