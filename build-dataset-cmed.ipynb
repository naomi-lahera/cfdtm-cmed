{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10462241,"sourceType":"datasetVersion","datasetId":6460784}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install topmost","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T00:27:11.583737Z","iopub.execute_input":"2025-02-19T00:27:11.584052Z","iopub.status.idle":"2025-02-19T00:27:26.032826Z","shell.execute_reply.started":"2025-02-19T00:27:11.584021Z","shell.execute_reply":"2025-02-19T00:27:26.031949Z"}},"outputs":[{"name":"stdout","text":"Collecting topmost\n  Downloading topmost-1.0.1-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: numpy<1.27.0 in /usr/local/lib/python3.10/dist-packages (from topmost) (1.26.4)\nCollecting scipy<=1.10.1 (from topmost)\n  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting sentence-transformers<3.0.0,>=2.6.0 (from topmost)\n  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: torchvision>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from topmost) (0.19.1+cu121)\nRequirement already satisfied: gensim>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from topmost) (4.3.3)\nRequirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from topmost) (1.2.2)\nRequirement already satisfied: tqdm>=4.66.0 in /usr/local/lib/python3.10/dist-packages (from topmost) (4.66.5)\nCollecting fastopic>=1.0.0 (from topmost)\n  Downloading fastopic-1.0.0-py3-none-any.whl.metadata (11 kB)\nCollecting bertopic>=0.15.0 (from topmost)\n  Downloading bertopic-0.16.4-py3-none-any.whl.metadata (23 kB)\nCollecting hdbscan>=0.8.29 (from bertopic>=0.15.0->topmost)\n  Downloading hdbscan-0.8.40-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\nRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from bertopic>=0.15.0->topmost) (2.1.4)\nRequirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from bertopic>=0.15.0->topmost) (5.24.1)\nCollecting umap-learn>=0.5.0 (from bertopic>=0.15.0->topmost)\n  Downloading umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim>=4.2.0->topmost) (7.0.4)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->topmost) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->topmost) (3.5.0)\nRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.6.0->topmost) (4.44.2)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.6.0->topmost) (2.4.1+cu121)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.6.0->topmost) (0.24.7)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.6.0->topmost) (10.4.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (2.32.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic>=0.15.0->topmost) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic>=0.15.0->topmost) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic>=0.15.0->topmost) (2024.1)\nRequirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic>=0.15.0->topmost) (9.0.0)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim>=4.2.0->topmost) (1.16.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (2024.9.11)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (0.19.1)\nRequirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.0->bertopic>=0.15.0->topmost) (0.60.0)\nCollecting pynndescent>=0.5 (from umap-learn>=0.5.0->bertopic>=0.15.0->topmost)\n  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic>=0.15.0->topmost) (0.43.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic>=0.15.0->topmost) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.6.0->topmost) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.0->topmost) (1.3.0)\nDownloading topmost-1.0.1-py3-none-any.whl (93 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m93.6/93.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bertopic-0.16.4-py3-none-any.whl (143 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m143.7/143.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastopic-1.0.0-py3-none-any.whl (89 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m89.6/89.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading hdbscan-0.8.40-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading umap_learn-0.5.7-py3-none-any.whl (88 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: scipy, pynndescent, hdbscan, umap-learn, sentence-transformers, bertopic, fastopic, topmost\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.13.1\n    Uninstalling scipy-1.13.1:\n      Successfully uninstalled scipy-1.13.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkaggle-environments 1.16.10 requires scipy>=1.11.2, but you have scipy 1.10.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bertopic-0.16.4 fastopic-1.0.0 hdbscan-0.8.40 pynndescent-0.5.13 scipy-1.10.1 sentence-transformers-2.7.0 topmost-1.0.1 umap-learn-0.5.7\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nfrom tqdm import tqdm\nimport scipy.sparse\nfrom topmost.preprocessing import Preprocessing\nimport topmost.preprocessing.preprocessing as prepro\nimport importlib\nfrom topmost.utils.logger import Logger\nimport fasttext\nimport fasttext.util\nimport nltk\nfrom nltk.corpus import stopwords","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T00:32:48.088559Z","iopub.execute_input":"2025-02-19T00:32:48.088940Z","iopub.status.idle":"2025-02-19T00:33:40.249989Z","shell.execute_reply.started":"2025-02-19T00:32:48.088910Z","shell.execute_reply":"2025-02-19T00:33:40.248970Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## FastText","metadata":{}},{"cell_type":"code","source":"logger = Logger(\"WARNING\")\nlogger = Logger(\"DEBUG\")\nnltk.download('stopwords')\nstopwords_es = set(stopwords.words('spanish'))\nfasttext.util.download_model('es', if_exists='ignore')  # Espa√±ol\n\n# print(stopwords_es)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T08:46:25.880711Z","iopub.execute_input":"2025-01-12T08:46:25.881418Z","iopub.status.idle":"2025-01-12T08:46:25.986928Z","shell.execute_reply.started":"2025-01-12T08:46:25.881392Z","shell.execute_reply":"2025-01-12T08:46:25.986194Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'cc.es.300.bin'"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"def make_word_embeddings_es(vocab):\n    # Cargar el modelo binario preentrenado\n    fasttext_model = fasttext.load_model(\"cc.es.300.bin\")\n\n    # glove_vectors = gensim.downloader.load('glove-wiki-gigaword-200')\n    word_embeddings = np.zeros((len(vocab), fasttext_model.get_dimension()))\n\n    num_found = 0\n\n    for i, word in enumerate(tqdm(vocab, desc=\"loading SPANISH üçÄ word embeddings\")):\n        word_embeddings[i] = fasttext_model.get_word_vector(word)\n        num_found += 1\n\n    logger.info(f'number of found embeddings: {num_found}/{len(vocab)}')\n\n    return scipy.sparse.csr_matrix(word_embeddings)\n\nprepro.make_word_embeddings = make_word_embeddings_es","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T08:46:25.988057Z","iopub.execute_input":"2025-01-12T08:46:25.988358Z","iopub.status.idle":"2025-01-12T08:46:25.993573Z","shell.execute_reply.started":"2025-01-12T08:46:25.988326Z","shell.execute_reply":"2025-01-12T08:46:25.992667Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## GloVe","metadata":{}},{"cell_type":"code","source":"!mkdir -p /kaggle/working/modelos/gloVe  # Crea la carpeta si no existe","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Modelo binario\n!wget -c \"http://dcc.uchile.cl/~jperez/word-embeddings/glove-sbwc.i25.bin\" -P /kaggle/working/modelos/gloVe","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Modelo KeyVectprs\n!wget -c \"http://dcc.uchile.cl/~jperez/word-embeddings/glove-sbwc.i25.bin\" -P !mkdir -p /kaggle/working/modelos/gloVe","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T18:27:57.816207Z","iopub.execute_input":"2025-02-20T18:27:57.816616Z","iopub.status.idle":"2025-02-20T18:27:59.072561Z","shell.execute_reply.started":"2025-02-20T18:27:57.816583Z","shell.execute_reply":"2025-02-20T18:27:59.071379Z"}},"outputs":[{"name":"stdout","text":"URL transformed to HTTPS due to an HSTS policy\n--2025-02-20 18:27:57--  https://dcc.uchile.cl/~jperez/word-embeddings/glove-sbwc.i25.bin\nResolving dcc.uchile.cl (dcc.uchile.cl)... 192.80.24.11\nConnecting to dcc.uchile.cl (dcc.uchile.cl)|192.80.24.11|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://users.dcc.uchile.cl/~jperez/word-embeddings/glove-sbwc.i25.bin [following]\n--2025-02-20 18:27:58--  https://users.dcc.uchile.cl/~jperez/word-embeddings/glove-sbwc.i25.bin\nResolving users.dcc.uchile.cl (users.dcc.uchile.cl)... 200.9.99.211, 192.80.24.4\nConnecting to users.dcc.uchile.cl (users.dcc.uchile.cl)|200.9.99.211|:443... connected.\nHTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n\n    The file is already fully retrieved; nothing to do.\n\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from gensim.models import Word2Vec\nfrom gensim.models.wrappers import GloVe\nword2vec_model = Word2Vec.load(\"complete.model\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def make_word_embeddings_es(vocab):\n    # Cargar el modelo binario preentrenado\n    word2vec_model = Word2Vec.load(\"complete.model\")\n\n    # glove_vectors = gensim.downloader.load('glove-wiki-gigaword-200')\n    word_embeddings = np.zeros((len(vocab), fasttext_model.get_dimension()))\n\n    num_found = 0\n\n    for i, word in enumerate(tqdm(vocab, desc=\"loading SPANISH üçÄ word embeddings\")):\n        word_embeddings[i] = fasttext_model.get_word_vector(word)\n        num_found += 1\n\n    logger.info(f'number of found embeddings: {num_found}/{len(vocab)}')\n\n    return scipy.sparse.csr_matrix(word_embeddings)\n\nprepro.make_word_embeddings = make_word_embeddings_es","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Word@Vec","metadata":{}},{"cell_type":"code","source":"!mkdir -p /kaggle/working/modelos/word2vec\n!wget -c \"http://cs.famaf.unc.edu.ar/~ccardellino/SBWCE/SBW-vectors-300-min5.bin.gz\" -P /kaggle/working/modelos/gloVe\n!wget -c \"http://cs.famaf.unc.edu.ar/~ccardellino/SBWCE/SBW-vectors-300-min5.bin.gz\" -P /kaggle/working/modelos/gloVe","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def make_word_embeddings_es(vocab):\n    # Cargar el modelo binario preentrenado\n    word2vec_model = Word2Vec.load(\"complete.model\")\n\n    # glove_vectors = gensim.downloader.load('glove-wiki-gigaword-200')\n    word_embeddings = np.zeros((len(vocab), fasttext_model.get_dimension()))\n\n    num_found = 0\n\n    for i, word in enumerate(tqdm(vocab, desc=\"loading SPANISH üçÄ word embeddings\")):\n        word_embeddings[i] = fasttext_model.get_word_vector(word)\n        num_found += 1\n\n    logger.info(f'number of found embeddings: {num_found}/{len(vocab)}')\n\n    return scipy.sparse.csr_matrix(word_embeddings)\n\nprepro.make_word_embeddings = make_word_embeddings_es","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ------------------------------------------------","metadata":{}},{"cell_type":"code","source":"jsonlist_path = '/kaggle/input/revista-ciencias-mdicas-de-la-habana-cmed'\noutput_path = './datasets/CMed'\n    \n# os.makedirs(jsonlist_path, exist_ok=True)\n# os.makedirs(output_path, exist_ok=True)\n\npreprocessing = Preprocessing(min_doc_count=10, stopwords=stopwords_es)\n\nrst = preprocessing.preprocess_jsonlist(dataset_dir=jsonlist_path, label_name=\"label\")\n\npreprocessing.save(output_path, **rst)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T08:46:25.994343Z","iopub.execute_input":"2025-01-12T08:46:25.994659Z","iopub.status.idle":"2025-01-12T08:47:05.268082Z","shell.execute_reply.started":"2025-01-12T08:46:25.994637Z","shell.execute_reply":"2025-01-12T08:47:05.267128Z"}},"outputs":[{"name":"stderr","text":"2025-01-12 08:46:26,676 - TopMost - Found training documents 1208 testing documents 658\n2025-01-12 08:46:26,679 - TopMost - label2id: {'carta-al-editor': 0, 'ciencias-basicas-biomedicas': 1, 'ciencias-clinicas-y-patologicas': 2, 'ciencias-de-la-educacion': 3, 'ciencias-epidemiologicas-y-salubristas': 4, 'ciencias-quirurgicas': 5, 'ciencias-sociales': 6, 'ciencias-tecnologicas': 7, 'editorial': 8, 'estudios-bibliometricos-y-cienciometricos': 9, 'historico': 10, 'nefrologia-al-dia': 11, 'reflexiones': 12, 'semblanza': 13}\nloading train texts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1208/1208 [00:08<00:00, 135.76it/s]\nloading test texts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 658/658 [00:04<00:00, 142.46it/s]\nparsing texts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1208/1208 [00:03<00:00, 375.99it/s]\n2025-01-12 08:46:45,998 - TopMost - Real vocab size: 19384\n2025-01-12 08:46:46,018 - TopMost - Real training size: 1208 \t avg length: 1335.378\nparsing texts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 658/658 [00:01<00:00, 377.12it/s]\n2025-01-12 08:46:48,739 - TopMost - Real testing size: 658 \t avg length: 1347.125\nloading SPANISH üçÄ word embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19384/19384 [00:00<00:00, 85854.12it/s]\n2025-01-12 08:46:57,070 - TopMost - number of found embeddings: 19384/19384\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Entidades nombradas","metadata":{}},{"cell_type":"markdown","source":"## Spacy","metadata":{}},{"cell_type":"code","source":"import spacy\n\nnlp = spacy.load(\"en_core_web_sm\")\ndoc = nlp(\"Apple is looking at buying U.K. startup for $1 billion. Apple is looking at buying U.K. startup for $1 billion.\")\nfor ent in doc.ents:\n    print(ent.text, ent.label_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T21:48:50.998079Z","iopub.execute_input":"2025-02-21T21:48:50.998398Z","iopub.status.idle":"2025-02-21T21:48:51.794373Z","shell.execute_reply.started":"2025-02-21T21:48:50.998372Z","shell.execute_reply":"2025-02-21T21:48:51.793145Z"}},"outputs":[{"name":"stdout","text":"Apple ORG\nU.K. GPE\n$1 billion MONEY\nApple ORG\nU.K. GPE\n$1 billion MONEY\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from spacy import displacy\n\ndisplacy.render(doc, style='ent', jupyter=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T21:50:53.013847Z","iopub.execute_input":"2025-02-21T21:50:53.014435Z","iopub.status.idle":"2025-02-21T21:50:53.027547Z","shell.execute_reply.started":"2025-02-21T21:50:53.014391Z","shell.execute_reply":"2025-02-21T21:50:53.026039Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Apple\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n</mark>\n is looking at buying \n<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    U.K.\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n</mark>\n startup for \n<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    $1 billion\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n</mark>\n. \n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Apple\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n</mark>\n is looking at buying \n<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    U.K.\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n</mark>\n startup for \n<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    $1 billion\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n</mark>\n.</div></span>"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"## Proceso completo de tokenizacion","metadata":{}},{"cell_type":"code","source":"import spacy\n# nlp = spacy.load('/kaggle/working/es_core_news_lg-3.8.0-py3-none-any.whl')\nnlp = spacy.load('es_core_news_lg')\n\ntext = (\"\"\"Introducci√≥n: Se ha notado el ingreso de neonatos con mastitis, cuya procedencia \ngeogr√°fica es diversa, pero parece recaer en determinadas √°reas geogr√°ficas de la \nprovincia La Habana. \nObjetivo: Determinar la incidencia y procedencia geogr√°fica de la mastitis neonatal \nen la provincia La Habana. \nMaterial y m√©todos:Estudio descriptivo, retrospectivo y transversal de neonatos con \nmastitis, ingresados en los servicios abiertos de Neonatolog√≠a de los hospitales \npedi√°tricos universitarios \"Juan Manuel M√°rquez\" y \"William Soler\", en la provincia de \nLa Habana, durante el a√±o 2013 y primer trimestre del 2014. La informaci√≥n se \nobtuvo de los expedientes cl√≠nicos de los pacientes y los registros estad√≠sticos del \ndepartamento de Epidemiolog√≠a Hospitalaria de la provincia La Habana y esta se \nproces√≥ mediante estad√≠stica descriptiva. \nResultados: La incidencia de mastitis neonatal en la provincia de La Habana para el \nper√≠odo de estudio fue de 3.56 x 1,000 nacidos vivos. La proporci√≥n de casos con \nmastitis neonatal es mayor para los nacidos en el hospital \"Luis D√≠az Soto\" y \nprocedentes del municipio Habana del Este, con diferencias cuando se compara con \ncada uno de los otros municipios de la provincia La Habana. \nConclusiones: La incidencia de la mastitis neonatal durante el per√≠odo estudiado en \nla provincia La Habana indica ser m√°s elevado que lo com√∫nmente reportado, con un \npredominio de casos provenientes del municipio Habana del Este y nacidos en el \nhospital \"Luis D√≠az Soto\", lo cual sugiere que pudieran existir all√≠ condiciones medioambientales o de otro tipo, que faciliten la afecci√≥n.\nPalabras clave: Mastitis, neonatal, Reci√©n nacido, Infecci√≥n, infecciones bacterianas, \ninfecciones de tejidos blandos, absceso de la gl√°ndula mamaria, incidencia.\n\"\"\")\n\n\ntokens = nlp(text)\n\nfrom nltk.corpus import stopwords\nstopwords = stopwords.words('spanish')\nwords_1 = set([token.text for token in tokens if not token.text in stopwords])\nwords_2 = set([token.lemma_ for token in tokens if not token.text in stopwords])\n\n#print(words_1)\n#print(words_2)\n#print([x for x in words_1 if x not in words_2])\n#print([x for x in words_2 if x not in words_1])\n\n\n#print([(x.text, x.lemma_) for x in tokens if x.text not in stopwords])\n\n#print(len(words_1), len(words_2))\n\n\n# Seleccionado: token.lemma_ ‚úÖ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T00:42:16.155406Z","iopub.execute_input":"2025-02-22T00:42:16.155800Z","iopub.status.idle":"2025-02-22T00:42:18.308207Z","shell.execute_reply.started":"2025-02-22T00:42:16.155770Z","shell.execute_reply":"2025-02-22T00:42:18.307204Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"print(len(text))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T00:42:28.038081Z","iopub.execute_input":"2025-02-22T00:42:28.038480Z","iopub.status.idle":"2025-02-22T00:42:28.044420Z","shell.execute_reply.started":"2025-02-22T00:42:28.038447Z","shell.execute_reply":"2025-02-22T00:42:28.043111Z"}},"outputs":[{"name":"stdout","text":"1785\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"from nltk.corpus import stopwords\nstopwords_ = stopwords.words('spanish')\n\ntext_split = text.split(' ')\nprint(len(text_split))\n\nfor x in stopwords_:\n    try:\n        text_split.remove(x)\n    except:\n        pass\n\nprint(len(text_split))\n\ndoc = nlp(' '.join(text_split))\n\nfrom spacy import displacy\ndisplacy.render(doc, style='ent', jupyter=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T01:03:44.253573Z","iopub.execute_input":"2025-02-22T01:03:44.253921Z","iopub.status.idle":"2025-02-22T01:03:44.313626Z","shell.execute_reply.started":"2025-02-22T01:03:44.253892Z","shell.execute_reply":"2025-02-22T01:03:44.312560Z"}},"outputs":[{"name":"stdout","text":"263\n237\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Introducci√≥n: Se notado ingreso neonatos mastitis, cuya procedencia <br>geogr√°fica diversa, parece recaer determinadas √°reas geogr√°ficas de <br>provincia \n<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    La Habana\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n</mark>\n. <br>Objetivo: Determinar la incidencia procedencia geogr√°fica de la mastitis neonatal <br>en la provincia \n<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    La Habana\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n</mark>\n. <br>Material y m√©todos:Estudio descriptivo, retrospectivo y transversal de neonatos con <br>mastitis, ingresados en servicios abiertos de \n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Neonatolog√≠a\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n</mark>\n de los hospitales <br>pedi√°tricos universitarios &quot;\n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Juan Manuel M√°rquez\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n</mark>\n&quot; y &quot;\n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    William Soler\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n</mark>\n&quot;, en la provincia de <br>\n<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    La Habana\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n</mark>\n, el a√±o 2013 y primer trimestre 2014. \n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    La informaci√≥n \nobtuvo de los expedientes cl√≠nicos de los pacientes\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n</mark>\n y los registros estad√≠sticos del <br>\n<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    departamento de Epidemiolog√≠a Hospitalaria\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n</mark>\n de la provincia \n<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    La Habana\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n</mark>\n y se <br>proces√≥ mediante estad√≠stica descriptiva. <br>\n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Resultados: La incidencia de mastitis\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n</mark>\n neonatal en la \n<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    provincia de\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n</mark>\n \n<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    La Habana\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n</mark>\n el <br>per√≠odo de estudio de 3.56 x 1,000 nacidos vivos. \n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    La proporci√≥n de casos con \nmastitis\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n</mark>\n neonatal es mayor para los nacidos en el hospital &quot;\n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Luis D√≠az Soto\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n</mark>\n&quot; y <br>procedentes del municipio \n<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Habana del Este\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n</mark>\n, con diferencias se compara con <br>cada de los municipios de la provincia \n<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    La Habana\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n</mark>\n. <br>\n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Conclusiones: La incidencia de la mastitis\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n</mark>\n neonatal durante el per√≠odo estudiado en <br>la provincia \n<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    La Habana\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n</mark>\n indica ser elevado com√∫nmente reportado, con <br>predominio de casos provenientes del municipio \n<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Habana del Este\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n</mark>\n y nacidos en el <br>hospital &quot;\n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Luis D√≠az Soto\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n</mark>\n&quot;, lo sugiere que pudieran existir all√≠ condiciones medioambientales de tipo, que faciliten la afecci√≥n.<br>\n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Palabras clave: Mastitis\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n</mark>\n, neonatal, \n<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Reci√©n\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n</mark>\n nacido, Infecci√≥n, infecciones bacterianas, <br>infecciones de tejidos blandos, absceso de la gl√°ndula mamaria, incidencia.<br></div></span>"},"metadata":{}}],"execution_count":66},{"cell_type":"code","source":"from nltk.corpus import stopwords\nfrom spacy.lang.es.stop_words import STOP_WORDS\n\nstopwords_1 = stopwords.words('spanish')\n\n# stopwords_2 = spacy.lang.es.stop_words.STOP_WORDS\n\nprint([x for x in stopwords_1 if not x in STOP_WORDS])\nprint(len([x for x in stopwords_1 if not x in STOP_WORDS]))\n\nprint(len(stopwords_1 ))\n\nprint('-'*50)\n\nprint([x for x in STOP_WORDS if not x in stopwords_1])\nprint(len([x for x in STOP_WORDS if not x in stopwords_1]))\nprint(len(STOP_WORDS ))\n\nprint([x for x in stopwords_1 if x in STOP_WORDS])\nprint(len([x for x in stopwords_1 if x in STOP_WORDS]))\n\n# Mejor resultado: nltk ‚úÖ porque la de spacy tiene muchos verbos","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T00:08:56.185392Z","iopub.execute_input":"2025-02-22T00:08:56.185733Z","iopub.status.idle":"2025-02-22T00:08:56.199989Z","shell.execute_reply.started":"2025-02-22T00:08:56.185701Z","shell.execute_reply":"2025-02-22T00:08:56.198506Z"}},"outputs":[{"name":"stdout","text":"['est√°s', 'est√°is', 'est√©', 'est√©s', 'estemos', 'est√©is', 'est√©n', 'estar√©', 'estar√°s', 'estaremos', 'estar√©is', 'estar√°n', 'estar√≠a', 'estar√≠as', 'estar√≠amos', 'estar√≠ais', 'estar√≠an', 'estabas', 'est√°bamos', 'estabais', 'estuve', 'estuviste', 'estuvimos', 'estuvisteis', 'estuvieron', 'estuviera', 'estuvieras', 'estuvi√©ramos', 'estuvierais', 'estuvieran', 'estuviese', 'estuvieses', 'estuvi√©semos', 'estuvieseis', 'estuviesen', 'estando', 'estada', 'estadas', 'estad', 'has', 'hab√©is', 'hayas', 'hayamos', 'hay√°is', 'hayan', 'habr√©', 'habr√°s', 'habremos', 'habr√©is', 'habr√°n', 'habr√≠a', 'habr√≠as', 'habr√≠amos', 'habr√≠ais', 'habr√≠an', 'hab√≠as', 'hab√≠amos', 'hab√≠ais', 'hube', 'hubiste', 'hubimos', 'hubisteis', 'hubieron', 'hubiera', 'hubieras', 'hubi√©ramos', 'hubierais', 'hubieran', 'hubiese', 'hubieses', 'hubi√©semos', 'hubieseis', 'hubiesen', 'habiendo', 'habido', 'habida', 'habidos', 'habidas', 'seas', 'seamos', 'se√°is', 'ser√©', 'ser√°s', 'seremos', 'ser√©is', 'ser√≠as', 'ser√≠amos', 'ser√≠ais', 'ser√≠an', '√©ramos', 'erais', 'fuiste', 'fuisteis', 'fueras', 'fu√©ramos', 'fuerais', 'fueran', 'fuese', 'fueses', 'fu√©semos', 'fueseis', 'fuesen', 'sintiendo', 'sentido', 'sentida', 'sentidos', 'sentidas', 'siente', 'sentid', 'tienes', 'ten√©is', 'tengas', 'tengamos', 'teng√°is', 'tengan', 'tendr√©', 'tendr√°s', 'tendremos', 'tendr√©is', 'tendr√≠a', 'tendr√≠as', 'tendr√≠amos', 'tendr√≠ais', 'tendr√≠an', 'ten√≠as', 'ten√≠amos', 'ten√≠ais', 'ten√≠an', 'tuve', 'tuviste', 'tuvimos', 'tuvisteis', 'tuvieron', 'tuviera', 'tuvieras', 'tuvi√©ramos', 'tuvierais', 'tuvieran', 'tuviese', 'tuvieses', 'tuvi√©semos', 'tuvieseis', 'tuviesen', 'teniendo', 'tenida', 'tenidos', 'tenidas', 'tened']\n148\n313\n--------------------------------------------------\n['cuanto', 'solo', 'si', 'consider√≥', 'menudo', 'hacia', 'buena', 'dar', 'solas', 'siete', 'qui√©nes', 'podr√≠a', 'mencion√≥', 'dice', 'arriba', 'seis', 'ahi', 'bien', 'estais', '√∫ltima', 'cuantas', 'misma', 'acuerdo', 'seg√∫n', 'propios', '√©stas', 'modo', 'poner', 'lleva', '√∫ltimas', 'trav√©s', 'quiza', 'ser', 'ahora', 'alli', 'aquel', 'diferentes', 'solamente', 'afirm√≥', 'dijo', 'cu√°ndo', 'ocho', 'usa', 'va', 'voy', 'segun', 'ustedes', 'aproximadamente', '√©sa', 'aqu√©llos', 'ning√∫n', 'todavia', 'debido', 'veces', 'indic√≥', 'cuenta', 'primeros', 'mias', 'cualquier', 'primero', 'qui√©n', 'once', 'atras', 'quiz√°', 'realiz√≥', 'lleg√≥', 'claro', 'peor', 'siguiente', 'podr√≠an', 'siendo', 'demasiado', 'buenos', 'existen', 'podriamos', 'quiz√°s', 'enfrente', 'aqui', 'tal', 'haces', 'asi', 'c√≥mo', 'nuevas', 'quiere', 'sabes', 'mediante', 'aqu√©llas', 'd√≥nde', 'ello', 'bastante', 'hacer', 'vais', 'consigues', 'pr√≥ximo', 'sigue', 'usas', 'van', 'podrian', 'tampoco', 'cu√°l', '√©sas', 'anterior', 'as√≠', 'cada', 'hacemos', 'ademas', 'cu√°nto', 'sido', 'cierta', 'pr√≥ximos', 'dijeron', 'lado', 'aquellas', 'adelante', 'dias', 'mios', 'pues', 'all√≠', 'mismo', 'existe', 'verdadera', 'explic√≥', '√©sos', 'respecto', 'partir', 'aqu√≠', 'grandes', 'medio', 'saber', 'hacen', 'd√≠a', 'despacio', 'qued√≥', 'tan', 'aun', 'mismos', 's√≥lo', 'cuatro', 'dentro', 'mientras', 'repente', 'mucha', 'a√∫n', 'conocer', '√©ste', '√∫ltimos', 'alrededor', 'hizo', 'pueden', 'segundo', 'tercero', 'ningunas', 'excepto', 'consigo', 'consiguen', 'ambos', 'temprano', 'podr√°n', 'propia', 'mas', 'a√±adi√≥', 'sabeis', 'sabemos', 'hicieron', 'toda', 'fin', 'ir', 'adem√°s', 'podeis', 'largo', 'sabe', 'pa√¨s', 'considera', 'podriais', 'eramos', 'hoy', 'grande', 'agreg√≥', 'd√≠as', 'cuanta', 'cinco', 'entonces', 'coment√≥', 'propio', 'pronto', 'haber', 'estan', '√©stos', 'aqu√©l', 's√©', 'apenas', 'buenas', 'tercera', '√©se', 'aquellos', 'pueda', 'detras', 'u', 'encima', 'todas', 'muchas', 'dan', 'podrias', 'realizar', 'tener', 'vamos', 'vez', 'decir', 'mismas', 'pesar', 'usamos', 'dos', 'pasada', 'usais', 'cu√°nta', 'llevar', 'cuantos', 'primera', 'dio', 'trata', 'alg√∫n', 'ah√≠', 'usted', 'asegur√≥', 'puede', 'sino', 'casi', 'contigo', 'hablan', 'final', 'breve', 'todav√≠a', 'pasado', 'teneis', 'dia', 'aquella', 'diez', 'segunda', 'ciertas', '√∫ltimo', 'hace', 'conmigo', 'despu√©s', 'nueva', 'despues', 'ninguna', 'aqu√©lla', 'vaya', 'cu√°ntos', 'incluso', 'gran', 'informo', 'igual', 'diferente', 'se√±al√≥', 'varios', 'alguno', 'manera', 'sera', 'dej√≥', 'mejor', 'ver', 'queremos', 'deben', 'siempre', 'tarde', 'manifest√≥', 'unas', 'cierto', 'nueve', 'detr√°s', 'debajo', 'haceis', 'mio', 'dem√°s', 'tras', 'primer', 'poca', 'qeu', 'dieron', 'parte', 'buen', 'nuevos', 'expres√≥', 'posible', 'cu√°les', 'tambien', 'doce', 'mia', 'poder', 'ultimo', 'aunque', 'nunca', 'conseguimos', 'ninguno', 'usar', 'podemos', 'quizas', 'usan', 'luego', 'dicen', 'alguna', 'conseguir', 'podria', '√©sta', 'hago', 'consigue', 'supuesto', 'varias', 'bueno', 'ningunos', 'habia', 'pocas', 'habla', 'dado', 'hacerlo', 'bajo', 'realizado', 'parece', 'solos', 'debe', 'mal', 'hecho', 'junto', 'salvo', 'proximo', 'ciertos', 'verdadero', 'deprisa', 'creo', 'aquello', 'encuentra', 'cu√°ntas', 'tres', 'nadie', 'cuales', 'da', 'enseguida', 'propias', 'sola', 'dicho', 'verdad', 'saben', 'embargo', 'haciendo', 'delante', 'nuevo', 'mayor', 'uso', 'pocos', 'pudo', 'podr√°', 'inform√≥', 'total', 'menos', 'puedo']\n356\n521\n['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se', 'las', 'por', 'un', 'para', 'con', 'no', 'una', 'su', 'al', 'lo', 'como', 'm√°s', 'pero', 'sus', 'le', 'ya', 'o', 'este', 's√≠', 'porque', 'esta', 'entre', 'cuando', 'muy', 'sin', 'sobre', 'tambi√©n', 'me', 'hasta', 'hay', 'donde', 'quien', 'desde', 'todo', 'nos', 'durante', 'todos', 'uno', 'les', 'ni', 'contra', 'otros', 'ese', 'eso', 'ante', 'ellos', 'e', 'esto', 'm√≠', 'antes', 'algunos', 'qu√©', 'unos', 'yo', 'otro', 'otras', 'otra', '√©l', 'tanto', 'esa', 'estos', 'mucho', 'quienes', 'nada', 'muchos', 'cual', 'poco', 'ella', 'estar', 'estas', 'algunas', 'algo', 'nosotros', 'mi', 'mis', 't√∫', 'te', 'ti', 'tu', 'tus', 'ellas', 'nosotras', 'vosotros', 'vosotras', 'os', 'm√≠o', 'm√≠a', 'm√≠os', 'm√≠as', 'tuyo', 'tuya', 'tuyos', 'tuyas', 'suyo', 'suya', 'suyos', 'suyas', 'nuestro', 'nuestra', 'nuestros', 'nuestras', 'vuestro', 'vuestra', 'vuestros', 'vuestras', 'esos', 'esas', 'estoy', 'est√°', 'estamos', 'est√°n', 'estar√°', 'estaba', 'estaban', 'estuvo', 'estado', 'estados', 'he', 'ha', 'hemos', 'han', 'haya', 'habr√°', 'hab√≠a', 'hab√≠an', 'hubo', 'soy', 'eres', 'es', 'somos', 'sois', 'son', 'sea', 'sean', 'ser√°', 'ser√°n', 'ser√≠a', 'era', 'eras', 'eran', 'fui', 'fue', 'fuimos', 'fueron', 'fuera', 'tengo', 'tiene', 'tenemos', 'tienen', 'tenga', 'tendr√°', 'tendr√°n', 'ten√≠a', 'tuvo', 'tenido']\n165\n","output_type":"stream"}],"execution_count":9}]}